2015-11-02 23:47:07,570 INFO  DataFormat - Finish read
2015-11-02 23:47:07,571 INFO  DataFormat - Finish write
2015-11-02 23:48:31,914 INFO  DataFormat - Finish read
2015-11-02 23:48:31,915 INFO  DataFormat - Finish write
2015-11-02 23:49:30,713 INFO  DataFormat - Finish read
2015-11-02 23:49:30,714 INFO  DataFormat - Finish write
2015-11-03 10:34:36,320 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 10:34:39,368 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 10:34:39,472 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 10:34:39,472 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2015-11-03 10:34:39,837 DEBUG org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2015-11-03 10:34:39,839 DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2015-11-03 10:34:39,840 DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2015-11-03 10:34:39,856 DEBUG org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-11-03 10:34:39,856 DEBUG org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.7.0_71\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;F:\IBM\JPos\gradle-0.9-preview-1-all\gradle-0.9-preview-1\bin;C:\Program Files\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;F:\Program Files\MATLAB\R2013b\runtime\win32;F:\Program Files\MATLAB\R2013b\bin;F:\Program Files\MATLAB\R2013b\polyspace\bin;C:\Program Files\MongoDB\Server\3.0\bin;E:\Program Files\Git\bin;E:\Program Files\MikTex\miktex\bin;F:\IBM\gradle-1.9-all\gradle-1.9\bin;.
2015-11-03 10:34:39,856 WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-03 10:34:39,856 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
2015-11-03 10:34:39,857 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-11-03 10:34:39,926 DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-11-03 10:34:39,982 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2015-11-03 10:34:39,991 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2015-11-03 10:34:40,002 DEBUG org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: admin
2015-11-03 10:34:40,004 DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:admin (auth:SIMPLE)
2015-11-03 10:34:40,254 INFO  org.apache.spark.SecurityManager - Changing view acls to: admin
2015-11-03 10:34:40,255 INFO  org.apache.spark.SecurityManager - Changing modify acls to: admin
2015-11-03 10:34:40,255 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(admin); users with modify permissions: Set(admin)
2015-11-03 10:34:40,326 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 10:34:40,998 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 10:34:40,999 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 10:34:41,023 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 10:34:41,023 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 10:34:41,379 DEBUG org.apache.spark.util.AkkaUtils - In createActorSystem, requireCookie is: off
2015-11-03 13:31:23,934 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 13:31:24,341 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 13:31:24,358 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 13:31:24,358 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2015-11-03 13:31:24,623 DEBUG org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2015-11-03 13:31:24,625 DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2015-11-03 13:31:24,626 DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2015-11-03 13:31:24,642 DEBUG org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-11-03 13:31:24,642 DEBUG org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.7.0_71\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;F:\IBM\JPos\gradle-0.9-preview-1-all\gradle-0.9-preview-1\bin;C:\Program Files\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;F:\Program Files\MATLAB\R2013b\runtime\win32;F:\Program Files\MATLAB\R2013b\bin;F:\Program Files\MATLAB\R2013b\polyspace\bin;C:\Program Files\MongoDB\Server\3.0\bin;E:\Program Files\Git\bin;E:\Program Files\MikTex\miktex\bin;F:\IBM\gradle-1.9-all\gradle-1.9\bin;.
2015-11-03 13:31:24,642 WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-03 13:31:24,642 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
2015-11-03 13:31:24,643 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-11-03 13:31:24,698 DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-11-03 13:31:25,018 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2015-11-03 13:31:25,019 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2015-11-03 13:31:25,028 DEBUG org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: admin
2015-11-03 13:31:25,030 DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:admin (auth:SIMPLE)
2015-11-03 13:31:25,281 INFO  org.apache.spark.SecurityManager - Changing view acls to: admin
2015-11-03 13:31:25,282 INFO  org.apache.spark.SecurityManager - Changing modify acls to: admin
2015-11-03 13:31:25,282 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(admin); users with modify permissions: Set(admin)
2015-11-03 13:31:25,353 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 13:31:25,703 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 13:31:25,704 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 13:31:25,734 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 13:31:25,734 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 13:31:26,065 DEBUG org.apache.spark.util.AkkaUtils - In createActorSystem, requireCookie is: off
2015-11-03 15:35:13,563 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 15:35:14,869 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 15:35:14,887 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 15:35:14,888 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2015-11-03 15:35:16,274 DEBUG org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2015-11-03 15:35:16,275 DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2015-11-03 15:35:16,277 DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2015-11-03 15:35:16,510 DEBUG org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-11-03 15:35:16,510 DEBUG org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.7.0_71\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;F:\IBM\JPos\gradle-0.9-preview-1-all\gradle-0.9-preview-1\bin;C:\Program Files\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;F:\Program Files\MATLAB\R2013b\runtime\win32;F:\Program Files\MATLAB\R2013b\bin;F:\Program Files\MATLAB\R2013b\polyspace\bin;C:\Program Files\MongoDB\Server\3.0\bin;E:\Program Files\Git\bin;E:\Program Files\MikTex\miktex\bin;F:\IBM\gradle-1.9-all\gradle-1.9\bin;F:\Program Files\SSH Communications Security\SSH Secure Shell;.
2015-11-03 15:35:16,510 WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-03 15:35:16,510 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
2015-11-03 15:35:16,511 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-11-03 15:35:16,575 DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-11-03 15:35:16,746 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2015-11-03 15:35:16,747 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2015-11-03 15:35:16,769 DEBUG org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: admin
2015-11-03 15:35:16,785 DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:admin (auth:SIMPLE)
2015-11-03 15:35:17,093 INFO  org.apache.spark.SecurityManager - Changing view acls to: admin
2015-11-03 15:35:17,093 INFO  org.apache.spark.SecurityManager - Changing modify acls to: admin
2015-11-03 15:35:17,094 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(admin); users with modify permissions: Set(admin)
2015-11-03 15:35:17,184 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 15:35:17,789 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 15:35:17,790 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 15:35:17,820 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 15:35:17,820 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 15:35:18,117 DEBUG org.apache.spark.util.AkkaUtils - In createActorSystem, requireCookie is: off
2015-11-03 15:35:42,330 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 15:35:42,442 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 15:35:42,446 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 15:35:42,447 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2015-11-03 15:35:42,662 DEBUG org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2015-11-03 15:35:42,663 DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2015-11-03 15:35:42,664 DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2015-11-03 15:35:42,665 DEBUG org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-11-03 15:35:42,665 DEBUG org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.7.0_71\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;F:\IBM\JPos\gradle-0.9-preview-1-all\gradle-0.9-preview-1\bin;C:\Program Files\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;F:\Program Files\MATLAB\R2013b\runtime\win32;F:\Program Files\MATLAB\R2013b\bin;F:\Program Files\MATLAB\R2013b\polyspace\bin;C:\Program Files\MongoDB\Server\3.0\bin;E:\Program Files\Git\bin;E:\Program Files\MikTex\miktex\bin;F:\IBM\gradle-1.9-all\gradle-1.9\bin;F:\Program Files\SSH Communications Security\SSH Secure Shell;.
2015-11-03 15:35:42,665 WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-03 15:35:42,665 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
2015-11-03 15:35:42,665 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-11-03 15:35:42,691 DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-11-03 15:35:42,694 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2015-11-03 15:35:42,695 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2015-11-03 15:35:42,697 DEBUG org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: admin
2015-11-03 15:35:42,698 DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:admin (auth:SIMPLE)
2015-11-03 15:35:42,887 ERROR org.apache.spark.SparkContext - Error initializing SparkContext.
org.apache.spark.SparkException: A master URL must be set in your configuration
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:385)
	at Join$.main(Join.scala:11)
	at Join.main(Join.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-11-03 15:35:43,283 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-03 15:36:20,364 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 15:36:21,074 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 15:36:21,118 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 15:36:21,119 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2015-11-03 15:36:22,287 DEBUG org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2015-11-03 15:36:22,288 DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2015-11-03 15:36:22,290 DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2015-11-03 15:36:22,323 DEBUG org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-11-03 15:36:22,323 DEBUG org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.7.0_71\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;F:\IBM\JPos\gradle-0.9-preview-1-all\gradle-0.9-preview-1\bin;C:\Program Files\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;F:\Program Files\MATLAB\R2013b\runtime\win32;F:\Program Files\MATLAB\R2013b\bin;F:\Program Files\MATLAB\R2013b\polyspace\bin;C:\Program Files\MongoDB\Server\3.0\bin;E:\Program Files\Git\bin;E:\Program Files\MikTex\miktex\bin;F:\IBM\gradle-1.9-all\gradle-1.9\bin;F:\Program Files\SSH Communications Security\SSH Secure Shell;.
2015-11-03 15:36:22,324 WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-03 15:36:22,324 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
2015-11-03 15:36:22,324 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-11-03 15:36:22,372 DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-11-03 15:36:22,857 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2015-11-03 15:36:22,950 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2015-11-03 15:36:22,953 DEBUG org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: admin
2015-11-03 15:36:23,077 DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:admin (auth:SIMPLE)
2015-11-03 15:36:23,718 INFO  org.apache.spark.SecurityManager - Changing view acls to: admin
2015-11-03 15:36:23,719 INFO  org.apache.spark.SecurityManager - Changing modify acls to: admin
2015-11-03 15:36:23,719 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(admin); users with modify permissions: Set(admin)
2015-11-03 15:36:23,826 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 15:36:24,911 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 15:36:24,912 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 15:36:24,950 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 15:36:24,951 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 15:36:25,590 DEBUG org.apache.spark.util.AkkaUtils - In createActorSystem, requireCookie is: off
2015-11-03 15:42:53,779 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 15:42:54,647 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 15:42:54,663 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 15:42:54,664 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2015-11-03 15:42:54,953 DEBUG org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2015-11-03 15:42:54,954 DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2015-11-03 15:42:54,956 DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2015-11-03 15:42:54,987 DEBUG org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-11-03 15:42:54,987 DEBUG org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.7.0_71\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;F:\IBM\JPos\gradle-0.9-preview-1-all\gradle-0.9-preview-1\bin;C:\Program Files\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;F:\Program Files\MATLAB\R2013b\runtime\win32;F:\Program Files\MATLAB\R2013b\bin;F:\Program Files\MATLAB\R2013b\polyspace\bin;C:\Program Files\MongoDB\Server\3.0\bin;E:\Program Files\Git\bin;E:\Program Files\MikTex\miktex\bin;F:\IBM\gradle-1.9-all\gradle-1.9\bin;F:\Program Files\SSH Communications Security\SSH Secure Shell;.
2015-11-03 15:42:54,987 WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-03 15:42:54,987 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
2015-11-03 15:42:54,988 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-11-03 15:42:55,036 DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-11-03 15:42:55,089 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2015-11-03 15:42:55,089 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2015-11-03 15:42:55,133 DEBUG org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: admin
2015-11-03 15:42:55,134 DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:admin (auth:SIMPLE)
2015-11-03 15:42:55,378 INFO  org.apache.spark.SecurityManager - Changing view acls to: admin
2015-11-03 15:42:55,378 INFO  org.apache.spark.SecurityManager - Changing modify acls to: admin
2015-11-03 15:42:55,379 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(admin); users with modify permissions: Set(admin)
2015-11-03 15:42:55,438 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 15:42:55,852 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 15:42:55,853 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 15:42:55,881 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 15:42:55,881 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 15:42:56,245 DEBUG org.apache.spark.util.AkkaUtils - In createActorSystem, requireCookie is: off
2015-11-03 15:59:51,759 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 15:59:52,769 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 15:59:52,813 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 15:59:52,813 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2015-11-03 15:59:54,759 DEBUG org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2015-11-03 15:59:54,760 DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2015-11-03 15:59:54,790 DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2015-11-03 15:59:54,912 DEBUG org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-11-03 15:59:54,912 DEBUG org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.7.0_71\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;F:\IBM\JPos\gradle-0.9-preview-1-all\gradle-0.9-preview-1\bin;C:\Program Files\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;F:\Program Files\MATLAB\R2013b\runtime\win32;F:\Program Files\MATLAB\R2013b\bin;F:\Program Files\MATLAB\R2013b\polyspace\bin;C:\Program Files\MongoDB\Server\3.0\bin;E:\Program Files\Git\bin;E:\Program Files\MikTex\miktex\bin;F:\IBM\gradle-1.9-all\gradle-1.9\bin;F:\Program Files\SSH Communications Security\SSH Secure Shell;.
2015-11-03 15:59:54,912 WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-03 15:59:54,912 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
2015-11-03 15:59:54,913 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-11-03 15:59:55,239 DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-11-03 15:59:55,440 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2015-11-03 15:59:55,441 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2015-11-03 15:59:55,488 DEBUG org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: admin
2015-11-03 15:59:55,490 DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:admin (auth:SIMPLE)
2015-11-03 15:59:56,108 INFO  org.apache.spark.SecurityManager - Changing view acls to: admin
2015-11-03 15:59:56,108 INFO  org.apache.spark.SecurityManager - Changing modify acls to: admin
2015-11-03 15:59:56,108 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(admin); users with modify permissions: Set(admin)
2015-11-03 15:59:56,448 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 15:59:57,851 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 15:59:57,852 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 15:59:57,889 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 15:59:57,890 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 15:59:58,495 DEBUG org.apache.spark.util.AkkaUtils - In createActorSystem, requireCookie is: off
2015-11-03 16:02:40,777 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 16:02:43,254 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 16:02:43,323 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 16:02:43,324 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2015-11-03 16:02:43,998 DEBUG org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2015-11-03 16:02:43,999 DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2015-11-03 16:02:44,001 DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2015-11-03 16:02:44,040 DEBUG org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-11-03 16:02:44,040 DEBUG org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.7.0_71\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;F:\IBM\JPos\gradle-0.9-preview-1-all\gradle-0.9-preview-1\bin;C:\Program Files\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;F:\Program Files\MATLAB\R2013b\runtime\win32;F:\Program Files\MATLAB\R2013b\bin;F:\Program Files\MATLAB\R2013b\polyspace\bin;C:\Program Files\MongoDB\Server\3.0\bin;E:\Program Files\Git\bin;E:\Program Files\MikTex\miktex\bin;F:\IBM\gradle-1.9-all\gradle-1.9\bin;F:\Program Files\SSH Communications Security\SSH Secure Shell;.
2015-11-03 16:02:44,041 WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-03 16:02:44,041 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
2015-11-03 16:02:44,041 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-11-03 16:02:44,115 DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-11-03 16:02:44,215 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2015-11-03 16:02:44,226 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2015-11-03 16:02:44,273 DEBUG org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: admin
2015-11-03 16:02:44,335 DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:admin (auth:SIMPLE)
2015-11-03 16:02:44,967 INFO  org.apache.spark.SecurityManager - Changing view acls to: admin
2015-11-03 16:02:44,968 INFO  org.apache.spark.SecurityManager - Changing modify acls to: admin
2015-11-03 16:02:44,968 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(admin); users with modify permissions: Set(admin)
2015-11-03 16:02:45,092 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 16:02:45,520 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 16:02:45,521 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 16:02:45,549 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 16:02:45,549 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 16:02:47,080 DEBUG org.apache.spark.util.AkkaUtils - In createActorSystem, requireCookie is: off
2015-11-03 16:09:13,952 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 16:09:14,361 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 16:09:14,379 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-11-03 16:09:14,380 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2015-11-03 16:09:14,700 DEBUG org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2015-11-03 16:09:14,701 DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2015-11-03 16:09:14,703 DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2015-11-03 16:09:14,743 DEBUG org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-11-03 16:09:14,743 DEBUG org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.7.0_71\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;F:\IBM\JPos\gradle-0.9-preview-1-all\gradle-0.9-preview-1\bin;C:\Program Files\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;F:\Program Files\MATLAB\R2013b\runtime\win32;F:\Program Files\MATLAB\R2013b\bin;F:\Program Files\MATLAB\R2013b\polyspace\bin;C:\Program Files\MongoDB\Server\3.0\bin;E:\Program Files\Git\bin;E:\Program Files\MikTex\miktex\bin;F:\IBM\gradle-1.9-all\gradle-1.9\bin;F:\Program Files\SSH Communications Security\SSH Secure Shell;.
2015-11-03 16:09:14,743 WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-03 16:09:14,743 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
2015-11-03 16:09:14,744 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-11-03 16:09:14,771 DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-11-03 16:09:14,838 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2015-11-03 16:09:14,839 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2015-11-03 16:09:14,849 DEBUG org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: admin
2015-11-03 16:09:14,872 DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:admin (auth:SIMPLE)
2015-11-03 16:09:15,138 INFO  org.apache.spark.SecurityManager - Changing view acls to: admin
2015-11-03 16:09:15,145 INFO  org.apache.spark.SecurityManager - Changing modify acls to: admin
2015-11-03 16:09:15,145 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(admin); users with modify permissions: Set(admin)
2015-11-03 16:09:15,273 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 16:09:15,612 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 16:09:15,613 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 16:09:15,637 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 16:09:15,637 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 16:09:15,934 DEBUG org.apache.spark.util.AkkaUtils - In createActorSystem, requireCookie is: off
2015-11-03 17:39:52,127 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 17:39:55,575 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
2015-11-03 17:39:56,178 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
2015-11-03 17:39:56,180 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2015-11-03 17:39:59,503 DEBUG org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2015-11-03 17:39:59,510 DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2015-11-03 17:39:59,543 DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2015-11-03 17:39:59,840 DEBUG org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
2015-11-03 17:39:59,842 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
2015-11-03 17:39:59,842 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2015-11-03 17:40:00,397 DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-11-03 17:40:00,671 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2015-11-03 17:40:00,694 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2015-11-03 17:40:00,821 DEBUG org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: Claire
2015-11-03 17:40:01,007 DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:Claire (auth:SIMPLE)
2015-11-03 17:40:02,275 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-03 17:40:02,371 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-03 17:40:02,372 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-03 17:40:02,901 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 17:40:08,565 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 17:40:08,570 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 17:40:08,642 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 17:40:08,643 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 17:40:09,144 DEBUG org.apache.spark.util.AkkaUtils - In createActorSystem, requireCookie is: off
2015-11-03 17:40:39,009 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 17:40:39,450 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
2015-11-03 17:40:39,460 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
2015-11-03 17:40:39,462 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2015-11-03 17:40:39,777 DEBUG org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2015-11-03 17:40:39,780 DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2015-11-03 17:40:39,783 DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2015-11-03 17:40:39,904 DEBUG org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
2015-11-03 17:40:39,905 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
2015-11-03 17:40:39,905 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2015-11-03 17:40:40,108 DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-11-03 17:40:40,114 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2015-11-03 17:40:40,115 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2015-11-03 17:40:40,124 DEBUG org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: Claire
2015-11-03 17:40:40,125 DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:Claire (auth:SIMPLE)
2015-11-03 17:40:40,236 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-03 17:40:40,237 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-03 17:40:40,238 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-03 17:40:40,262 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 17:40:40,695 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 17:40:40,699 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 17:40:40,705 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 17:40:40,706 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 17:40:40,759 DEBUG org.apache.spark.util.AkkaUtils - In createActorSystem, requireCookie is: off
2015-11-03 17:43:12,494 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 17:43:13,155 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
2015-11-03 17:43:13,164 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
2015-11-03 17:43:13,166 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2015-11-03 17:43:13,588 DEBUG org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2015-11-03 17:43:13,591 DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2015-11-03 17:43:13,593 DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2015-11-03 17:43:13,597 DEBUG org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
2015-11-03 17:43:13,598 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
2015-11-03 17:43:13,598 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2015-11-03 17:43:13,730 DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-11-03 17:43:13,761 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2015-11-03 17:43:13,762 DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2015-11-03 17:43:13,770 DEBUG org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: Claire
2015-11-03 17:43:13,772 DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:Claire (auth:SIMPLE)
2015-11-03 17:43:13,824 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-03 17:43:13,825 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-03 17:43:13,825 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-03 17:43:13,846 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 17:43:14,170 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 17:43:14,172 DEBUG org.apache.spark.SSLOptions - No SSL protocol specified
2015-11-03 17:43:14,176 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 17:43:14,177 DEBUG org.apache.spark.SecurityManager - SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-11-03 17:43:14,224 DEBUG org.apache.spark.util.AkkaUtils - In createActorSystem, requireCookie is: off
2015-11-03 17:48:37,468 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 17:48:38,175 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-03 17:48:38,176 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-03 17:48:38,176 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-03 17:58:29,761 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 17:58:31,546 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-03 17:58:31,565 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-03 17:58:31,566 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-03 17:58:34,514 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-03 17:58:34,929 INFO  Remoting - Starting remoting
2015-11-03 17:58:35,825 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:52431]
2015-11-03 17:58:35,915 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52431.
2015-11-03 17:58:36,226 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-03 17:58:36,331 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-03 17:58:36,498 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-d94275e0-9e39-4c80-985d-e2dc3fe800e9
2015-11-03 17:58:36,664 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-03 17:58:36,990 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-02181948-2e96-47e1-ae74-8b5956dfb5db\httpd-06a8a4c5-8b96-44e4-abb3-3d32200e23f9
2015-11-03 17:58:37,139 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-03 17:58:37,438 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 17:58:37,495 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:52435
2015-11-03 17:58:37,496 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 52435.
2015-11-03 17:58:37,570 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-03 17:58:38,877 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 17:58:39,004 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-03 17:58:39,005 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-03 17:58:39,023 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-03 17:58:39,640 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-03 17:58:39,666 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-03 17:58:40,832 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52464.
2015-11-03 17:58:40,833 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 52464
2015-11-03 17:58:40,850 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-03 17:58:40,871 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:52464 with 481.9 MB RAM, BlockManagerId(driver, localhost, 52464)
2015-11-03 17:58:40,908 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-03 17:58:43,787 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-03 17:58:43,809 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-03 17:58:44,062 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-03 17:58:44,063 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-03 17:58:44,066 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:52464 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 17:58:44,132 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at WordCount.scala:17
2015-11-03 17:58:46,633 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:105%31, but we couldn't find any external IP address!
2015-11-03 17:58:47,259 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 17:58:47,597 INFO  org.apache.spark.SparkContext - Starting job: collect at WordCount.scala:18
2015-11-03 17:58:47,874 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 3 (map at WordCount.scala:18)
2015-11-03 17:58:47,924 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (collect at WordCount.scala:18) with 1 output partitions
2015-11-03 17:58:47,925 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 1(collect at WordCount.scala:18)
2015-11-03 17:58:47,948 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 0)
2015-11-03 17:58:47,951 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 0)
2015-11-03 17:58:48,047 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at WordCount.scala:18), which has no missing parents
2015-11-03 17:58:48,246 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(4016) called with curMem=116545, maxMem=505361203
2015-11-03 17:58:48,247 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 481.8 MB)
2015-11-03 17:58:48,249 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2287) called with curMem=120561, maxMem=505361203
2015-11-03 17:58:48,250 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 481.8 MB)
2015-11-03 17:58:48,251 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:52464 (size: 2.2 KB, free: 481.9 MB)
2015-11-03 17:58:48,252 INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-11-03 17:58:48,405 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at WordCount.scala:18)
2015-11-03 17:58:48,406 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2015-11-03 17:58:48,846 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2160 bytes)
2015-11-03 17:58:49,136 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-03 17:58:49,563 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/count.txt:0+48
2015-11-03 17:58:49,846 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-03 17:58:49,847 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-03 17:58:49,847 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-03 17:58:49,847 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-03 17:58:49,848 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-03 17:58:50,920 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
2015-11-03 17:58:50,958 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 2238 ms on localhost (1/1)
2015-11-03 17:58:50,960 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-03 17:58:51,037 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (map at WordCount.scala:18) finished in 2.432 s
2015-11-03 17:58:51,040 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 17:58:51,041 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 17:58:51,042 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 1)
2015-11-03 17:58:51,043 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 17:58:51,108 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 1: List()
2015-11-03 17:58:51,159 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (ShuffledRDD[4] at reduceByKey at WordCount.scala:18), which is now runnable
2015-11-03 17:58:51,178 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2288) called with curMem=122848, maxMem=505361203
2015-11-03 17:58:51,179 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.2 KB, free 481.8 MB)
2015-11-03 17:58:51,180 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1379) called with curMem=125136, maxMem=505361203
2015-11-03 17:58:51,181 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1379.0 B, free 481.8 MB)
2015-11-03 17:58:51,185 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:52464 (size: 1379.0 B, free: 481.9 MB)
2015-11-03 17:58:51,187 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-03 17:58:51,216 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (ShuffledRDD[4] at reduceByKey at WordCount.scala:18)
2015-11-03 17:58:51,216 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2015-11-03 17:58:51,221 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-03 17:58:51,223 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2015-11-03 17:58:51,290 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 17:58:51,299 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 25 ms
2015-11-03 17:58:51,418 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1410 bytes result sent to driver
2015-11-03 17:58:51,421 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 204 ms on localhost (1/1)
2015-11-03 17:58:51,422 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-03 17:58:51,422 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 1 (collect at WordCount.scala:18) finished in 0.205 s
2015-11-03 17:58:51,456 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: collect at WordCount.scala:18, took 3.859034 s
2015-11-03 17:58:51,535 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-03 17:58:51,536 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-03 17:58:51,536 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-03 17:58:51,536 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-03 17:58:51,536 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-03 17:58:51,536 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-03 17:58:51,537 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-03 17:58:51,537 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-03 17:58:51,537 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-03 17:58:51,537 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-03 17:58:51,537 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-03 17:58:51,537 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-03 17:58:51,537 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-03 17:58:51,537 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-03 17:58:51,538 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-03 17:58:51,538 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-03 17:58:51,538 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-03 17:58:51,538 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-03 17:58:51,538 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-03 17:58:51,538 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-03 17:58:51,538 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-03 17:58:51,539 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-03 17:58:51,539 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-03 17:58:51,539 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-03 17:58:51,539 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-03 17:58:51,593 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-03 17:58:51,633 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-03 17:58:51,736 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-03 17:58:51,775 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-03 17:58:51,786 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-03 17:58:51,808 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-03 17:58:51,850 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-03 17:58:51,866 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-03 17:58:51,890 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-03 17:58:51,891 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-02181948-2e96-47e1-ae74-8b5956dfb5db
2015-11-03 17:59:35,581 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 17:59:37,109 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-03 17:59:37,110 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-03 17:59:37,111 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-03 17:59:37,941 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-03 17:59:38,007 INFO  Remoting - Starting remoting
2015-11-03 17:59:38,217 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:52613]
2015-11-03 17:59:38,224 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52613.
2015-11-03 17:59:38,246 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-03 17:59:38,261 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-03 17:59:38,284 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-68d0460f-52b4-49d0-88d2-e2368d7cb078
2015-11-03 17:59:38,298 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-03 17:59:38,383 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-db7853ad-63c6-411c-8ece-87f809b43bf9\httpd-0e2a1c3d-a328-4e72-8134-aafdca2046ec
2015-11-03 17:59:38,389 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-03 17:59:38,471 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 17:59:38,492 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:52614
2015-11-03 17:59:38,492 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 52614.
2015-11-03 17:59:38,516 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-03 17:59:38,715 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 17:59:38,733 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-03 17:59:38,733 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-03 17:59:38,737 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-03 17:59:38,863 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-03 17:59:38,866 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-03 17:59:39,249 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52635.
2015-11-03 17:59:39,250 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 52635
2015-11-03 17:59:39,251 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-03 17:59:39,254 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:52635 with 481.9 MB RAM, BlockManagerId(driver, localhost, 52635)
2015-11-03 17:59:39,256 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-03 17:59:39,979 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-03 17:59:39,981 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-03 17:59:40,027 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-03 17:59:40,028 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-03 17:59:40,032 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:52635 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 17:59:40,037 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at Join.scala:16
2015-11-03 17:59:40,239 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=116545, maxMem=505361203
2015-11-03 17:59:40,240 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 104.0 KB, free 481.7 MB)
2015-11-03 17:59:40,261 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=223065, maxMem=505361203
2015-11-03 17:59:40,262 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.7 MB)
2015-11-03 17:59:40,263 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:52635 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 17:59:40,266 INFO  org.apache.spark.SparkContext - Created broadcast 1 from textFile at Join.scala:25
2015-11-03 17:59:41,758 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:105%31, but we couldn't find any external IP address!
2015-11-03 17:59:42,260 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 17:59:42,346 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 17:59:42,697 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-03 17:59:42,698 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-03 17:59:42,698 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-03 17:59:42,698 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-03 17:59:42,698 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-03 17:59:42,959 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at Join.scala:37
2015-11-03 17:59:42,985 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 2 (map at Join.scala:17)
2015-11-03 17:59:42,986 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 5 (map at Join.scala:26)
2015-11-03 17:59:42,989 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsTextFile at Join.scala:37) with 1 output partitions
2015-11-03 17:59:42,990 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2(saveAsTextFile at Join.scala:37)
2015-11-03 17:59:42,990 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 17:59:42,992 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 17:59:43,001 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at Join.scala:17), which has no missing parents
2015-11-03 17:59:43,029 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3528) called with curMem=233130, maxMem=505361203
2015-11-03 17:59:43,030 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 3.4 KB, free 481.7 MB)
2015-11-03 17:59:43,037 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2075) called with curMem=236658, maxMem=505361203
2015-11-03 17:59:43,037 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.7 MB)
2015-11-03 17:59:43,040 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:52635 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 17:59:43,041 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-03 17:59:43,045 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at Join.scala:17)
2015-11-03 17:59:43,046 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2015-11-03 17:59:43,058 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Join.scala:26), which has no missing parents
2015-11-03 17:59:43,061 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3544) called with curMem=238733, maxMem=505361203
2015-11-03 17:59:43,062 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 3.5 KB, free 481.7 MB)
2015-11-03 17:59:43,067 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2085) called with curMem=242277, maxMem=505361203
2015-11-03 17:59:43,067 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.7 MB)
2015-11-03 17:59:43,069 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:52635 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 17:59:43,070 INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-11-03 17:59:43,070 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Join.scala:26)
2015-11-03 17:59:43,070 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2015-11-03 17:59:43,091 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2160 bytes)
2015-11-03 17:59:43,100 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-03 17:59:43,135 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/Hotel.txt:0+337904
2015-11-03 17:59:45,096 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
2015-11-03 17:59:45,290 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 2172 bytes)
2015-11-03 17:59:45,293 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2015-11-03 17:59:45,357 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 2222 ms on localhost (1/1)
2015-11-03 17:59:45,360 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/hotel_id_position.txt:0+17841
2015-11-03 17:59:45,452 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-03 17:59:45,536 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 2253 bytes result sent to driver
2015-11-03 17:59:45,544 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 257 ms on localhost (1/1)
2015-11-03 17:59:45,545 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-03 17:59:46,199 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (map at Join.scala:17) finished in 3.064 s
2015-11-03 17:59:46,291 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 17:59:46,293 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set(ShuffleMapStage 1)
2015-11-03 17:59:46,295 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 17:59:46,314 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 17:59:46,461 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List(ShuffleMapStage 1)
2015-11-03 17:59:46,480 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at Join.scala:26) finished in 3.384 s
2015-11-03 17:59:46,480 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 17:59:46,480 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 17:59:46,480 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 17:59:46,480 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 17:59:46,481 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List()
2015-11-03 17:59:46,500 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[10] at saveAsTextFile at Join.scala:37), which is now runnable
2015-11-03 17:59:46,568 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95976) called with curMem=244362, maxMem=505361203
2015-11-03 17:59:46,568 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 93.7 KB, free 481.6 MB)
2015-11-03 17:59:46,571 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31374) called with curMem=340338, maxMem=505361203
2015-11-03 17:59:46,571 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 30.6 KB, free 481.6 MB)
2015-11-03 17:59:46,573 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:52635 (size: 30.6 KB, free: 481.9 MB)
2015-11-03 17:59:46,574 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-03 17:59:46,582 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at saveAsTextFile at Join.scala:37)
2015-11-03 17:59:46,582 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks
2015-11-03 17:59:46,585 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 17:59:46,585 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2015-11-03 17:59:46,655 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-03 17:59:46,656 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-03 17:59:46,658 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-03 17:59:46,665 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-03 17:59:46,788 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 17:59:46,797 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 21 ms
2015-11-03 17:59:46,873 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 17:59:46,874 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 17:59:48,002 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031759_0002_m_000000_2' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/HotelInfo/_temporary/0/task_201511031759_0002_m_000000
2015-11-03 17:59:48,026 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031759_0002_m_000000_2: Committed
2015-11-03 17:59:48,028 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1165 bytes result sent to driver
2015-11-03 17:59:48,032 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on localhost:52635 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 17:59:48,035 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 1452 ms on localhost (1/1)
2015-11-03 17:59:48,035 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-03 17:59:48,052 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (saveAsTextFile at Join.scala:37) finished in 1.469 s
2015-11-03 17:59:48,093 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on localhost:52635 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 17:59:48,120 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsTextFile at Join.scala:37, took 5.160843 s
2015-11-03 17:59:48,191 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(64288) called with curMem=360480, maxMem=505361203
2015-11-03 17:59:48,192 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 62.8 KB, free 481.5 MB)
2015-11-03 17:59:48,254 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(14119) called with curMem=424768, maxMem=505361203
2015-11-03 17:59:48,255 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.8 KB, free 481.5 MB)
2015-11-03 17:59:48,257 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:52635 (size: 13.8 KB, free: 481.9 MB)
2015-11-03 17:59:48,261 INFO  org.apache.spark.SparkContext - Created broadcast 5 from textFile at Join.scala:40
2015-11-03 17:59:48,303 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(148024) called with curMem=438887, maxMem=505361203
2015-11-03 17:59:48,304 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 144.6 KB, free 481.4 MB)
2015-11-03 17:59:48,340 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(14119) called with curMem=586911, maxMem=505361203
2015-11-03 17:59:48,341 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 13.8 KB, free 481.4 MB)
2015-11-03 17:59:48,344 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on localhost:52635 (size: 13.8 KB, free: 481.9 MB)
2015-11-03 17:59:48,347 INFO  org.apache.spark.SparkContext - Created broadcast 6 from textFile at Join.scala:51
2015-11-03 17:59:48,366 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-03 17:59:48,401 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-03 17:59:48,402 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-03 17:59:48,402 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-03 17:59:48,402 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-03 17:59:48,402 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-03 17:59:48,402 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-03 17:59:48,403 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-03 17:59:48,403 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-03 17:59:48,403 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-03 17:59:48,403 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-03 17:59:48,403 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-03 17:59:48,403 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-03 17:59:48,403 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-03 17:59:48,403 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-03 17:59:48,404 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-03 17:59:48,404 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-03 17:59:48,404 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-03 17:59:48,404 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-03 17:59:48,404 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-03 17:59:48,404 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-03 17:59:48,404 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-03 17:59:48,405 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-03 17:59:48,405 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-03 17:59:48,405 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-03 17:59:48,405 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-03 17:59:48,457 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-03 17:59:48,466 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-03 17:59:48,578 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-03 17:59:48,628 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-03 17:59:48,640 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-03 17:59:48,651 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-03 17:59:48,663 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-03 17:59:48,664 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-03 17:59:48,677 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-03 17:59:48,678 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-db7853ad-63c6-411c-8ece-87f809b43bf9
2015-11-03 18:03:19,987 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 18:03:21,260 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-03 18:03:21,261 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-03 18:03:21,262 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-03 18:03:22,111 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-03 18:03:22,173 INFO  Remoting - Starting remoting
2015-11-03 18:03:22,371 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:53153]
2015-11-03 18:03:22,377 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53153.
2015-11-03 18:03:22,398 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-03 18:03:22,414 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-03 18:03:22,440 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-741f35c9-b11c-4366-98a2-c7fa32769c30
2015-11-03 18:03:22,454 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-03 18:03:22,534 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-830cea1c-47ef-48d1-91f9-daf332d57307\httpd-30fc0e93-6932-4e78-aa33-0e8ea7fbd933
2015-11-03 18:03:22,539 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-03 18:03:22,608 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 18:03:22,628 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:53156
2015-11-03 18:03:22,628 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 53156.
2015-11-03 18:03:22,651 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-03 18:03:22,832 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 18:03:22,853 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-03 18:03:22,853 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-03 18:03:22,857 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-03 18:03:23,005 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-03 18:03:23,009 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-03 18:03:23,453 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53178.
2015-11-03 18:03:23,453 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 53178
2015-11-03 18:03:23,456 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-03 18:03:23,458 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:53178 with 481.9 MB RAM, BlockManagerId(driver, localhost, 53178)
2015-11-03 18:03:23,461 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-03 18:03:24,119 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-03 18:03:24,121 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-03 18:03:24,164 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-03 18:03:24,165 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-03 18:03:24,170 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:53178 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:03:24,178 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at Join.scala:16
2015-11-03 18:03:24,284 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=116545, maxMem=505361203
2015-11-03 18:03:24,285 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 104.0 KB, free 481.7 MB)
2015-11-03 18:03:24,305 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=223065, maxMem=505361203
2015-11-03 18:03:24,305 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.7 MB)
2015-11-03 18:03:24,306 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:53178 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:03:24,308 INFO  org.apache.spark.SparkContext - Created broadcast 1 from textFile at Join.scala:25
2015-11-03 18:03:25,648 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:105%31, but we couldn't find any external IP address!
2015-11-03 18:03:26,159 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:03:26,218 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:03:26,376 INFO  org.apache.spark.SparkContext - Starting job: collect at Join.scala:38
2015-11-03 18:03:26,411 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 2 (map at Join.scala:17)
2015-11-03 18:03:26,413 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 5 (map at Join.scala:26)
2015-11-03 18:03:26,417 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (collect at Join.scala:38) with 1 output partitions
2015-11-03 18:03:26,418 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2(collect at Join.scala:38)
2015-11-03 18:03:26,419 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 18:03:26,422 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 18:03:26,433 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at Join.scala:17), which has no missing parents
2015-11-03 18:03:26,459 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3528) called with curMem=233130, maxMem=505361203
2015-11-03 18:03:26,460 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 3.4 KB, free 481.7 MB)
2015-11-03 18:03:26,462 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2075) called with curMem=236658, maxMem=505361203
2015-11-03 18:03:26,463 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.7 MB)
2015-11-03 18:03:26,464 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:53178 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:03:26,465 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-03 18:03:26,470 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at Join.scala:17)
2015-11-03 18:03:26,472 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2015-11-03 18:03:26,484 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Join.scala:26), which has no missing parents
2015-11-03 18:03:26,488 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3544) called with curMem=238733, maxMem=505361203
2015-11-03 18:03:26,489 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 3.5 KB, free 481.7 MB)
2015-11-03 18:03:26,493 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2085) called with curMem=242277, maxMem=505361203
2015-11-03 18:03:26,493 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.7 MB)
2015-11-03 18:03:26,495 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:53178 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:03:26,497 INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-11-03 18:03:26,497 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Join.scala:26)
2015-11-03 18:03:26,497 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2015-11-03 18:03:26,519 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2160 bytes)
2015-11-03 18:03:26,527 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-03 18:03:26,552 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/Hotel.txt:0+337904
2015-11-03 18:03:26,560 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-03 18:03:26,560 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-03 18:03:26,560 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-03 18:03:26,560 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-03 18:03:26,560 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-03 18:03:26,844 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
2015-11-03 18:03:26,851 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 2172 bytes)
2015-11-03 18:03:26,851 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2015-11-03 18:03:26,861 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/hotel_id_position.txt:0+17841
2015-11-03 18:03:26,863 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 358 ms on localhost (1/1)
2015-11-03 18:03:26,865 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-03 18:03:26,871 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (map at Join.scala:17) finished in 0.387 s
2015-11-03 18:03:26,872 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:03:26,873 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set(ShuffleMapStage 1)
2015-11-03 18:03:26,873 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 18:03:26,875 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:03:26,879 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List(ShuffleMapStage 1)
2015-11-03 18:03:26,916 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 2253 bytes result sent to driver
2015-11-03 18:03:26,933 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 84 ms on localhost (1/1)
2015-11-03 18:03:26,934 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-03 18:03:26,934 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at Join.scala:26) finished in 0.412 s
2015-11-03 18:03:26,934 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:03:26,935 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 18:03:26,935 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 18:03:26,935 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:03:26,936 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List()
2015-11-03 18:03:26,940 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[9] at map at Join.scala:36), which is now runnable
2015-11-03 18:03:26,949 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3048) called with curMem=244362, maxMem=505361203
2015-11-03 18:03:26,950 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.0 KB, free 481.7 MB)
2015-11-03 18:03:26,960 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1646) called with curMem=247410, maxMem=505361203
2015-11-03 18:03:26,961 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1646.0 B, free 481.7 MB)
2015-11-03 18:03:26,966 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:53178 (size: 1646.0 B, free: 481.9 MB)
2015-11-03 18:03:26,970 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-03 18:03:26,972 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at map at Join.scala:36)
2015-11-03 18:03:26,973 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks
2015-11-03 18:03:26,984 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:03:26,988 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2015-11-03 18:03:27,018 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:03:27,021 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 8 ms
2015-11-03 18:03:27,047 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:03:27,047 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:03:27,638 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 51936 bytes result sent to driver
2015-11-03 18:03:27,661 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 680 ms on localhost (1/1)
2015-11-03 18:03:27,661 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-03 18:03:27,675 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (collect at Join.scala:38) finished in 0.701 s
2015-11-03 18:03:27,685 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: collect at Join.scala:38, took 1.308600 s
2015-11-03 18:03:28,192 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(64288) called with curMem=249056, maxMem=505361203
2015-11-03 18:03:28,193 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 62.8 KB, free 481.7 MB)
2015-11-03 18:03:28,247 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(14119) called with curMem=313344, maxMem=505361203
2015-11-03 18:03:28,270 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.8 KB, free 481.6 MB)
2015-11-03 18:03:28,272 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:53178 (size: 13.8 KB, free: 481.9 MB)
2015-11-03 18:03:28,273 INFO  org.apache.spark.SparkContext - Created broadcast 5 from textFile at Join.scala:41
2015-11-03 18:03:28,286 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(148024) called with curMem=327463, maxMem=505361203
2015-11-03 18:03:28,287 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 144.6 KB, free 481.5 MB)
2015-11-03 18:03:28,339 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(14119) called with curMem=475487, maxMem=505361203
2015-11-03 18:03:28,340 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 13.8 KB, free 481.5 MB)
2015-11-03 18:03:28,344 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on localhost:53178 (size: 13.8 KB, free: 481.9 MB)
2015-11-03 18:03:28,346 INFO  org.apache.spark.SparkContext - Created broadcast 6 from textFile at Join.scala:52
2015-11-03 18:03:28,573 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-03 18:03:28,578 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on localhost:53178 in memory (size: 1646.0 B, free: 481.9 MB)
2015-11-03 18:03:28,585 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 3
2015-11-03 18:03:28,587 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on localhost:53178 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:03:28,588 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 2
2015-11-03 18:03:28,589 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-03 18:03:28,589 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-03 18:03:28,589 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-03 18:03:28,589 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-03 18:03:28,590 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-03 18:03:28,590 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-03 18:03:28,590 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-03 18:03:28,590 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-03 18:03:28,591 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-03 18:03:28,591 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-03 18:03:28,591 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-03 18:03:28,591 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-03 18:03:28,591 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on localhost:53178 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:03:28,592 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-03 18:03:28,592 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-03 18:03:28,592 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-03 18:03:28,592 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-03 18:03:28,593 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-03 18:03:28,593 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-03 18:03:28,593 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-03 18:03:28,593 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-03 18:03:28,594 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-03 18:03:28,594 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-03 18:03:28,594 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-03 18:03:28,594 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-03 18:03:28,594 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-03 18:03:28,598 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 1
2015-11-03 18:03:28,647 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-03 18:03:28,652 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-03 18:03:28,723 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-03 18:03:28,763 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-03 18:03:28,764 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-03 18:03:28,765 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-03 18:03:28,768 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-03 18:03:28,769 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-03 18:03:28,770 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-03 18:03:28,770 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-830cea1c-47ef-48d1-91f9-daf332d57307
2015-11-03 18:04:02,404 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 18:04:03,909 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-03 18:04:03,910 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-03 18:04:03,910 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-03 18:04:04,725 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-03 18:04:04,785 INFO  Remoting - Starting remoting
2015-11-03 18:04:04,990 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:53293]
2015-11-03 18:04:04,996 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53293.
2015-11-03 18:04:05,016 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-03 18:04:05,034 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-03 18:04:05,056 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-e8fb7b58-5ac2-4deb-991c-b3b1d01eda84
2015-11-03 18:04:05,071 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-03 18:04:05,152 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-65c3ccff-6333-47ca-a665-30e4b7ee609c\httpd-a82479cf-9673-4306-a931-5c4a1d699821
2015-11-03 18:04:05,157 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-03 18:04:05,235 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 18:04:05,257 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:53294
2015-11-03 18:04:05,258 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 53294.
2015-11-03 18:04:05,280 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-03 18:04:05,464 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 18:04:05,481 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-03 18:04:05,481 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-03 18:04:05,484 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-03 18:04:05,598 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-03 18:04:05,617 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-03 18:04:06,010 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53313.
2015-11-03 18:04:06,011 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 53313
2015-11-03 18:04:06,012 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-03 18:04:06,015 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:53313 with 481.9 MB RAM, BlockManagerId(driver, localhost, 53313)
2015-11-03 18:04:06,017 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-03 18:04:06,665 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-03 18:04:06,667 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-03 18:04:06,712 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-03 18:04:06,712 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-03 18:04:06,716 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:53313 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:04:06,722 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at Join.scala:16
2015-11-03 18:04:06,817 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=116545, maxMem=505361203
2015-11-03 18:04:06,817 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 104.0 KB, free 481.7 MB)
2015-11-03 18:04:06,840 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=223065, maxMem=505361203
2015-11-03 18:04:06,841 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.7 MB)
2015-11-03 18:04:06,842 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:53313 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:04:06,844 INFO  org.apache.spark.SparkContext - Created broadcast 1 from textFile at Join.scala:25
2015-11-03 18:04:08,230 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:105%31, but we couldn't find any external IP address!
2015-11-03 18:04:08,722 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:04:08,772 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:04:08,875 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-03 18:04:08,875 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-03 18:04:08,875 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-03 18:04:08,875 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-03 18:04:08,876 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-03 18:04:09,066 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at Join.scala:37
2015-11-03 18:04:09,099 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 2 (map at Join.scala:17)
2015-11-03 18:04:09,100 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 5 (map at Join.scala:26)
2015-11-03 18:04:09,103 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsTextFile at Join.scala:37) with 1 output partitions
2015-11-03 18:04:09,104 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2(saveAsTextFile at Join.scala:37)
2015-11-03 18:04:09,104 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 18:04:09,107 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 18:04:09,122 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at Join.scala:17), which has no missing parents
2015-11-03 18:04:09,149 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3528) called with curMem=233130, maxMem=505361203
2015-11-03 18:04:09,150 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 3.4 KB, free 481.7 MB)
2015-11-03 18:04:09,156 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2075) called with curMem=236658, maxMem=505361203
2015-11-03 18:04:09,157 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.7 MB)
2015-11-03 18:04:09,159 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:53313 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:04:09,160 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-03 18:04:09,164 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at Join.scala:17)
2015-11-03 18:04:09,166 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2015-11-03 18:04:09,177 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Join.scala:26), which has no missing parents
2015-11-03 18:04:09,181 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3544) called with curMem=238733, maxMem=505361203
2015-11-03 18:04:09,182 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 3.5 KB, free 481.7 MB)
2015-11-03 18:04:09,188 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2085) called with curMem=242277, maxMem=505361203
2015-11-03 18:04:09,189 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.7 MB)
2015-11-03 18:04:09,190 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:53313 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:04:09,191 INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-11-03 18:04:09,192 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Join.scala:26)
2015-11-03 18:04:09,192 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2015-11-03 18:04:09,209 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2160 bytes)
2015-11-03 18:04:09,219 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-03 18:04:09,250 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/Hotel.txt:0+337904
2015-11-03 18:04:09,502 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
2015-11-03 18:04:09,507 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 2172 bytes)
2015-11-03 18:04:09,508 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2015-11-03 18:04:09,515 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/hotel_id_position.txt:0+17841
2015-11-03 18:04:09,515 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 319 ms on localhost (1/1)
2015-11-03 18:04:09,517 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-03 18:04:09,521 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (map at Join.scala:17) finished in 0.344 s
2015-11-03 18:04:09,523 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:04:09,523 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set(ShuffleMapStage 1)
2015-11-03 18:04:09,524 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 18:04:09,525 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:04:09,529 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List(ShuffleMapStage 1)
2015-11-03 18:04:09,558 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 2253 bytes result sent to driver
2015-11-03 18:04:09,564 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 58 ms on localhost (1/1)
2015-11-03 18:04:09,564 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at Join.scala:26) finished in 0.351 s
2015-11-03 18:04:09,564 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:04:09,564 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-03 18:04:09,565 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 18:04:09,565 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 18:04:09,565 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:04:09,566 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List()
2015-11-03 18:04:09,568 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[10] at saveAsTextFile at Join.scala:37), which is now runnable
2015-11-03 18:04:09,635 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95992) called with curMem=244362, maxMem=505361203
2015-11-03 18:04:09,635 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 93.7 KB, free 481.6 MB)
2015-11-03 18:04:09,640 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31387) called with curMem=340354, maxMem=505361203
2015-11-03 18:04:09,641 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 30.7 KB, free 481.6 MB)
2015-11-03 18:04:09,643 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:53313 (size: 30.7 KB, free: 481.9 MB)
2015-11-03 18:04:09,644 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-03 18:04:09,645 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at saveAsTextFile at Join.scala:37)
2015-11-03 18:04:09,645 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks
2015-11-03 18:04:09,650 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:04:09,651 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2015-11-03 18:04:09,688 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-03 18:04:09,690 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-03 18:04:09,694 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-03 18:04:09,702 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-03 18:04:09,769 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:04:09,771 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 9 ms
2015-11-03 18:04:09,789 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:04:09,789 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:04:10,952 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031804_0002_m_000000_2' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/HotelInfo.txt/_temporary/0/task_201511031804_0002_m_000000
2015-11-03 18:04:10,953 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031804_0002_m_000000_2: Committed
2015-11-03 18:04:10,956 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1165 bytes result sent to driver
2015-11-03 18:04:10,961 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 1315 ms on localhost (1/1)
2015-11-03 18:04:10,961 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-03 18:04:10,962 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (saveAsTextFile at Join.scala:37) finished in 1.316 s
2015-11-03 18:04:10,969 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsTextFile at Join.scala:37, took 1.901785 s
2015-11-03 18:04:11,009 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(64288) called with curMem=371741, maxMem=505361203
2015-11-03 18:04:11,009 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 62.8 KB, free 481.5 MB)
2015-11-03 18:04:11,104 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on localhost:53313 in memory (size: 30.7 KB, free: 481.9 MB)
2015-11-03 18:04:11,109 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 3
2015-11-03 18:04:11,111 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on localhost:53313 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:04:11,112 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(14119) called with curMem=303021, maxMem=505361203
2015-11-03 18:04:11,112 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 2
2015-11-03 18:04:11,112 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.8 KB, free 481.6 MB)
2015-11-03 18:04:11,187 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:53313 (size: 13.8 KB, free: 481.9 MB)
2015-11-03 18:04:11,188 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on localhost:53313 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:04:11,189 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 1
2015-11-03 18:04:11,190 INFO  org.apache.spark.SparkContext - Created broadcast 5 from textFile at Join.scala:41
2015-11-03 18:04:11,211 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(148024) called with curMem=311537, maxMem=505361203
2015-11-03 18:04:11,212 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 144.6 KB, free 481.5 MB)
2015-11-03 18:04:11,257 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(14119) called with curMem=459561, maxMem=505361203
2015-11-03 18:04:11,258 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 13.8 KB, free 481.5 MB)
2015-11-03 18:04:11,262 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on localhost:53313 (size: 13.8 KB, free: 481.9 MB)
2015-11-03 18:04:11,266 INFO  org.apache.spark.SparkContext - Created broadcast 6 from textFile at Join.scala:52
2015-11-03 18:04:11,294 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-03 18:04:11,309 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-03 18:04:11,310 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-03 18:04:11,310 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-03 18:04:11,310 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-03 18:04:11,310 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-03 18:04:11,310 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-03 18:04:11,310 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-03 18:04:11,310 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-03 18:04:11,311 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-03 18:04:11,311 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-03 18:04:11,311 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-03 18:04:11,311 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-03 18:04:11,311 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-03 18:04:11,311 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-03 18:04:11,311 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-03 18:04:11,312 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-03 18:04:11,312 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-03 18:04:11,312 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-03 18:04:11,312 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-03 18:04:11,312 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-03 18:04:11,312 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-03 18:04:11,312 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-03 18:04:11,313 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-03 18:04:11,313 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-03 18:04:11,313 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-03 18:04:11,365 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-03 18:04:11,370 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-03 18:04:11,437 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-03 18:04:11,537 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-03 18:04:11,539 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-03 18:04:11,545 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-03 18:04:11,554 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-03 18:04:11,557 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-03 18:04:11,559 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-03 18:04:11,560 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-65c3ccff-6333-47ca-a665-30e4b7ee609c
2015-11-03 18:10:38,595 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 18:10:39,946 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-03 18:10:39,947 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-03 18:10:39,948 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-03 18:10:42,738 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-03 18:10:42,994 INFO  Remoting - Starting remoting
2015-11-03 18:10:43,354 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:54309]
2015-11-03 18:10:43,361 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54309.
2015-11-03 18:10:43,908 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-03 18:10:44,040 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-03 18:10:44,205 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-70f45013-a1ee-4f32-8849-5bbe74d7c6f4
2015-11-03 18:10:44,418 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-03 18:10:44,678 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-35898ecf-c2ba-45f1-9eaa-e963336eb1ed\httpd-673c2373-fec6-4e5f-880e-dcb4fef51391
2015-11-03 18:10:44,793 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-03 18:10:45,104 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 18:10:45,170 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:54313
2015-11-03 18:10:45,171 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 54313.
2015-11-03 18:10:45,255 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-03 18:10:46,092 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 18:10:46,127 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-03 18:10:46,128 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-03 18:10:46,130 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-03 18:10:46,727 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-03 18:10:46,797 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-03 18:10:47,303 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54340.
2015-11-03 18:10:47,304 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 54340
2015-11-03 18:10:47,337 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-03 18:10:47,356 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:54340 with 481.9 MB RAM, BlockManagerId(driver, localhost, 54340)
2015-11-03 18:10:47,400 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-03 18:10:49,383 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-03 18:10:49,386 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-03 18:10:49,592 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-03 18:10:49,593 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-03 18:10:49,598 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:54340 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:10:49,683 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at Join.scala:17
2015-11-03 18:10:50,095 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=116545, maxMem=505361203
2015-11-03 18:10:50,096 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 104.0 KB, free 481.7 MB)
2015-11-03 18:10:50,114 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=223065, maxMem=505361203
2015-11-03 18:10:50,115 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.7 MB)
2015-11-03 18:10:50,116 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:54340 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:10:50,118 INFO  org.apache.spark.SparkContext - Created broadcast 1 from textFile at Join.scala:27
2015-11-03 18:10:50,168 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=233130, maxMem=505361203
2015-11-03 18:10:50,169 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 104.0 KB, free 481.6 MB)
2015-11-03 18:10:50,192 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=339650, maxMem=505361203
2015-11-03 18:10:50,193 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.6 MB)
2015-11-03 18:10:50,195 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:54340 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:10:50,196 INFO  org.apache.spark.SparkContext - Created broadcast 2 from textFile at Join.scala:43
2015-11-03 18:10:50,228 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=349715, maxMem=505361203
2015-11-03 18:10:50,229 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 104.0 KB, free 481.5 MB)
2015-11-03 18:10:50,250 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=456235, maxMem=505361203
2015-11-03 18:10:50,250 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.5 MB)
2015-11-03 18:10:50,251 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:54340 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:10:50,252 INFO  org.apache.spark.SparkContext - Created broadcast 3 from textFile at Join.scala:54
2015-11-03 18:10:51,746 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:105%31, but we couldn't find any external IP address!
2015-11-03 18:10:52,274 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:10:52,363 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:10:52,596 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-03 18:10:52,597 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-03 18:10:52,597 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-03 18:10:52,597 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-03 18:10:52,597 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-03 18:10:53,036 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at Join.scala:66
2015-11-03 18:10:53,146 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 8 (map at Join.scala:44)
2015-11-03 18:10:53,164 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 11 (map at Join.scala:55)
2015-11-03 18:10:53,177 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsTextFile at Join.scala:66) with 1 output partitions
2015-11-03 18:10:53,177 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2(saveAsTextFile at Join.scala:66)
2015-11-03 18:10:53,179 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 18:10:53,191 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 18:10:53,261 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[8] at map at Join.scala:44), which has no missing parents
2015-11-03 18:10:53,397 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3536) called with curMem=466300, maxMem=505361203
2015-11-03 18:10:53,398 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.5 KB, free 481.5 MB)
2015-11-03 18:10:53,401 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2076) called with curMem=469836, maxMem=505361203
2015-11-03 18:10:53,401 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.5 MB)
2015-11-03 18:10:53,403 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:54340 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:10:53,404 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-03 18:10:53,435 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[8] at map at Join.scala:44)
2015-11-03 18:10:53,454 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2015-11-03 18:10:53,565 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at map at Join.scala:55), which has no missing parents
2015-11-03 18:10:53,584 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3536) called with curMem=471912, maxMem=505361203
2015-11-03 18:10:53,585 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 3.5 KB, free 481.5 MB)
2015-11-03 18:10:53,588 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2087) called with curMem=475448, maxMem=505361203
2015-11-03 18:10:53,589 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.5 MB)
2015-11-03 18:10:53,591 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:54340 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:10:53,594 INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-11-03 18:10:53,595 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at map at Join.scala:55)
2015-11-03 18:10:53,595 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2015-11-03 18:10:53,966 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2165 bytes)
2015-11-03 18:10:55,666 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-03 18:10:59,860 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/ratingFile.txt:0+934
2015-11-03 18:11:00,875 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
2015-11-03 18:11:00,881 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 2166 bytes)
2015-11-03 18:11:00,883 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2015-11-03 18:11:00,913 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 7106 ms on localhost (1/1)
2015-11-03 18:11:00,914 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-03 18:11:00,917 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/commentFile.txt:0+489
2015-11-03 18:11:01,026 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 2253 bytes result sent to driver
2015-11-03 18:11:01,030 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 150 ms on localhost (1/1)
2015-11-03 18:11:01,030 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-03 18:11:01,113 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (map at Join.scala:44) finished in 7.548 s
2015-11-03 18:11:01,137 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:11:01,153 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set(ShuffleMapStage 1)
2015-11-03 18:11:01,154 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 18:11:01,183 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:11:01,209 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List(ShuffleMapStage 1)
2015-11-03 18:11:01,306 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at Join.scala:55) finished in 6.902 s
2015-11-03 18:11:01,306 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:11:01,306 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 18:11:01,306 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 18:11:01,306 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:11:01,306 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List()
2015-11-03 18:11:01,400 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[16] at saveAsTextFile at Join.scala:66), which is now runnable
2015-11-03 18:11:01,449 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95992) called with curMem=477535, maxMem=505361203
2015-11-03 18:11:01,450 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 93.7 KB, free 481.4 MB)
2015-11-03 18:11:01,452 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31390) called with curMem=573527, maxMem=505361203
2015-11-03 18:11:01,452 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 30.7 KB, free 481.4 MB)
2015-11-03 18:11:01,454 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on localhost:54340 (size: 30.7 KB, free: 481.9 MB)
2015-11-03 18:11:01,455 INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:861
2015-11-03 18:11:01,481 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at saveAsTextFile at Join.scala:66)
2015-11-03 18:11:01,481 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks
2015-11-03 18:11:01,484 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:11:01,484 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2015-11-03 18:11:01,571 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-03 18:11:01,572 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-03 18:11:01,574 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-03 18:11:01,579 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-03 18:11:01,913 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:11:01,963 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 73 ms
2015-11-03 18:11:02,050 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:11:02,051 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:11:02,571 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031810_0002_m_000000_2' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/hotelUserInfo/_temporary/0/task_201511031810_0002_m_000000
2015-11-03 18:11:02,573 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031810_0002_m_000000_2: Committed
2015-11-03 18:11:02,579 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1165 bytes result sent to driver
2015-11-03 18:11:02,587 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 1104 ms on localhost (1/1)
2015-11-03 18:11:02,588 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-03 18:11:02,606 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (saveAsTextFile at Join.scala:66) finished in 1.124 s
2015-11-03 18:11:02,631 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsTextFile at Join.scala:66, took 9.593830 s
2015-11-03 18:11:02,689 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-03 18:11:02,745 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-03 18:11:02,746 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-03 18:11:02,746 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-03 18:11:02,746 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-03 18:11:02,747 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-03 18:11:02,747 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-03 18:11:02,747 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-03 18:11:02,748 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-03 18:11:02,748 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-03 18:11:02,748 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-03 18:11:02,748 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-03 18:11:02,749 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-03 18:11:02,749 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-03 18:11:02,749 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-03 18:11:02,750 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-03 18:11:02,750 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-03 18:11:02,750 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-03 18:11:02,750 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-03 18:11:02,750 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-03 18:11:02,751 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-03 18:11:02,751 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-03 18:11:02,751 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-03 18:11:02,752 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-03 18:11:02,752 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-03 18:11:02,752 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-03 18:11:02,858 WARN  org.spark-project.jetty.util.thread.QueuedThreadPool - 5 threads could not be stopped
2015-11-03 18:11:02,860 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-03 18:11:02,885 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-03 18:11:03,001 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-03 18:11:03,102 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-03 18:11:03,206 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-03 18:11:03,295 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-03 18:11:03,313 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-03 18:11:03,314 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-03 18:11:03,343 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-03 18:11:03,344 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-35898ecf-c2ba-45f1-9eaa-e963336eb1ed
2015-11-03 18:34:47,659 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 18:34:49,470 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-03 18:34:49,489 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-03 18:34:49,490 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-03 18:34:52,700 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-03 18:34:52,986 INFO  Remoting - Starting remoting
2015-11-03 18:34:53,308 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:58148]
2015-11-03 18:34:53,316 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 58148.
2015-11-03 18:34:53,532 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-03 18:34:53,802 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-03 18:34:53,980 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-7dca7121-305e-4623-ac7d-cbb312545f11
2015-11-03 18:34:54,212 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-03 18:34:54,481 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-b22227de-2978-41d6-96a3-63d00507a217\httpd-55109e91-0fa6-4791-a28c-ae0a442ba372
2015-11-03 18:34:54,642 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-03 18:34:55,018 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 18:34:55,098 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:58157
2015-11-03 18:34:55,098 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 58157.
2015-11-03 18:34:55,183 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-03 18:34:56,045 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 18:34:56,081 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-03 18:34:56,081 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-03 18:34:56,099 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-03 18:34:56,719 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-03 18:34:56,752 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-03 18:34:57,270 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58182.
2015-11-03 18:34:57,270 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 58182
2015-11-03 18:34:57,309 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-03 18:34:57,330 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:58182 with 481.9 MB RAM, BlockManagerId(driver, localhost, 58182)
2015-11-03 18:34:57,367 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-03 18:35:00,312 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-03 18:35:00,336 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-03 18:35:00,542 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-03 18:35:00,542 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-03 18:35:00,547 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:58182 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:35:00,601 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at Join.scala:17
2015-11-03 18:35:00,926 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=116545, maxMem=505361203
2015-11-03 18:35:00,927 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 104.0 KB, free 481.7 MB)
2015-11-03 18:35:00,946 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=223065, maxMem=505361203
2015-11-03 18:35:00,946 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.7 MB)
2015-11-03 18:35:00,947 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:58182 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:35:00,950 INFO  org.apache.spark.SparkContext - Created broadcast 1 from textFile at Join.scala:27
2015-11-03 18:35:01,007 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=233130, maxMem=505361203
2015-11-03 18:35:01,008 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 104.0 KB, free 481.6 MB)
2015-11-03 18:35:01,028 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=339650, maxMem=505361203
2015-11-03 18:35:01,028 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.6 MB)
2015-11-03 18:35:01,030 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:58182 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:35:01,032 INFO  org.apache.spark.SparkContext - Created broadcast 2 from textFile at Join.scala:37
2015-11-03 18:35:01,063 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=349715, maxMem=505361203
2015-11-03 18:35:01,064 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 104.0 KB, free 481.5 MB)
2015-11-03 18:35:01,085 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=456235, maxMem=505361203
2015-11-03 18:35:01,086 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.5 MB)
2015-11-03 18:35:01,086 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:58182 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:35:01,088 INFO  org.apache.spark.SparkContext - Created broadcast 3 from textFile at Join.scala:48
2015-11-03 18:35:02,581 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:105%31, but we couldn't find any external IP address!
2015-11-03 18:35:03,213 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:35:03,306 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:35:03,524 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-03 18:35:03,524 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-03 18:35:03,524 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-03 18:35:03,524 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-03 18:35:03,524 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-03 18:35:03,989 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at Join.scala:65
2015-11-03 18:35:04,197 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 2 (map at Join.scala:18)
2015-11-03 18:35:04,215 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 5 (map at Join.scala:28)
2015-11-03 18:35:04,237 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsTextFile at Join.scala:65) with 1 output partitions
2015-11-03 18:35:04,239 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2(saveAsTextFile at Join.scala:65)
2015-11-03 18:35:04,240 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 18:35:04,251 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 18:35:04,323 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at Join.scala:18), which has no missing parents
2015-11-03 18:35:04,496 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3528) called with curMem=466300, maxMem=505361203
2015-11-03 18:35:04,542 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.4 KB, free 481.5 MB)
2015-11-03 18:35:04,545 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2075) called with curMem=469828, maxMem=505361203
2015-11-03 18:35:04,546 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.5 MB)
2015-11-03 18:35:04,548 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:58182 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:35:04,549 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-03 18:35:04,618 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at Join.scala:18)
2015-11-03 18:35:04,638 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2015-11-03 18:35:05,866 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Join.scala:28), which has no missing parents
2015-11-03 18:35:05,874 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3544) called with curMem=471903, maxMem=505361203
2015-11-03 18:35:05,875 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 3.5 KB, free 481.5 MB)
2015-11-03 18:35:05,879 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2085) called with curMem=475447, maxMem=505361203
2015-11-03 18:35:05,880 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.5 MB)
2015-11-03 18:35:05,885 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:58182 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:35:05,891 INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-11-03 18:35:05,891 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Join.scala:28)
2015-11-03 18:35:05,891 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2015-11-03 18:35:06,588 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2160 bytes)
2015-11-03 18:35:07,015 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-03 18:35:10,233 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/Hotel.txt:0+337904
2015-11-03 18:35:12,441 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
2015-11-03 18:35:12,446 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 2172 bytes)
2015-11-03 18:35:12,448 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2015-11-03 18:35:12,472 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 6109 ms on localhost (1/1)
2015-11-03 18:35:12,475 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/hotel_id_position.txt:0+17841
2015-11-03 18:35:12,485 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-03 18:35:12,579 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (map at Join.scala:18) finished in 6.709 s
2015-11-03 18:35:12,583 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 2253 bytes result sent to driver
2015-11-03 18:35:12,586 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 141 ms on localhost (1/1)
2015-11-03 18:35:12,586 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-03 18:35:12,591 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:35:12,592 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set(ShuffleMapStage 1)
2015-11-03 18:35:12,592 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 18:35:12,592 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:35:12,651 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List(ShuffleMapStage 1)
2015-11-03 18:35:12,677 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at Join.scala:28) finished in 5.934 s
2015-11-03 18:35:12,678 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:35:12,678 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 18:35:12,678 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 18:35:12,678 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:35:12,679 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List()
2015-11-03 18:35:12,716 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[16] at saveAsTextFile at Join.scala:65), which is now runnable
2015-11-03 18:35:12,791 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95976) called with curMem=477532, maxMem=505361203
2015-11-03 18:35:12,791 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 93.7 KB, free 481.4 MB)
2015-11-03 18:35:12,809 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31373) called with curMem=573508, maxMem=505361203
2015-11-03 18:35:12,809 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 30.6 KB, free 481.4 MB)
2015-11-03 18:35:12,810 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on localhost:58182 (size: 30.6 KB, free: 481.9 MB)
2015-11-03 18:35:12,811 INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:861
2015-11-03 18:35:12,821 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at saveAsTextFile at Join.scala:65)
2015-11-03 18:35:12,822 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks
2015-11-03 18:35:12,825 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:35:12,825 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2015-11-03 18:35:12,851 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-03 18:35:12,852 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-03 18:35:12,854 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-03 18:35:12,858 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-03 18:35:12,970 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:35:12,979 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 19 ms
2015-11-03 18:35:13,018 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:35:13,018 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:35:13,379 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on localhost:58182 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:35:13,391 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on localhost:58182 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:35:13,917 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031835_0002_m_000000_2' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/HotelInfo/_temporary/0/task_201511031835_0002_m_000000
2015-11-03 18:35:13,918 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031835_0002_m_000000_2: Committed
2015-11-03 18:35:13,920 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1165 bytes result sent to driver
2015-11-03 18:35:13,924 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 1101 ms on localhost (1/1)
2015-11-03 18:35:13,924 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-03 18:35:13,934 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (saveAsTextFile at Join.scala:65) finished in 1.112 s
2015-11-03 18:35:13,947 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsTextFile at Join.scala:65, took 9.956837 s
2015-11-03 18:35:14,031 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:35:14,050 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:35:14,191 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at Join.scala:72
2015-11-03 18:35:14,193 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 8 (map at Join.scala:38)
2015-11-03 18:35:14,194 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 11 (map at Join.scala:49)
2015-11-03 18:35:14,194 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (saveAsTextFile at Join.scala:72) with 1 output partitions
2015-11-03 18:35:14,195 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 5(saveAsTextFile at Join.scala:72)
2015-11-03 18:35:14,195 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 3, ShuffleMapStage 4)
2015-11-03 18:35:14,195 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 3, ShuffleMapStage 4)
2015-11-03 18:35:14,196 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at map at Join.scala:38), which has no missing parents
2015-11-03 18:35:14,199 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3536) called with curMem=593649, maxMem=505361203
2015-11-03 18:35:14,199 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 3.5 KB, free 481.4 MB)
2015-11-03 18:35:14,202 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2075) called with curMem=597185, maxMem=505361203
2015-11-03 18:35:14,203 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.4 MB)
2015-11-03 18:35:14,205 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on localhost:58182 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:35:14,206 INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:861
2015-11-03 18:35:14,206 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at map at Join.scala:38)
2015-11-03 18:35:14,206 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks
2015-11-03 18:35:14,207 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 4 (MapPartitionsRDD[11] at map at Join.scala:49), which has no missing parents
2015-11-03 18:35:14,208 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3, localhost, PROCESS_LOCAL, 2165 bytes)
2015-11-03 18:35:14,209 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2015-11-03 18:35:14,210 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3536) called with curMem=599260, maxMem=505361203
2015-11-03 18:35:14,211 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 3.5 KB, free 481.4 MB)
2015-11-03 18:35:14,214 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/ratingFile.txt:0+934
2015-11-03 18:35:14,242 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2084) called with curMem=602796, maxMem=505361203
2015-11-03 18:35:14,243 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.4 MB)
2015-11-03 18:35:14,245 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on localhost:58182 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:35:14,246 INFO  org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:861
2015-11-03 18:35:14,246 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[11] at map at Join.scala:49)
2015-11-03 18:35:14,246 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks
2015-11-03 18:35:14,258 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2253 bytes result sent to driver
2015-11-03 18:35:14,260 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4, localhost, PROCESS_LOCAL, 2166 bytes)
2015-11-03 18:35:14,260 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2015-11-03 18:35:14,261 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 54 ms on localhost (1/1)
2015-11-03 18:35:14,261 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 3 (map at Join.scala:38) finished in 0.055 s
2015-11-03 18:35:14,262 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:35:14,262 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set(ShuffleMapStage 4)
2015-11-03 18:35:14,262 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 5)
2015-11-03 18:35:14,262 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:35:14,262 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-11-03 18:35:14,262 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 5: List(ShuffleMapStage 4)
2015-11-03 18:35:14,266 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/commentFile.txt:0+489
2015-11-03 18:35:14,275 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2253 bytes result sent to driver
2015-11-03 18:35:14,278 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 19 ms on localhost (1/1)
2015-11-03 18:35:14,278 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 4 (map at Join.scala:49) finished in 0.031 s
2015-11-03 18:35:14,278 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:35:14,278 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-11-03 18:35:14,278 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 18:35:14,278 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 5)
2015-11-03 18:35:14,278 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:35:14,279 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 5: List()
2015-11-03 18:35:14,279 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[21] at saveAsTextFile at Join.scala:72), which is now runnable
2015-11-03 18:35:14,330 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95968) called with curMem=604880, maxMem=505361203
2015-11-03 18:35:14,331 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 93.7 KB, free 481.3 MB)
2015-11-03 18:35:14,340 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31386) called with curMem=700848, maxMem=505361203
2015-11-03 18:35:14,341 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 30.7 KB, free 481.3 MB)
2015-11-03 18:35:14,344 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on localhost:58182 (size: 30.7 KB, free: 481.8 MB)
2015-11-03 18:35:14,345 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_7_piece0 on localhost:58182 in memory (size: 2.0 KB, free: 481.8 MB)
2015-11-03 18:35:14,345 INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:861
2015-11-03 18:35:14,345 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at saveAsTextFile at Join.scala:72)
2015-11-03 18:35:14,346 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks
2015-11-03 18:35:14,348 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:35:14,354 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2015-11-03 18:35:14,408 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:35:14,408 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 18:35:14,408 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:35:14,409 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 18:35:14,456 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031835_0005_m_000000_5' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/UserInfo/_temporary/0/task_201511031835_0005_m_000000
2015-11-03 18:35:14,458 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031835_0005_m_000000_5: Committed
2015-11-03 18:35:14,459 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 1165 bytes result sent to driver
2015-11-03 18:35:14,461 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 113 ms on localhost (1/1)
2015-11-03 18:35:14,461 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-11-03 18:35:14,464 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 5 (saveAsTextFile at Join.scala:72) finished in 0.118 s
2015-11-03 18:35:14,465 INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: saveAsTextFile at Join.scala:72, took 0.273288 s
2015-11-03 18:35:14,487 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(64288) called with curMem=726623, maxMem=505361203
2015-11-03 18:35:14,488 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 62.8 KB, free 481.2 MB)
2015-11-03 18:35:14,523 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(14119) called with curMem=790911, maxMem=505361203
2015-11-03 18:35:14,523 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.8 KB, free 481.2 MB)
2015-11-03 18:35:14,525 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on localhost:58182 (size: 13.8 KB, free: 481.8 MB)
2015-11-03 18:35:14,527 INFO  org.apache.spark.SparkContext - Created broadcast 10 from textFile at Join.scala:75
2015-11-03 18:35:14,547 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(148024) called with curMem=805030, maxMem=505361203
2015-11-03 18:35:14,547 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 144.6 KB, free 481.0 MB)
2015-11-03 18:35:14,566 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(14119) called with curMem=953054, maxMem=505361203
2015-11-03 18:35:14,566 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 13.8 KB, free 481.0 MB)
2015-11-03 18:35:14,586 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on localhost:58182 (size: 13.8 KB, free: 481.8 MB)
2015-11-03 18:35:14,587 INFO  org.apache.spark.SparkContext - Created broadcast 11 from textFile at Join.scala:83
2015-11-03 18:35:15,378 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:35:15,481 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:35:15,567 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at Join.scala:94
2015-11-03 18:35:15,568 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 24 (map at Join.scala:75)
2015-11-03 18:35:15,569 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 27 (map at Join.scala:83)
2015-11-03 18:35:15,569 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 2 (saveAsTextFile at Join.scala:94) with 1 output partitions
2015-11-03 18:35:15,569 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 8(saveAsTextFile at Join.scala:94)
2015-11-03 18:35:15,569 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 6, ShuffleMapStage 7)
2015-11-03 18:35:15,570 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 6, ShuffleMapStage 7)
2015-11-03 18:35:15,570 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 6 (MapPartitionsRDD[24] at map at Join.scala:75), which has no missing parents
2015-11-03 18:35:15,572 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3536) called with curMem=967173, maxMem=505361203
2015-11-03 18:35:15,573 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 3.5 KB, free 481.0 MB)
2015-11-03 18:35:15,574 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2080) called with curMem=970709, maxMem=505361203
2015-11-03 18:35:15,575 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.0 MB)
2015-11-03 18:35:15,576 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on localhost:58182 (size: 2.0 KB, free: 481.8 MB)
2015-11-03 18:35:15,577 INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:861
2015-11-03 18:35:15,577 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[24] at map at Join.scala:75)
2015-11-03 18:35:15,577 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks
2015-11-03 18:35:15,578 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 7 (MapPartitionsRDD[27] at map at Join.scala:83), which has no missing parents
2015-11-03 18:35:15,578 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6, localhost, PROCESS_LOCAL, 2171 bytes)
2015-11-03 18:35:15,579 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2015-11-03 18:35:15,580 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3528) called with curMem=972789, maxMem=505361203
2015-11-03 18:35:15,580 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 3.4 KB, free 481.0 MB)
2015-11-03 18:35:15,585 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/HotelInfo/part-00000:0+46479
2015-11-03 18:35:15,610 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2080) called with curMem=976317, maxMem=505361203
2015-11-03 18:35:15,611 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.0 MB)
2015-11-03 18:35:15,635 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_13_piece0 in memory on localhost:58182 (size: 2.0 KB, free: 481.8 MB)
2015-11-03 18:35:15,636 INFO  org.apache.spark.SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:861
2015-11-03 18:35:15,636 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[27] at map at Join.scala:83)
2015-11-03 18:35:15,637 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks
2015-11-03 18:35:15,639 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 2253 bytes result sent to driver
2015-11-03 18:35:15,641 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7, localhost, PROCESS_LOCAL, 2170 bytes)
2015-11-03 18:35:15,641 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2015-11-03 18:35:15,643 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 6 (map at Join.scala:75) finished in 0.066 s
2015-11-03 18:35:15,644 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:35:15,644 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set(ShuffleMapStage 7)
2015-11-03 18:35:15,644 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 8)
2015-11-03 18:35:15,644 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:35:15,645 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 8: List(ShuffleMapStage 7)
2015-11-03 18:35:15,642 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 63 ms on localhost (1/1)
2015-11-03 18:35:15,647 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-11-03 18:35:15,651 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/UserInfo/part-00000:0+72
2015-11-03 18:35:15,662 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 2253 bytes result sent to driver
2015-11-03 18:35:15,665 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 25 ms on localhost (1/1)
2015-11-03 18:35:15,665 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2015-11-03 18:35:15,668 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 7 (map at Join.scala:83) finished in 0.028 s
2015-11-03 18:35:15,668 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:35:15,668 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 18:35:15,668 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 8)
2015-11-03 18:35:15,668 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:35:15,669 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 8: List()
2015-11-03 18:35:15,670 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[32] at saveAsTextFile at Join.scala:94), which is now runnable
2015-11-03 18:35:15,707 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95992) called with curMem=978397, maxMem=505361203
2015-11-03 18:35:15,707 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_14 stored as values in memory (estimated size 93.7 KB, free 480.9 MB)
2015-11-03 18:35:15,735 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31407) called with curMem=1074389, maxMem=505361203
2015-11-03 18:35:15,736 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 30.7 KB, free 480.9 MB)
2015-11-03 18:35:15,737 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_14_piece0 in memory on localhost:58182 (size: 30.7 KB, free: 481.8 MB)
2015-11-03 18:35:15,737 INFO  org.apache.spark.SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:861
2015-11-03 18:35:15,737 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_12_piece0 on localhost:58182 in memory (size: 2.0 KB, free: 481.8 MB)
2015-11-03 18:35:15,738 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[32] at saveAsTextFile at Join.scala:94)
2015-11-03 18:35:15,738 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks
2015-11-03 18:35:15,739 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:35:15,739 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2015-11-03 18:35:15,740 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_9_piece0 on localhost:58182 in memory (size: 30.7 KB, free: 481.8 MB)
2015-11-03 18:35:15,786 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:35:15,787 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 18:35:15,788 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:35:15,788 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:35:15,865 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031835_0008_m_000000_8' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/HotelUserInfo/_temporary/0/task_201511031835_0008_m_000000
2015-11-03 18:35:15,865 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031835_0008_m_000000_8: Committed
2015-11-03 18:35:15,866 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1165 bytes result sent to driver
2015-11-03 18:35:15,867 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 127 ms on localhost (1/1)
2015-11-03 18:35:15,867 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 8 (saveAsTextFile at Join.scala:94) finished in 0.129 s
2015-11-03 18:35:15,867 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2015-11-03 18:35:15,867 INFO  org.apache.spark.scheduler.DAGScheduler - Job 2 finished: saveAsTextFile at Join.scala:94, took 0.299681 s
2015-11-03 18:35:15,890 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-03 18:35:15,928 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-03 18:35:15,929 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-03 18:35:15,929 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-03 18:35:15,929 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-03 18:35:15,930 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-03 18:35:15,930 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-03 18:35:15,930 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-03 18:35:15,930 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-03 18:35:15,931 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-03 18:35:15,931 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-03 18:35:15,931 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-03 18:35:15,931 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-03 18:35:15,932 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-03 18:35:15,932 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-03 18:35:15,932 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-03 18:35:15,932 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-03 18:35:15,932 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-03 18:35:15,933 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-03 18:35:15,933 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-03 18:35:15,933 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-03 18:35:15,933 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-03 18:35:15,934 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-03 18:35:15,934 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-03 18:35:15,934 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-03 18:35:15,934 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-03 18:35:16,105 WARN  org.spark-project.jetty.util.thread.QueuedThreadPool - 5 threads could not be stopped
2015-11-03 18:35:16,106 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-03 18:35:16,110 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-03 18:35:16,213 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-03 18:35:16,315 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-03 18:35:16,333 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-03 18:35:16,334 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-03 18:35:16,356 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-03 18:35:16,368 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-03 18:35:16,381 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-03 18:35:16,383 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-b22227de-2978-41d6-96a3-63d00507a217
2015-11-03 18:41:58,767 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 18:42:04,302 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-03 18:42:04,341 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-03 18:42:04,343 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-03 18:42:09,429 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-03 18:42:09,704 INFO  Remoting - Starting remoting
2015-11-03 18:42:09,956 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:59219]
2015-11-03 18:42:09,962 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 59219.
2015-11-03 18:42:10,213 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-03 18:42:10,286 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-03 18:42:10,396 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-5773504e-8c0b-44ad-b099-90901d10c380
2015-11-03 18:42:10,520 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-03 18:42:10,770 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-03bd38ad-7651-4156-92bd-dc482740cbd1\httpd-b919697e-eef5-476d-9225-285aaa4afe54
2015-11-03 18:42:10,885 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-03 18:42:11,214 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 18:42:11,284 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:59222
2015-11-03 18:42:11,284 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 59222.
2015-11-03 18:42:11,402 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-03 18:42:12,084 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 18:42:12,099 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-03 18:42:12,099 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-03 18:42:12,114 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-03 18:42:12,583 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-03 18:42:12,621 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-03 18:42:13,062 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59245.
2015-11-03 18:42:13,063 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 59245
2015-11-03 18:42:13,083 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-03 18:42:13,106 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:59245 with 481.9 MB RAM, BlockManagerId(driver, localhost, 59245)
2015-11-03 18:42:13,128 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-03 18:42:15,063 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-03 18:42:15,089 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-03 18:42:15,321 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-03 18:42:15,321 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-03 18:42:15,325 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:59245 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:42:15,368 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at Join.scala:17
2015-11-03 18:42:15,741 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=116545, maxMem=505361203
2015-11-03 18:42:15,742 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 104.0 KB, free 481.7 MB)
2015-11-03 18:42:15,761 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=223065, maxMem=505361203
2015-11-03 18:42:15,761 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.7 MB)
2015-11-03 18:42:15,762 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:59245 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:42:15,764 INFO  org.apache.spark.SparkContext - Created broadcast 1 from textFile at Join.scala:27
2015-11-03 18:42:15,808 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=233130, maxMem=505361203
2015-11-03 18:42:15,809 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 104.0 KB, free 481.6 MB)
2015-11-03 18:42:15,830 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=339650, maxMem=505361203
2015-11-03 18:42:15,830 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.6 MB)
2015-11-03 18:42:15,832 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:59245 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:42:15,834 INFO  org.apache.spark.SparkContext - Created broadcast 2 from textFile at Join.scala:37
2015-11-03 18:42:15,869 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=349715, maxMem=505361203
2015-11-03 18:42:15,869 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 104.0 KB, free 481.5 MB)
2015-11-03 18:42:15,891 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=456235, maxMem=505361203
2015-11-03 18:42:15,891 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.5 MB)
2015-11-03 18:42:15,892 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:59245 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 18:42:15,894 INFO  org.apache.spark.SparkContext - Created broadcast 3 from textFile at Join.scala:48
2015-11-03 18:42:17,330 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:105%31, but we couldn't find any external IP address!
2015-11-03 18:42:17,855 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:42:17,915 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:42:18,153 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-03 18:42:18,153 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-03 18:42:18,153 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-03 18:42:18,153 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-03 18:42:18,153 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-03 18:42:18,510 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at Join.scala:65
2015-11-03 18:42:18,598 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 2 (map at Join.scala:18)
2015-11-03 18:42:18,600 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 5 (map at Join.scala:28)
2015-11-03 18:42:18,623 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsTextFile at Join.scala:65) with 1 output partitions
2015-11-03 18:42:18,624 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2(saveAsTextFile at Join.scala:65)
2015-11-03 18:42:18,625 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 18:42:18,636 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 18:42:18,673 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at Join.scala:18), which has no missing parents
2015-11-03 18:42:18,769 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3544) called with curMem=466300, maxMem=505361203
2015-11-03 18:42:18,771 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.5 KB, free 481.5 MB)
2015-11-03 18:42:18,777 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2091) called with curMem=469844, maxMem=505361203
2015-11-03 18:42:18,778 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.5 MB)
2015-11-03 18:42:18,782 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:59245 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:42:18,784 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-03 18:42:18,811 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at Join.scala:18)
2015-11-03 18:42:18,824 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2015-11-03 18:42:18,889 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Join.scala:28), which has no missing parents
2015-11-03 18:42:18,894 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3552) called with curMem=471935, maxMem=505361203
2015-11-03 18:42:18,894 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 3.5 KB, free 481.5 MB)
2015-11-03 18:42:18,896 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2098) called with curMem=475487, maxMem=505361203
2015-11-03 18:42:18,897 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.5 MB)
2015-11-03 18:42:18,910 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:59245 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:42:18,911 INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-11-03 18:42:18,911 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Join.scala:28)
2015-11-03 18:42:18,911 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2015-11-03 18:42:18,968 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2173 bytes)
2015-11-03 18:42:19,013 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-03 18:42:19,150 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/Hotel.txt:0+337904
2015-11-03 18:42:19,394 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
2015-11-03 18:42:19,398 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 18:42:19,398 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2015-11-03 18:42:19,403 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 477 ms on localhost (1/1)
2015-11-03 18:42:19,405 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-03 18:42:19,405 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/hotel_id_position.txt:0+17841
2015-11-03 18:42:19,408 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (map at Join.scala:18) finished in 0.519 s
2015-11-03 18:42:19,408 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:42:19,409 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set(ShuffleMapStage 1)
2015-11-03 18:42:19,410 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 18:42:19,410 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:42:19,413 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List(ShuffleMapStage 1)
2015-11-03 18:42:19,438 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 2253 bytes result sent to driver
2015-11-03 18:42:19,443 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 45 ms on localhost (1/1)
2015-11-03 18:42:19,443 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-03 18:42:19,444 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at Join.scala:28) finished in 0.471 s
2015-11-03 18:42:19,444 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:42:19,444 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 18:42:19,444 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 18:42:19,444 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:42:19,445 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List()
2015-11-03 18:42:19,447 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[16] at saveAsTextFile at Join.scala:65), which is now runnable
2015-11-03 18:42:19,496 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(96024) called with curMem=477585, maxMem=505361203
2015-11-03 18:42:19,497 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 93.8 KB, free 481.4 MB)
2015-11-03 18:42:19,498 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31394) called with curMem=573609, maxMem=505361203
2015-11-03 18:42:19,499 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 30.7 KB, free 481.4 MB)
2015-11-03 18:42:19,500 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on localhost:59245 (size: 30.7 KB, free: 481.9 MB)
2015-11-03 18:42:19,501 INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:861
2015-11-03 18:42:19,502 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at saveAsTextFile at Join.scala:65)
2015-11-03 18:42:19,502 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks
2015-11-03 18:42:19,505 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:42:19,505 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2015-11-03 18:42:19,529 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-03 18:42:19,530 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-03 18:42:19,533 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-03 18:42:19,538 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-03 18:42:19,572 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:42:19,574 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 5 ms
2015-11-03 18:42:19,586 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:42:19,586 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 18:42:20,132 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0002_m_000000_2' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelInfo/_temporary/0/task_201511031842_0002_m_000000
2015-11-03 18:42:20,133 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0002_m_000000_2: Committed
2015-11-03 18:42:20,136 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1165 bytes result sent to driver
2015-11-03 18:42:20,141 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 638 ms on localhost (1/1)
2015-11-03 18:42:20,142 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-03 18:42:20,142 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (saveAsTextFile at Join.scala:65) finished in 0.639 s
2015-11-03 18:42:20,147 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsTextFile at Join.scala:65, took 1.637598 s
2015-11-03 18:42:20,193 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:42:20,213 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:42:20,336 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at Join.scala:72
2015-11-03 18:42:20,337 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 8 (map at Join.scala:38)
2015-11-03 18:42:20,338 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 11 (map at Join.scala:49)
2015-11-03 18:42:20,338 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (saveAsTextFile at Join.scala:72) with 7 output partitions
2015-11-03 18:42:20,338 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 5(saveAsTextFile at Join.scala:72)
2015-11-03 18:42:20,338 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 3, ShuffleMapStage 4)
2015-11-03 18:42:20,339 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 3, ShuffleMapStage 4)
2015-11-03 18:42:20,340 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at map at Join.scala:38), which has no missing parents
2015-11-03 18:42:20,344 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3552) called with curMem=605003, maxMem=505361203
2015-11-03 18:42:20,344 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 3.5 KB, free 481.4 MB)
2015-11-03 18:42:20,382 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2094) called with curMem=608555, maxMem=505361203
2015-11-03 18:42:20,383 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.4 MB)
2015-11-03 18:42:20,394 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on localhost:59245 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:42:20,399 INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:861
2015-11-03 18:42:20,399 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at map at Join.scala:38)
2015-11-03 18:42:20,399 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks
2015-11-03 18:42:20,401 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 4 (MapPartitionsRDD[11] at map at Join.scala:49), which has no missing parents
2015-11-03 18:42:20,404 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 18:42:20,405 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2015-11-03 18:42:20,409 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3552) called with curMem=610649, maxMem=505361203
2015-11-03 18:42:20,410 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 3.5 KB, free 481.4 MB)
2015-11-03 18:42:20,412 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2104) called with curMem=614201, maxMem=505361203
2015-11-03 18:42:20,413 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000001.dat:0+15177529
2015-11-03 18:42:20,413 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.1 KB, free 481.4 MB)
2015-11-03 18:42:20,432 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on localhost:59245 (size: 2.1 KB, free: 481.9 MB)
2015-11-03 18:42:20,449 INFO  org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:861
2015-11-03 18:42:20,449 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 7 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[11] at map at Join.scala:49)
2015-11-03 18:42:20,449 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 7 tasks
2015-11-03 18:42:20,450 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on localhost:59245 in memory (size: 30.7 KB, free: 481.9 MB)
2015-11-03 18:42:20,465 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 3
2015-11-03 18:42:20,468 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on localhost:59245 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:42:20,471 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 2
2015-11-03 18:42:20,475 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on localhost:59245 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:42:20,485 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 1
2015-11-03 18:42:21,489 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2259 bytes result sent to driver
2015-11-03 18:42:21,491 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 18:42:21,491 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2015-11-03 18:42:21,492 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 1089 ms on localhost (1/1)
2015-11-03 18:42:21,492 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 3 (map at Join.scala:38) finished in 1.092 s
2015-11-03 18:42:21,492 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-11-03 18:42:21,492 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:42:21,493 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set(ShuffleMapStage 4)
2015-11-03 18:42:21,493 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 5)
2015-11-03 18:42:21,493 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:42:21,493 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 5: List(ShuffleMapStage 4)
2015-11-03 18:42:21,496 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:0+33554432
2015-11-03 18:42:21,991 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2259 bytes result sent to driver
2015-11-03 18:42:21,992 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 4.0 (TID 5, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 18:42:21,993 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 4.0 (TID 5)
2015-11-03 18:42:21,993 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 503 ms on localhost (1/7)
2015-11-03 18:42:21,997 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:33554432+33554432
2015-11-03 18:42:22,420 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 4.0 (TID 5). 2259 bytes result sent to driver
2015-11-03 18:42:22,421 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 4.0 (TID 6, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 18:42:22,422 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 4.0 (TID 6)
2015-11-03 18:42:22,423 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 4.0 (TID 5) in 431 ms on localhost (2/7)
2015-11-03 18:42:22,426 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:67108864+33554432
2015-11-03 18:42:22,812 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 4.0 (TID 6). 2259 bytes result sent to driver
2015-11-03 18:42:22,813 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 4.0 (TID 7, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 18:42:22,814 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 4.0 (TID 7)
2015-11-03 18:42:22,814 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 4.0 (TID 6) in 394 ms on localhost (3/7)
2015-11-03 18:42:22,818 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:100663296+33554432
2015-11-03 18:42:23,446 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 4.0 (TID 7). 2259 bytes result sent to driver
2015-11-03 18:42:23,447 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 4.0 (TID 8, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 18:42:23,448 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 4.0 (TID 8)
2015-11-03 18:42:23,449 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 4.0 (TID 7) in 636 ms on localhost (4/7)
2015-11-03 18:42:23,453 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:134217728+33554432
2015-11-03 18:42:24,190 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 4.0 (TID 8). 2259 bytes result sent to driver
2015-11-03 18:42:24,192 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 4.0 (TID 9, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 18:42:24,193 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 4.0 (TID 8) in 746 ms on localhost (5/7)
2015-11-03 18:42:24,193 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 4.0 (TID 9)
2015-11-03 18:42:24,197 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:167772160+33554432
2015-11-03 18:42:24,770 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 4.0 (TID 9). 2259 bytes result sent to driver
2015-11-03 18:42:24,773 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 4.0 (TID 10, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 18:42:24,774 INFO  org.apache.spark.executor.Executor - Running task 6.0 in stage 4.0 (TID 10)
2015-11-03 18:42:24,774 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 4.0 (TID 9) in 583 ms on localhost (6/7)
2015-11-03 18:42:24,778 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:201326592+15972963
2015-11-03 18:42:25,001 INFO  org.apache.spark.executor.Executor - Finished task 6.0 in stage 4.0 (TID 10). 2259 bytes result sent to driver
2015-11-03 18:42:25,004 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 4.0 (TID 10) in 232 ms on localhost (7/7)
2015-11-03 18:42:25,004 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 4 (map at Join.scala:49) finished in 4.553 s
2015-11-03 18:42:25,004 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:42:25,004 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 18:42:25,004 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 5)
2015-11-03 18:42:25,004 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-11-03 18:42:25,004 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:42:25,005 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 5: List()
2015-11-03 18:42:25,005 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[21] at saveAsTextFile at Join.scala:72), which is now runnable
2015-11-03 18:42:25,051 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(96024) called with curMem=477602, maxMem=505361203
2015-11-03 18:42:25,051 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 93.8 KB, free 481.4 MB)
2015-11-03 18:42:25,053 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31408) called with curMem=573626, maxMem=505361203
2015-11-03 18:42:25,053 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 30.7 KB, free 481.4 MB)
2015-11-03 18:42:25,054 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on localhost:59245 (size: 30.7 KB, free: 481.9 MB)
2015-11-03 18:42:25,054 INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:861
2015-11-03 18:42:25,055 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 7 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at saveAsTextFile at Join.scala:72)
2015-11-03 18:42:25,055 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 7 tasks
2015-11-03 18:42:25,056 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 11, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:42:25,057 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 11)
2015-11-03 18:42:25,098 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:42:25,098 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:42:25,099 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 18:42:25,099 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:42:26,516 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0005_m_000000_11' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511031842_0005_m_000000
2015-11-03 18:42:26,516 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0005_m_000000_11: Committed
2015-11-03 18:42:26,517 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 11). 1165 bytes result sent to driver
2015-11-03 18:42:26,517 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 12, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:42:26,518 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 11) in 1463 ms on localhost (1/7)
2015-11-03 18:42:26,518 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 12)
2015-11-03 18:42:26,557 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:42:26,558 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 18:42:26,558 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 18:42:26,558 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:42:27,102 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_8_piece0 on localhost:59245 in memory (size: 2.1 KB, free: 481.9 MB)
2015-11-03 18:42:27,104 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_7_piece0 on localhost:59245 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:42:28,130 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0005_m_000001_12' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511031842_0005_m_000001
2015-11-03 18:42:28,131 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0005_m_000001_12: Committed
2015-11-03 18:42:28,133 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 12). 1165 bytes result sent to driver
2015-11-03 18:42:28,138 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 5.0 (TID 13, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:42:28,139 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 5.0 (TID 13)
2015-11-03 18:42:28,140 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 12) in 1622 ms on localhost (2/7)
2015-11-03 18:42:28,194 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:42:28,194 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:42:28,195 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 18:42:28,195 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:42:28,835 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0005_m_000002_13' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511031842_0005_m_000002
2015-11-03 18:42:28,835 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0005_m_000002_13: Committed
2015-11-03 18:42:28,835 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 5.0 (TID 13). 1165 bytes result sent to driver
2015-11-03 18:42:28,836 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 5.0 (TID 14, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:42:28,837 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 5.0 (TID 14)
2015-11-03 18:42:28,837 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 5.0 (TID 13) in 702 ms on localhost (3/7)
2015-11-03 18:42:28,872 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:42:28,872 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:42:28,873 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 18:42:28,873 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:42:30,190 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0005_m_000003_14' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511031842_0005_m_000003
2015-11-03 18:42:30,190 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0005_m_000003_14: Committed
2015-11-03 18:42:30,191 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 5.0 (TID 14). 1165 bytes result sent to driver
2015-11-03 18:42:30,191 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 5.0 (TID 15, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:42:30,192 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 5.0 (TID 15)
2015-11-03 18:42:30,192 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 5.0 (TID 14) in 1356 ms on localhost (4/7)
2015-11-03 18:42:30,249 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:42:30,249 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:42:30,250 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 18:42:30,250 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:42:31,310 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0005_m_000004_15' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511031842_0005_m_000004
2015-11-03 18:42:31,311 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0005_m_000004_15: Committed
2015-11-03 18:42:31,311 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 5.0 (TID 15). 1165 bytes result sent to driver
2015-11-03 18:42:31,312 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 5.0 (TID 16, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:42:31,312 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 5.0 (TID 16)
2015-11-03 18:42:31,313 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 5.0 (TID 15) in 1121 ms on localhost (5/7)
2015-11-03 18:42:31,327 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:42:31,327 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:42:31,328 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 18:42:31,328 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:42:33,185 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0005_m_000005_16' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511031842_0005_m_000005
2015-11-03 18:42:33,185 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0005_m_000005_16: Committed
2015-11-03 18:42:33,186 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 5.0 (TID 16). 1165 bytes result sent to driver
2015-11-03 18:42:33,187 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 5.0 (TID 17, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:42:33,187 INFO  org.apache.spark.executor.Executor - Running task 6.0 in stage 5.0 (TID 17)
2015-11-03 18:42:33,188 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 5.0 (TID 16) in 1875 ms on localhost (6/7)
2015-11-03 18:42:33,198 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:42:33,198 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:42:33,199 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 18:42:33,199 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:42:34,272 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0005_m_000006_17' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511031842_0005_m_000006
2015-11-03 18:42:34,272 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0005_m_000006_17: Committed
2015-11-03 18:42:34,272 INFO  org.apache.spark.executor.Executor - Finished task 6.0 in stage 5.0 (TID 17). 1165 bytes result sent to driver
2015-11-03 18:42:34,274 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 5.0 (TID 17) in 1087 ms on localhost (7/7)
2015-11-03 18:42:34,274 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 5 (saveAsTextFile at Join.scala:72) finished in 9.219 s
2015-11-03 18:42:34,274 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-11-03 18:42:34,274 INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: saveAsTextFile at Join.scala:72, took 13.937697 s
2015-11-03 18:42:37,725 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(64288) called with curMem=593732, maxMem=505361203
2015-11-03 18:42:37,725 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 62.8 KB, free 481.3 MB)
2015-11-03 18:42:37,762 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(14119) called with curMem=658020, maxMem=505361203
2015-11-03 18:42:37,763 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.8 KB, free 481.3 MB)
2015-11-03 18:42:37,766 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on localhost:59245 (size: 13.8 KB, free: 481.9 MB)
2015-11-03 18:42:37,767 INFO  org.apache.spark.SparkContext - Created broadcast 10 from textFile at Join.scala:75
2015-11-03 18:42:38,284 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(148024) called with curMem=672139, maxMem=505361203
2015-11-03 18:42:38,284 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 144.6 KB, free 481.2 MB)
2015-11-03 18:42:38,297 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(14119) called with curMem=820163, maxMem=505361203
2015-11-03 18:42:38,297 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 13.8 KB, free 481.2 MB)
2015-11-03 18:42:38,298 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on localhost:59245 (size: 13.8 KB, free: 481.9 MB)
2015-11-03 18:42:38,299 INFO  org.apache.spark.SparkContext - Created broadcast 11 from textFile at Join.scala:83
2015-11-03 18:42:44,811 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 7
2015-11-03 18:42:44,915 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 18:42:45,113 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at Join.scala:94
2015-11-03 18:42:45,114 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 24 (map at Join.scala:75)
2015-11-03 18:42:45,115 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 27 (map at Join.scala:83)
2015-11-03 18:42:45,115 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 2 (saveAsTextFile at Join.scala:94) with 17 output partitions
2015-11-03 18:42:45,116 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 8(saveAsTextFile at Join.scala:94)
2015-11-03 18:42:45,116 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 6, ShuffleMapStage 7)
2015-11-03 18:42:45,116 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 6, ShuffleMapStage 7)
2015-11-03 18:42:45,119 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 6 (MapPartitionsRDD[24] at map at Join.scala:75), which has no missing parents
2015-11-03 18:42:45,121 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3544) called with curMem=834282, maxMem=505361203
2015-11-03 18:42:45,121 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 3.5 KB, free 481.2 MB)
2015-11-03 18:42:45,123 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2096) called with curMem=837826, maxMem=505361203
2015-11-03 18:42:45,123 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.1 MB)
2015-11-03 18:42:45,125 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on localhost:59245 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:42:45,126 INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:861
2015-11-03 18:42:45,126 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[24] at map at Join.scala:75)
2015-11-03 18:42:45,126 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks
2015-11-03 18:42:45,127 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 7 (MapPartitionsRDD[27] at map at Join.scala:83), which has no missing parents
2015-11-03 18:42:45,129 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 18, localhost, PROCESS_LOCAL, 2184 bytes)
2015-11-03 18:42:45,130 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 18)
2015-11-03 18:42:45,130 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3544) called with curMem=839922, maxMem=505361203
2015-11-03 18:42:45,131 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 3.5 KB, free 481.1 MB)
2015-11-03 18:42:45,132 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2098) called with curMem=843466, maxMem=505361203
2015-11-03 18:42:45,133 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.1 MB)
2015-11-03 18:42:45,134 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_13_piece0 in memory on localhost:59245 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:42:45,135 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelInfo/part-00000:0+46479
2015-11-03 18:42:45,135 INFO  org.apache.spark.SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:861
2015-11-03 18:42:45,136 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 17 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[27] at map at Join.scala:83)
2015-11-03 18:42:45,137 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 17 tasks
2015-11-03 18:42:45,226 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 18). 2269 bytes result sent to driver
2015-11-03 18:42:45,227 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 19, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:45,227 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 19)
2015-11-03 18:42:45,227 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 18) in 100 ms on localhost (1/1)
2015-11-03 18:42:45,228 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-11-03 18:42:45,228 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 6 (map at Join.scala:75) finished in 0.101 s
2015-11-03 18:42:45,228 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:42:45,228 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set(ShuffleMapStage 7)
2015-11-03 18:42:45,229 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 8)
2015-11-03 18:42:45,229 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:42:45,229 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 8: List(ShuffleMapStage 7)
2015-11-03 18:42:45,231 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00000:0+33554432
2015-11-03 18:42:45,885 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_12_piece0 on localhost:59245 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 18:42:47,599 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 19). 2269 bytes result sent to driver
2015-11-03 18:42:47,600 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 7.0 (TID 20, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:47,600 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 7.0 (TID 20)
2015-11-03 18:42:47,601 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 19) in 2375 ms on localhost (1/17)
2015-11-03 18:42:47,604 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00000:33554432+34824632
2015-11-03 18:42:49,131 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 7.0 (TID 20). 2269 bytes result sent to driver
2015-11-03 18:42:49,132 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 7.0 (TID 21, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:49,133 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 7.0 (TID 20) in 1533 ms on localhost (2/17)
2015-11-03 18:42:49,133 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 7.0 (TID 21)
2015-11-03 18:42:49,137 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00001:0+33554432
2015-11-03 18:42:50,200 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 7.0 (TID 21). 2269 bytes result sent to driver
2015-11-03 18:42:50,202 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 7.0 (TID 22, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:50,203 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 7.0 (TID 22)
2015-11-03 18:42:50,204 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 7.0 (TID 21) in 1073 ms on localhost (3/17)
2015-11-03 18:42:50,207 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00001:33554432+36145941
2015-11-03 18:42:51,094 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 7.0 (TID 22). 2269 bytes result sent to driver
2015-11-03 18:42:51,095 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 7.0 (TID 23, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:51,096 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 7.0 (TID 22) in 895 ms on localhost (4/17)
2015-11-03 18:42:51,096 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 7.0 (TID 23)
2015-11-03 18:42:51,100 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00002:0+33554432
2015-11-03 18:42:52,703 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 7.0 (TID 23). 2269 bytes result sent to driver
2015-11-03 18:42:52,704 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 7.0 (TID 24, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:52,704 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 7.0 (TID 24)
2015-11-03 18:42:52,705 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 7.0 (TID 23) in 1610 ms on localhost (5/17)
2015-11-03 18:42:52,707 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00002:33554432+4326235
2015-11-03 18:42:52,881 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 7.0 (TID 24). 2269 bytes result sent to driver
2015-11-03 18:42:52,882 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 7.0 (TID 25, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:52,883 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 7.0 (TID 24) in 179 ms on localhost (6/17)
2015-11-03 18:42:52,883 INFO  org.apache.spark.executor.Executor - Running task 6.0 in stage 7.0 (TID 25)
2015-11-03 18:42:52,886 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00003:0+33554432
2015-11-03 18:42:53,928 INFO  org.apache.spark.executor.Executor - Finished task 6.0 in stage 7.0 (TID 25). 2269 bytes result sent to driver
2015-11-03 18:42:53,929 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 7.0 (TID 26, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:53,929 INFO  org.apache.spark.executor.Executor - Running task 7.0 in stage 7.0 (TID 26)
2015-11-03 18:42:53,930 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 7.0 (TID 25) in 1049 ms on localhost (7/17)
2015-11-03 18:42:53,933 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00003:33554432+7937584
2015-11-03 18:42:54,178 INFO  org.apache.spark.executor.Executor - Finished task 7.0 in stage 7.0 (TID 26). 2269 bytes result sent to driver
2015-11-03 18:42:54,180 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 8.0 in stage 7.0 (TID 27, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:54,180 INFO  org.apache.spark.executor.Executor - Running task 8.0 in stage 7.0 (TID 27)
2015-11-03 18:42:54,181 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 7.0 (TID 26) in 251 ms on localhost (8/17)
2015-11-03 18:42:54,183 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00004:0+33554432
2015-11-03 18:42:55,391 INFO  org.apache.spark.executor.Executor - Finished task 8.0 in stage 7.0 (TID 27). 2269 bytes result sent to driver
2015-11-03 18:42:55,393 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 9.0 in stage 7.0 (TID 28, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:55,394 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 8.0 in stage 7.0 (TID 27) in 1214 ms on localhost (9/17)
2015-11-03 18:42:55,394 INFO  org.apache.spark.executor.Executor - Running task 9.0 in stage 7.0 (TID 28)
2015-11-03 18:42:55,397 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00004:33554432+36440007
2015-11-03 18:42:56,222 INFO  org.apache.spark.executor.Executor - Finished task 9.0 in stage 7.0 (TID 28). 2269 bytes result sent to driver
2015-11-03 18:42:56,223 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 10.0 in stage 7.0 (TID 29, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:56,224 INFO  org.apache.spark.executor.Executor - Running task 10.0 in stage 7.0 (TID 29)
2015-11-03 18:42:56,224 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 9.0 in stage 7.0 (TID 28) in 831 ms on localhost (10/17)
2015-11-03 18:42:56,226 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00005:0+33554432
2015-11-03 18:42:57,010 INFO  org.apache.spark.executor.Executor - Finished task 10.0 in stage 7.0 (TID 29). 2269 bytes result sent to driver
2015-11-03 18:42:57,011 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 11.0 in stage 7.0 (TID 30, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:57,012 INFO  org.apache.spark.executor.Executor - Running task 11.0 in stage 7.0 (TID 30)
2015-11-03 18:42:57,012 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 10.0 in stage 7.0 (TID 29) in 789 ms on localhost (11/17)
2015-11-03 18:42:57,014 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00005:33554432+33554432
2015-11-03 18:42:57,988 INFO  org.apache.spark.executor.Executor - Finished task 11.0 in stage 7.0 (TID 30). 2269 bytes result sent to driver
2015-11-03 18:42:57,989 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 12.0 in stage 7.0 (TID 31, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:57,989 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 11.0 in stage 7.0 (TID 30) in 978 ms on localhost (12/17)
2015-11-03 18:42:57,990 INFO  org.apache.spark.executor.Executor - Running task 12.0 in stage 7.0 (TID 31)
2015-11-03 18:42:57,993 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00005:67108864+33554432
2015-11-03 18:42:58,793 INFO  org.apache.spark.executor.Executor - Finished task 12.0 in stage 7.0 (TID 31). 2269 bytes result sent to driver
2015-11-03 18:42:58,794 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 13.0 in stage 7.0 (TID 32, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:58,795 INFO  org.apache.spark.executor.Executor - Running task 13.0 in stage 7.0 (TID 32)
2015-11-03 18:42:58,795 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 12.0 in stage 7.0 (TID 31) in 807 ms on localhost (13/17)
2015-11-03 18:42:58,797 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00005:100663296+33554432
2015-11-03 18:42:59,553 INFO  org.apache.spark.executor.Executor - Finished task 13.0 in stage 7.0 (TID 32). 2269 bytes result sent to driver
2015-11-03 18:42:59,554 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 14.0 in stage 7.0 (TID 33, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:59,555 INFO  org.apache.spark.executor.Executor - Running task 14.0 in stage 7.0 (TID 33)
2015-11-03 18:42:59,555 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 13.0 in stage 7.0 (TID 32) in 761 ms on localhost (14/17)
2015-11-03 18:42:59,558 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00005:134217728+15369355
2015-11-03 18:42:59,960 INFO  org.apache.spark.executor.Executor - Finished task 14.0 in stage 7.0 (TID 33). 2269 bytes result sent to driver
2015-11-03 18:42:59,961 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 15.0 in stage 7.0 (TID 34, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:42:59,962 INFO  org.apache.spark.executor.Executor - Running task 15.0 in stage 7.0 (TID 34)
2015-11-03 18:42:59,962 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 14.0 in stage 7.0 (TID 33) in 408 ms on localhost (15/17)
2015-11-03 18:42:59,965 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00006:0+33554432
2015-11-03 18:43:00,715 INFO  org.apache.spark.executor.Executor - Finished task 15.0 in stage 7.0 (TID 34). 2269 bytes result sent to driver
2015-11-03 18:43:00,716 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 16.0 in stage 7.0 (TID 35, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 18:43:00,717 INFO  org.apache.spark.executor.Executor - Running task 16.0 in stage 7.0 (TID 35)
2015-11-03 18:43:00,717 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 15.0 in stage 7.0 (TID 34) in 756 ms on localhost (16/17)
2015-11-03 18:43:00,720 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00006:33554432+17559114
2015-11-03 18:43:01,165 INFO  org.apache.spark.executor.Executor - Finished task 16.0 in stage 7.0 (TID 35). 2269 bytes result sent to driver
2015-11-03 18:43:01,167 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 16.0 in stage 7.0 (TID 35) in 451 ms on localhost (17/17)
2015-11-03 18:43:01,167 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 7 (map at Join.scala:83) finished in 16.030 s
2015-11-03 18:43:01,167 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2015-11-03 18:43:01,167 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 18:43:01,167 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 18:43:01,167 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 8)
2015-11-03 18:43:01,167 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 18:43:01,168 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 8: List()
2015-11-03 18:43:01,168 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[32] at saveAsTextFile at Join.scala:94), which is now runnable
2015-11-03 18:43:01,197 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(96040) called with curMem=839924, maxMem=505361203
2015-11-03 18:43:01,198 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_14 stored as values in memory (estimated size 93.8 KB, free 481.1 MB)
2015-11-03 18:43:01,199 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31436) called with curMem=935964, maxMem=505361203
2015-11-03 18:43:01,199 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 30.7 KB, free 481.0 MB)
2015-11-03 18:43:01,200 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_14_piece0 in memory on localhost:59245 (size: 30.7 KB, free: 481.8 MB)
2015-11-03 18:43:01,201 INFO  org.apache.spark.SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:861
2015-11-03 18:43:01,201 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 17 missing tasks from ResultStage 8 (MapPartitionsRDD[32] at saveAsTextFile at Join.scala:94)
2015-11-03 18:43:01,201 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 17 tasks
2015-11-03 18:43:01,202 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 36, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:01,203 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 36)
2015-11-03 18:43:01,224 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:01,224 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:01,225 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:01,225 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:01,993 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_13_piece0 on localhost:59245 in memory (size: 2.0 KB, free: 481.8 MB)
2015-11-03 18:43:01,995 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_9_piece0 on localhost:59245 in memory (size: 30.7 KB, free: 481.9 MB)
2015-11-03 18:43:01,995 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 6
2015-11-03 18:43:01,996 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 5
2015-11-03 18:43:01,996 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 4
2015-11-03 18:43:02,249 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000000_36' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000000
2015-11-03 18:43:02,250 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000000_36: Committed
2015-11-03 18:43:02,250 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 36). 1165 bytes result sent to driver
2015-11-03 18:43:02,251 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 8.0 (TID 37, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:02,251 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 8.0 (TID 37)
2015-11-03 18:43:02,252 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 36) in 1049 ms on localhost (1/17)
2015-11-03 18:43:02,262 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:02,262 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:02,263 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:02,263 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 18:43:03,117 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000001_37' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000001
2015-11-03 18:43:03,117 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000001_37: Committed
2015-11-03 18:43:03,118 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 8.0 (TID 37). 1165 bytes result sent to driver
2015-11-03 18:43:03,118 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 8.0 (TID 38, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:03,119 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 8.0 (TID 38)
2015-11-03 18:43:03,119 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 8.0 (TID 37) in 869 ms on localhost (2/17)
2015-11-03 18:43:03,135 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:03,135 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:03,135 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:03,135 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:03,569 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000002_38' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000002
2015-11-03 18:43:03,570 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000002_38: Committed
2015-11-03 18:43:03,570 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 8.0 (TID 38). 1165 bytes result sent to driver
2015-11-03 18:43:03,571 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 8.0 (TID 39, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:03,572 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 8.0 (TID 39)
2015-11-03 18:43:03,572 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 8.0 (TID 38) in 454 ms on localhost (3/17)
2015-11-03 18:43:03,583 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:03,583 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 18:43:03,584 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:03,584 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:04,249 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000003_39' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000003
2015-11-03 18:43:04,249 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000003_39: Committed
2015-11-03 18:43:04,250 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 8.0 (TID 39). 1165 bytes result sent to driver
2015-11-03 18:43:04,251 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 8.0 (TID 40, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:04,252 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 8.0 (TID 40)
2015-11-03 18:43:04,252 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 8.0 (TID 39) in 681 ms on localhost (4/17)
2015-11-03 18:43:04,262 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:04,262 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:04,262 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:04,262 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:04,715 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000004_40' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000004
2015-11-03 18:43:04,715 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000004_40: Committed
2015-11-03 18:43:04,716 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 8.0 (TID 40). 1165 bytes result sent to driver
2015-11-03 18:43:04,717 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 8.0 (TID 41, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:04,717 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 8.0 (TID 41)
2015-11-03 18:43:04,721 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 8.0 (TID 40) in 469 ms on localhost (5/17)
2015-11-03 18:43:04,727 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:04,727 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:04,728 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:04,728 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:05,188 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000005_41' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000005
2015-11-03 18:43:05,188 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000005_41: Committed
2015-11-03 18:43:05,188 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 8.0 (TID 41). 1165 bytes result sent to driver
2015-11-03 18:43:05,189 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 8.0 (TID 42, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:05,189 INFO  org.apache.spark.executor.Executor - Running task 6.0 in stage 8.0 (TID 42)
2015-11-03 18:43:05,190 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 8.0 (TID 41) in 473 ms on localhost (6/17)
2015-11-03 18:43:05,198 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:05,199 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 18:43:05,199 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:05,199 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:05,563 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000006_42' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000006
2015-11-03 18:43:05,564 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000006_42: Committed
2015-11-03 18:43:05,564 INFO  org.apache.spark.executor.Executor - Finished task 6.0 in stage 8.0 (TID 42). 1165 bytes result sent to driver
2015-11-03 18:43:05,565 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 8.0 (TID 43, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:05,565 INFO  org.apache.spark.executor.Executor - Running task 7.0 in stage 8.0 (TID 43)
2015-11-03 18:43:05,565 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 8.0 (TID 42) in 376 ms on localhost (7/17)
2015-11-03 18:43:05,576 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:05,576 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:05,577 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:05,577 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:06,121 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000007_43' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000007
2015-11-03 18:43:06,121 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000007_43: Committed
2015-11-03 18:43:06,121 INFO  org.apache.spark.executor.Executor - Finished task 7.0 in stage 8.0 (TID 43). 1165 bytes result sent to driver
2015-11-03 18:43:06,122 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 8.0 in stage 8.0 (TID 44, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:06,122 INFO  org.apache.spark.executor.Executor - Running task 8.0 in stage 8.0 (TID 44)
2015-11-03 18:43:06,123 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 8.0 (TID 43) in 559 ms on localhost (8/17)
2015-11-03 18:43:06,132 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:06,132 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:06,133 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:06,133 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:06,895 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000008_44' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000008
2015-11-03 18:43:06,895 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000008_44: Committed
2015-11-03 18:43:06,896 INFO  org.apache.spark.executor.Executor - Finished task 8.0 in stage 8.0 (TID 44). 1165 bytes result sent to driver
2015-11-03 18:43:06,897 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 9.0 in stage 8.0 (TID 45, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:06,897 INFO  org.apache.spark.executor.Executor - Running task 9.0 in stage 8.0 (TID 45)
2015-11-03 18:43:06,897 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 8.0 in stage 8.0 (TID 44) in 775 ms on localhost (9/17)
2015-11-03 18:43:06,906 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:06,906 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:06,907 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:06,907 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:07,512 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000009_45' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000009
2015-11-03 18:43:07,512 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000009_45: Committed
2015-11-03 18:43:07,513 INFO  org.apache.spark.executor.Executor - Finished task 9.0 in stage 8.0 (TID 45). 1165 bytes result sent to driver
2015-11-03 18:43:07,514 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 10.0 in stage 8.0 (TID 46, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:07,514 INFO  org.apache.spark.executor.Executor - Running task 10.0 in stage 8.0 (TID 46)
2015-11-03 18:43:07,514 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 9.0 in stage 8.0 (TID 45) in 618 ms on localhost (10/17)
2015-11-03 18:43:07,523 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:07,523 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:07,523 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:07,523 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:08,361 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000010_46' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000010
2015-11-03 18:43:08,361 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000010_46: Committed
2015-11-03 18:43:08,362 INFO  org.apache.spark.executor.Executor - Finished task 10.0 in stage 8.0 (TID 46). 1165 bytes result sent to driver
2015-11-03 18:43:08,362 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 11.0 in stage 8.0 (TID 47, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:08,363 INFO  org.apache.spark.executor.Executor - Running task 11.0 in stage 8.0 (TID 47)
2015-11-03 18:43:08,363 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 10.0 in stage 8.0 (TID 46) in 850 ms on localhost (11/17)
2015-11-03 18:43:08,372 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:08,372 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 18:43:08,372 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:08,372 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:09,341 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000011_47' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000011
2015-11-03 18:43:09,342 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000011_47: Committed
2015-11-03 18:43:09,342 INFO  org.apache.spark.executor.Executor - Finished task 11.0 in stage 8.0 (TID 47). 1165 bytes result sent to driver
2015-11-03 18:43:09,343 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 12.0 in stage 8.0 (TID 48, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:09,343 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 11.0 in stage 8.0 (TID 47) in 981 ms on localhost (12/17)
2015-11-03 18:43:09,343 INFO  org.apache.spark.executor.Executor - Running task 12.0 in stage 8.0 (TID 48)
2015-11-03 18:43:09,352 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:09,352 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:09,352 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:09,352 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:10,454 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000012_48' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000012
2015-11-03 18:43:10,454 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000012_48: Committed
2015-11-03 18:43:10,455 INFO  org.apache.spark.executor.Executor - Finished task 12.0 in stage 8.0 (TID 48). 1165 bytes result sent to driver
2015-11-03 18:43:10,456 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 13.0 in stage 8.0 (TID 49, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:10,456 INFO  org.apache.spark.executor.Executor - Running task 13.0 in stage 8.0 (TID 49)
2015-11-03 18:43:10,457 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 12.0 in stage 8.0 (TID 48) in 1114 ms on localhost (13/17)
2015-11-03 18:43:10,465 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:10,465 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:10,466 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:10,466 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:12,228 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000013_49' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000013
2015-11-03 18:43:12,228 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000013_49: Committed
2015-11-03 18:43:12,229 INFO  org.apache.spark.executor.Executor - Finished task 13.0 in stage 8.0 (TID 49). 1165 bytes result sent to driver
2015-11-03 18:43:12,231 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 14.0 in stage 8.0 (TID 50, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:12,231 INFO  org.apache.spark.executor.Executor - Running task 14.0 in stage 8.0 (TID 50)
2015-11-03 18:43:12,231 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 13.0 in stage 8.0 (TID 49) in 1776 ms on localhost (14/17)
2015-11-03 18:43:12,245 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:12,245 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 18:43:12,246 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:12,246 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 18:43:12,755 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000014_50' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000014
2015-11-03 18:43:12,756 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000014_50: Committed
2015-11-03 18:43:12,756 INFO  org.apache.spark.executor.Executor - Finished task 14.0 in stage 8.0 (TID 50). 1165 bytes result sent to driver
2015-11-03 18:43:12,757 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 15.0 in stage 8.0 (TID 51, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:12,757 INFO  org.apache.spark.executor.Executor - Running task 15.0 in stage 8.0 (TID 51)
2015-11-03 18:43:12,757 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 14.0 in stage 8.0 (TID 50) in 527 ms on localhost (15/17)
2015-11-03 18:43:12,766 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:12,766 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:12,767 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:12,767 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 18:43:13,677 INFO  org.apache.spark.util.collection.ExternalAppendOnlyMap - Thread 84 spilling in-memory map of 147.8 MB to disk (1 time so far)
2015-11-03 18:43:15,222 INFO  org.apache.spark.util.collection.ExternalAppendOnlyMap - Thread 84 spilling in-memory map of 147.8 MB to disk (2 times so far)
2015-11-03 18:43:17,544 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000015_51' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000015
2015-11-03 18:43:17,544 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000015_51: Committed
2015-11-03 18:43:17,545 INFO  org.apache.spark.executor.Executor - Finished task 15.0 in stage 8.0 (TID 51). 1165 bytes result sent to driver
2015-11-03 18:43:17,546 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 16.0 in stage 8.0 (TID 52, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 18:43:17,547 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 15.0 in stage 8.0 (TID 51) in 4790 ms on localhost (16/17)
2015-11-03 18:43:17,547 INFO  org.apache.spark.executor.Executor - Running task 16.0 in stage 8.0 (TID 52)
2015-11-03 18:43:17,556 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 18:43:17,556 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:17,557 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 18:43:17,557 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 18:43:18,309 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511031842_0008_m_000016_52' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511031842_0008_m_000016
2015-11-03 18:43:18,309 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511031842_0008_m_000016_52: Committed
2015-11-03 18:43:18,309 INFO  org.apache.spark.executor.Executor - Finished task 16.0 in stage 8.0 (TID 52). 1165 bytes result sent to driver
2015-11-03 18:43:18,310 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 16.0 in stage 8.0 (TID 52) in 764 ms on localhost (17/17)
2015-11-03 18:43:18,310 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 8 (saveAsTextFile at Join.scala:94) finished in 17.108 s
2015-11-03 18:43:18,311 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2015-11-03 18:43:18,311 INFO  org.apache.spark.scheduler.DAGScheduler - Job 2 finished: saveAsTextFile at Join.scala:94, took 33.197893 s
2015-11-03 18:43:18,513 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-03 18:43:18,632 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-03 18:43:18,632 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-03 18:43:18,632 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-03 18:43:18,633 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-03 18:43:18,633 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-03 18:43:18,633 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-03 18:43:18,633 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-03 18:43:18,633 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-03 18:43:18,634 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-03 18:43:18,634 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-03 18:43:18,634 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-03 18:43:18,634 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-03 18:43:18,634 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-03 18:43:18,635 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-03 18:43:18,635 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-03 18:43:18,635 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-03 18:43:18,635 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-03 18:43:18,635 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-03 18:43:18,636 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-03 18:43:18,636 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-03 18:43:18,637 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-03 18:43:18,637 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-03 18:43:18,637 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-03 18:43:18,637 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-03 18:43:18,637 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-03 18:43:18,732 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-03 18:43:18,799 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-03 18:43:19,109 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-03 18:43:19,385 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-03 18:43:19,395 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-03 18:43:19,406 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-03 18:43:19,513 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-03 18:43:19,525 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-03 18:43:19,565 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-03 18:43:19,606 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-03bd38ad-7651-4156-92bd-dc482740cbd1
2015-11-03 21:25:15,288 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-03 21:25:25,813 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-03 21:25:25,832 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-03 21:25:25,833 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-03 21:25:40,117 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-03 21:25:40,657 INFO  Remoting - Starting remoting
2015-11-03 21:25:41,741 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:51682]
2015-11-03 21:25:41,782 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51682.
2015-11-03 21:25:42,039 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-03 21:25:42,210 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-03 21:25:42,387 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-513a199a-8afd-46e6-b5e2-461138056121
2015-11-03 21:25:42,566 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-03 21:25:42,879 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-96c48d05-0a44-48cd-b0a0-36e1eed215af\httpd-48e73b89-716e-4fc2-a03d-6632a70a5687
2015-11-03 21:25:43,041 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-03 21:25:43,384 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 21:25:43,418 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:51683
2015-11-03 21:25:43,419 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 51683.
2015-11-03 21:25:43,538 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-03 21:25:44,541 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-03 21:25:44,589 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-03 21:25:44,590 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-03 21:25:44,592 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-03 21:25:45,271 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-03 21:25:45,301 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-03 21:25:46,357 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51702.
2015-11-03 21:25:46,358 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 51702
2015-11-03 21:25:46,385 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-03 21:25:46,404 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:51702 with 481.9 MB RAM, BlockManagerId(driver, localhost, 51702)
2015-11-03 21:25:46,443 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-03 21:25:49,587 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-03 21:25:49,611 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-03 21:25:49,919 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-03 21:25:49,919 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-03 21:25:49,922 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:51702 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 21:25:50,031 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at Join.scala:17
2015-11-03 21:25:50,485 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=116545, maxMem=505361203
2015-11-03 21:25:50,486 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 104.0 KB, free 481.7 MB)
2015-11-03 21:25:50,510 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=223065, maxMem=505361203
2015-11-03 21:25:50,512 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.7 MB)
2015-11-03 21:25:50,515 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:51702 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 21:25:50,519 INFO  org.apache.spark.SparkContext - Created broadcast 1 from textFile at Join.scala:27
2015-11-03 21:25:50,591 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=233130, maxMem=505361203
2015-11-03 21:25:50,591 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 104.0 KB, free 481.6 MB)
2015-11-03 21:25:50,614 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=339650, maxMem=505361203
2015-11-03 21:25:50,615 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.6 MB)
2015-11-03 21:25:50,617 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:51702 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 21:25:50,619 INFO  org.apache.spark.SparkContext - Created broadcast 2 from textFile at Join.scala:37
2015-11-03 21:25:50,652 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106520) called with curMem=349715, maxMem=505361203
2015-11-03 21:25:50,652 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 104.0 KB, free 481.5 MB)
2015-11-03 21:25:50,674 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=456235, maxMem=505361203
2015-11-03 21:25:50,675 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.5 MB)
2015-11-03 21:25:50,676 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:51702 (size: 9.8 KB, free: 481.9 MB)
2015-11-03 21:25:50,677 INFO  org.apache.spark.SparkContext - Created broadcast 3 from textFile at Join.scala:48
2015-11-03 21:25:52,444 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:105%31, but we couldn't find any external IP address!
2015-11-03 21:25:53,104 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 21:25:53,281 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 21:25:53,557 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-03 21:25:53,557 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-03 21:25:53,557 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-03 21:25:53,557 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-03 21:25:53,557 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-03 21:25:53,997 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at Join.scala:65
2015-11-03 21:25:54,139 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 2 (map at Join.scala:18)
2015-11-03 21:25:54,158 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 5 (map at Join.scala:28)
2015-11-03 21:25:54,196 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsTextFile at Join.scala:65) with 1 output partitions
2015-11-03 21:25:54,198 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2(saveAsTextFile at Join.scala:65)
2015-11-03 21:25:54,224 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 21:25:54,230 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2015-11-03 21:25:54,310 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at Join.scala:18), which has no missing parents
2015-11-03 21:25:54,437 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3544) called with curMem=466300, maxMem=505361203
2015-11-03 21:25:54,439 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.5 KB, free 481.5 MB)
2015-11-03 21:25:54,445 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2091) called with curMem=469844, maxMem=505361203
2015-11-03 21:25:54,446 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.5 MB)
2015-11-03 21:25:54,449 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:51702 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 21:25:54,450 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-03 21:25:54,506 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at Join.scala:18)
2015-11-03 21:25:54,508 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2015-11-03 21:25:54,569 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Join.scala:28), which has no missing parents
2015-11-03 21:25:54,573 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3552) called with curMem=471935, maxMem=505361203
2015-11-03 21:25:54,574 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 3.5 KB, free 481.5 MB)
2015-11-03 21:25:54,576 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2098) called with curMem=475487, maxMem=505361203
2015-11-03 21:25:54,577 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.5 MB)
2015-11-03 21:25:54,579 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:51702 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 21:25:54,581 INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-11-03 21:25:54,581 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Join.scala:28)
2015-11-03 21:25:54,581 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2015-11-03 21:25:54,665 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2173 bytes)
2015-11-03 21:25:54,721 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-03 21:25:54,986 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/Hotel.txt:0+337904
2015-11-03 21:25:55,678 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
2015-11-03 21:25:55,698 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 21:25:55,699 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2015-11-03 21:25:55,707 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/hotel_id_position.txt:0+17841
2015-11-03 21:25:55,719 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1065 ms on localhost (1/1)
2015-11-03 21:25:55,776 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 2253 bytes result sent to driver
2015-11-03 21:25:55,822 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (map at Join.scala:18) finished in 1.253 s
2015-11-03 21:25:55,834 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 21:25:55,835 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set(ShuffleMapStage 1)
2015-11-03 21:25:55,835 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 21:25:55,836 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 21:25:55,836 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-03 21:25:55,840 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 143 ms on localhost (1/1)
2015-11-03 21:25:55,841 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-03 21:25:55,879 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List(ShuffleMapStage 1)
2015-11-03 21:25:55,901 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at Join.scala:28) finished in 1.231 s
2015-11-03 21:25:55,902 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 21:25:55,902 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 21:25:55,902 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-03 21:25:55,902 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 21:25:55,902 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List()
2015-11-03 21:25:55,933 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[16] at saveAsTextFile at Join.scala:65), which is now runnable
2015-11-03 21:25:56,022 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(96024) called with curMem=477585, maxMem=505361203
2015-11-03 21:25:56,022 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 93.8 KB, free 481.4 MB)
2015-11-03 21:25:56,030 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31394) called with curMem=573609, maxMem=505361203
2015-11-03 21:25:56,031 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 30.7 KB, free 481.4 MB)
2015-11-03 21:25:56,033 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on localhost:51702 (size: 30.7 KB, free: 481.9 MB)
2015-11-03 21:25:56,034 INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:861
2015-11-03 21:25:56,036 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at saveAsTextFile at Join.scala:65)
2015-11-03 21:25:56,036 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks
2015-11-03 21:25:56,039 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 21:25:56,039 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2015-11-03 21:25:56,095 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-03 21:25:56,096 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-03 21:25:56,098 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-03 21:25:56,102 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-03 21:25:56,242 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:25:56,255 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 53 ms
2015-11-03 21:25:56,352 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:25:56,353 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:25:57,194 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511032125_0002_m_000000_2' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelInfo/_temporary/0/task_201511032125_0002_m_000000
2015-11-03 21:25:57,195 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511032125_0002_m_000000_2: Committed
2015-11-03 21:25:57,197 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1165 bytes result sent to driver
2015-11-03 21:25:57,200 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 1162 ms on localhost (1/1)
2015-11-03 21:25:57,200 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-03 21:25:57,211 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (saveAsTextFile at Join.scala:65) finished in 1.174 s
2015-11-03 21:25:57,235 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsTextFile at Join.scala:65, took 3.237772 s
2015-11-03 21:25:57,312 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 21:25:57,328 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 21:25:57,441 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at Join.scala:72
2015-11-03 21:25:57,442 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 8 (map at Join.scala:38)
2015-11-03 21:25:57,442 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 11 (map at Join.scala:49)
2015-11-03 21:25:57,443 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (saveAsTextFile at Join.scala:72) with 7 output partitions
2015-11-03 21:25:57,443 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 5(saveAsTextFile at Join.scala:72)
2015-11-03 21:25:57,443 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 3, ShuffleMapStage 4)
2015-11-03 21:25:57,443 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 3, ShuffleMapStage 4)
2015-11-03 21:25:57,444 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at map at Join.scala:38), which has no missing parents
2015-11-03 21:25:57,447 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3552) called with curMem=605003, maxMem=505361203
2015-11-03 21:25:57,448 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 3.5 KB, free 481.4 MB)
2015-11-03 21:25:57,469 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2094) called with curMem=608555, maxMem=505361203
2015-11-03 21:25:57,470 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.4 MB)
2015-11-03 21:25:57,473 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on localhost:51702 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 21:25:57,474 INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:861
2015-11-03 21:25:57,474 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at map at Join.scala:38)
2015-11-03 21:25:57,474 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks
2015-11-03 21:25:57,476 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 4 (MapPartitionsRDD[11] at map at Join.scala:49), which has no missing parents
2015-11-03 21:25:57,479 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 21:25:57,481 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3552) called with curMem=610649, maxMem=505361203
2015-11-03 21:25:57,483 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2015-11-03 21:25:57,484 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 3.5 KB, free 481.4 MB)
2015-11-03 21:25:57,487 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2104) called with curMem=614201, maxMem=505361203
2015-11-03 21:25:57,487 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.1 KB, free 481.4 MB)
2015-11-03 21:25:57,490 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000001.dat:0+15177529
2015-11-03 21:25:57,494 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on localhost:51702 (size: 2.1 KB, free: 481.9 MB)
2015-11-03 21:25:57,501 INFO  org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:861
2015-11-03 21:25:57,502 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 7 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[11] at map at Join.scala:49)
2015-11-03 21:25:57,502 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 7 tasks
2015-11-03 21:25:58,536 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2259 bytes result sent to driver
2015-11-03 21:25:58,537 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 21:25:58,541 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2015-11-03 21:25:58,543 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 1066 ms on localhost (1/1)
2015-11-03 21:25:58,544 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-11-03 21:25:58,544 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 3 (map at Join.scala:38) finished in 1.069 s
2015-11-03 21:25:58,544 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 21:25:58,544 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set(ShuffleMapStage 4)
2015-11-03 21:25:58,544 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 5)
2015-11-03 21:25:58,544 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 21:25:58,545 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 5: List(ShuffleMapStage 4)
2015-11-03 21:25:58,547 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:0+33554432
2015-11-03 21:25:58,970 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2259 bytes result sent to driver
2015-11-03 21:25:58,971 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 4.0 (TID 5, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 21:25:58,972 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 4.0 (TID 5)
2015-11-03 21:25:58,973 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 435 ms on localhost (1/7)
2015-11-03 21:25:58,976 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:33554432+33554432
2015-11-03 21:25:59,630 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 4.0 (TID 5). 2259 bytes result sent to driver
2015-11-03 21:25:59,632 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 4.0 (TID 6, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 21:25:59,633 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 4.0 (TID 6)
2015-11-03 21:25:59,635 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 4.0 (TID 5) in 665 ms on localhost (2/7)
2015-11-03 21:25:59,638 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:67108864+33554432
2015-11-03 21:26:00,496 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 4.0 (TID 6). 2259 bytes result sent to driver
2015-11-03 21:26:00,497 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 4.0 (TID 7, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 21:26:00,498 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 4.0 (TID 7)
2015-11-03 21:26:00,498 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 4.0 (TID 6) in 867 ms on localhost (3/7)
2015-11-03 21:26:00,502 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:100663296+33554432
2015-11-03 21:26:01,474 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 4.0 (TID 7). 2259 bytes result sent to driver
2015-11-03 21:26:01,475 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 4.0 (TID 8, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 21:26:01,475 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 4.0 (TID 8)
2015-11-03 21:26:01,477 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 4.0 (TID 7) in 980 ms on localhost (4/7)
2015-11-03 21:26:01,479 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:134217728+33554432
2015-11-03 21:26:01,983 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 4.0 (TID 8). 2259 bytes result sent to driver
2015-11-03 21:26:01,984 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 4.0 (TID 9, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 21:26:01,985 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 4.0 (TID 9)
2015-11-03 21:26:01,985 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 4.0 (TID 8) in 511 ms on localhost (5/7)
2015-11-03 21:26:01,989 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:167772160+33554432
2015-11-03 21:26:02,377 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 4.0 (TID 9). 2259 bytes result sent to driver
2015-11-03 21:26:02,378 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 4.0 (TID 10, localhost, PROCESS_LOCAL, 2185 bytes)
2015-11-03 21:26:02,379 INFO  org.apache.spark.executor.Executor - Running task 6.0 in stage 4.0 (TID 10)
2015-11-03 21:26:02,379 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 4.0 (TID 9) in 396 ms on localhost (6/7)
2015-11-03 21:26:02,383 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/CD-00001-00000002.dat:201326592+15972963
2015-11-03 21:26:02,664 INFO  org.apache.spark.executor.Executor - Finished task 6.0 in stage 4.0 (TID 10). 2259 bytes result sent to driver
2015-11-03 21:26:02,666 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 4.0 (TID 10) in 288 ms on localhost (7/7)
2015-11-03 21:26:02,666 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 4 (map at Join.scala:49) finished in 5.163 s
2015-11-03 21:26:02,666 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-11-03 21:26:02,666 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 21:26:02,667 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 21:26:02,667 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 5)
2015-11-03 21:26:02,667 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 21:26:02,667 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 5: List()
2015-11-03 21:26:02,668 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[21] at saveAsTextFile at Join.scala:72), which is now runnable
2015-11-03 21:26:02,712 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(96024) called with curMem=616305, maxMem=505361203
2015-11-03 21:26:02,712 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 93.8 KB, free 481.3 MB)
2015-11-03 21:26:02,714 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31408) called with curMem=712329, maxMem=505361203
2015-11-03 21:26:02,714 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 30.7 KB, free 481.2 MB)
2015-11-03 21:26:02,715 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on localhost:51702 (size: 30.7 KB, free: 481.8 MB)
2015-11-03 21:26:02,716 INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:861
2015-11-03 21:26:02,716 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 7 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at saveAsTextFile at Join.scala:72)
2015-11-03 21:26:02,716 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 7 tasks
2015-11-03 21:26:02,717 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 11, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 21:26:02,718 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 11)
2015-11-03 21:26:02,755 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:02,756 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:26:02,756 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 21:26:02,756 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:04,161 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511032125_0005_m_000000_11' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511032125_0005_m_000000
2015-11-03 21:26:04,161 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511032125_0005_m_000000_11: Committed
2015-11-03 21:26:04,162 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 11). 1165 bytes result sent to driver
2015-11-03 21:26:04,163 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 12, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 21:26:04,163 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 11) in 1446 ms on localhost (1/7)
2015-11-03 21:26:04,164 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 12)
2015-11-03 21:26:04,206 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:04,206 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:26:04,206 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 21:26:04,206 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:05,888 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_8_piece0 on localhost:51702 in memory (size: 2.1 KB, free: 481.8 MB)
2015-11-03 21:26:05,980 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_7_piece0 on localhost:51702 in memory (size: 2.0 KB, free: 481.8 MB)
2015-11-03 21:26:05,984 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on localhost:51702 in memory (size: 30.7 KB, free: 481.9 MB)
2015-11-03 21:26:05,987 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 3
2015-11-03 21:26:05,993 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on localhost:51702 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 21:26:05,994 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 2
2015-11-03 21:26:05,997 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on localhost:51702 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 21:26:05,997 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 1
2015-11-03 21:26:06,550 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511032125_0005_m_000001_12' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511032125_0005_m_000001
2015-11-03 21:26:06,550 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511032125_0005_m_000001_12: Committed
2015-11-03 21:26:06,551 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 12). 1165 bytes result sent to driver
2015-11-03 21:26:06,552 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 5.0 (TID 13, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 21:26:06,552 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 5.0 (TID 13)
2015-11-03 21:26:06,552 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 12) in 2390 ms on localhost (2/7)
2015-11-03 21:26:06,586 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:06,586 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:06,587 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 21:26:06,587 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:07,238 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511032125_0005_m_000002_13' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511032125_0005_m_000002
2015-11-03 21:26:07,239 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511032125_0005_m_000002_13: Committed
2015-11-03 21:26:07,239 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 5.0 (TID 13). 1165 bytes result sent to driver
2015-11-03 21:26:07,240 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 5.0 (TID 14, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 21:26:07,240 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 5.0 (TID 14)
2015-11-03 21:26:07,242 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 5.0 (TID 13) in 690 ms on localhost (3/7)
2015-11-03 21:26:07,271 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:07,271 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:07,272 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 21:26:07,272 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:26:08,104 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511032125_0005_m_000003_14' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511032125_0005_m_000003
2015-11-03 21:26:08,104 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511032125_0005_m_000003_14: Committed
2015-11-03 21:26:08,105 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 5.0 (TID 14). 1165 bytes result sent to driver
2015-11-03 21:26:08,106 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 5.0 (TID 15, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 21:26:08,106 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 5.0 (TID 15)
2015-11-03 21:26:08,106 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 5.0 (TID 14) in 867 ms on localhost (4/7)
2015-11-03 21:26:08,171 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:08,171 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:08,172 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 21:26:08,173 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:26:09,150 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511032125_0005_m_000004_15' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511032125_0005_m_000004
2015-11-03 21:26:09,151 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511032125_0005_m_000004_15: Committed
2015-11-03 21:26:09,151 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 5.0 (TID 15). 1165 bytes result sent to driver
2015-11-03 21:26:09,152 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 5.0 (TID 16, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 21:26:09,152 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 5.0 (TID 15) in 1047 ms on localhost (5/7)
2015-11-03 21:26:09,152 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 5.0 (TID 16)
2015-11-03 21:26:09,166 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:09,166 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:09,167 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 21:26:09,167 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:11,062 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511032125_0005_m_000005_16' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511032125_0005_m_000005
2015-11-03 21:26:11,062 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511032125_0005_m_000005_16: Committed
2015-11-03 21:26:11,062 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 5.0 (TID 16). 1165 bytes result sent to driver
2015-11-03 21:26:11,063 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 5.0 (TID 17, localhost, PROCESS_LOCAL, 1974 bytes)
2015-11-03 21:26:11,064 INFO  org.apache.spark.executor.Executor - Running task 6.0 in stage 5.0 (TID 17)
2015-11-03 21:26:11,064 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 5.0 (TID 16) in 1913 ms on localhost (6/7)
2015-11-03 21:26:11,078 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:11,078 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:11,079 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 7 non-empty blocks out of 7 blocks
2015-11-03 21:26:11,079 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:11,907 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511032125_0005_m_000006_17' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/_temporary/0/task_201511032125_0005_m_000006
2015-11-03 21:26:11,908 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511032125_0005_m_000006_17: Committed
2015-11-03 21:26:11,908 INFO  org.apache.spark.executor.Executor - Finished task 6.0 in stage 5.0 (TID 17). 1165 bytes result sent to driver
2015-11-03 21:26:11,909 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 5.0 (TID 17) in 846 ms on localhost (7/7)
2015-11-03 21:26:11,909 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-11-03 21:26:11,909 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 5 (saveAsTextFile at Join.scala:72) finished in 9.193 s
2015-11-03 21:26:11,910 INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: saveAsTextFile at Join.scala:72, took 14.469223 s
2015-11-03 21:26:14,354 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(64288) called with curMem=593732, maxMem=505361203
2015-11-03 21:26:14,355 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 62.8 KB, free 481.3 MB)
2015-11-03 21:26:14,415 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(14119) called with curMem=658020, maxMem=505361203
2015-11-03 21:26:14,416 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.8 KB, free 481.3 MB)
2015-11-03 21:26:14,601 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on localhost:51702 (size: 13.8 KB, free: 481.9 MB)
2015-11-03 21:26:14,603 INFO  org.apache.spark.SparkContext - Created broadcast 10 from textFile at Join.scala:75
2015-11-03 21:26:15,291 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(148024) called with curMem=672139, maxMem=505361203
2015-11-03 21:26:15,291 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 144.6 KB, free 481.2 MB)
2015-11-03 21:26:15,311 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(14119) called with curMem=820163, maxMem=505361203
2015-11-03 21:26:15,312 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 13.8 KB, free 481.2 MB)
2015-11-03 21:26:15,316 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on localhost:51702 (size: 13.8 KB, free: 481.9 MB)
2015-11-03 21:26:15,317 INFO  org.apache.spark.SparkContext - Created broadcast 11 from textFile at Join.scala:83
2015-11-03 21:26:19,523 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 7
2015-11-03 21:26:19,625 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-11-03 21:26:19,994 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at Join.scala:94
2015-11-03 21:26:19,996 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 27 (map at Join.scala:83)
2015-11-03 21:26:19,996 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 24 (map at Join.scala:75)
2015-11-03 21:26:19,997 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 32 (coalesce at Join.scala:94)
2015-11-03 21:26:19,997 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 2 (saveAsTextFile at Join.scala:94) with 3 output partitions
2015-11-03 21:26:19,997 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 9(saveAsTextFile at Join.scala:94)
2015-11-03 21:26:19,997 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 8)
2015-11-03 21:26:19,998 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 8)
2015-11-03 21:26:19,998 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 6 (MapPartitionsRDD[27] at map at Join.scala:83), which has no missing parents
2015-11-03 21:26:20,002 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3544) called with curMem=834282, maxMem=505361203
2015-11-03 21:26:20,003 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 3.5 KB, free 481.2 MB)
2015-11-03 21:26:20,004 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2098) called with curMem=837826, maxMem=505361203
2015-11-03 21:26:20,004 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.1 MB)
2015-11-03 21:26:20,005 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on localhost:51702 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 21:26:20,006 INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:861
2015-11-03 21:26:20,006 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 17 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[27] at map at Join.scala:83)
2015-11-03 21:26:20,007 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 17 tasks
2015-11-03 21:26:20,007 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at map at Join.scala:75), which has no missing parents
2015-11-03 21:26:20,008 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 18, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:20,009 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3544) called with curMem=839924, maxMem=505361203
2015-11-03 21:26:20,009 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 3.5 KB, free 481.1 MB)
2015-11-03 21:26:20,011 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2096) called with curMem=843468, maxMem=505361203
2015-11-03 21:26:20,011 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.0 KB, free 481.1 MB)
2015-11-03 21:26:20,012 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 18)
2015-11-03 21:26:20,012 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_13_piece0 in memory on localhost:51702 (size: 2.0 KB, free: 481.9 MB)
2015-11-03 21:26:20,013 INFO  org.apache.spark.SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:861
2015-11-03 21:26:20,013 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at map at Join.scala:75)
2015-11-03 21:26:20,014 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks
2015-11-03 21:26:20,017 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00000:0+33554432
2015-11-03 21:26:21,020 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 18). 2269 bytes result sent to driver
2015-11-03 21:26:21,021 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 6.0 (TID 19, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:21,021 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 18) in 1014 ms on localhost (1/17)
2015-11-03 21:26:21,022 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 6.0 (TID 19)
2015-11-03 21:26:21,025 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00000:33554432+34824632
2015-11-03 21:26:22,026 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 6.0 (TID 19). 2269 bytes result sent to driver
2015-11-03 21:26:22,027 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 6.0 (TID 20, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:22,027 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 6.0 (TID 20)
2015-11-03 21:26:22,027 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 6.0 (TID 19) in 1007 ms on localhost (2/17)
2015-11-03 21:26:22,031 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00001:0+33554432
2015-11-03 21:26:22,928 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 6.0 (TID 20). 2269 bytes result sent to driver
2015-11-03 21:26:22,929 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 6.0 (TID 21, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:22,930 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 6.0 (TID 21)
2015-11-03 21:26:22,930 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 6.0 (TID 20) in 904 ms on localhost (3/17)
2015-11-03 21:26:22,933 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00001:33554432+36145941
2015-11-03 21:26:23,731 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 6.0 (TID 21). 2269 bytes result sent to driver
2015-11-03 21:26:23,732 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 6.0 (TID 22, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:23,732 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 6.0 (TID 21) in 804 ms on localhost (4/17)
2015-11-03 21:26:23,733 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 6.0 (TID 22)
2015-11-03 21:26:23,736 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00002:0+33554432
2015-11-03 21:26:24,543 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 6.0 (TID 22). 2269 bytes result sent to driver
2015-11-03 21:26:24,545 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 6.0 (TID 23, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:24,545 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 6.0 (TID 22) in 814 ms on localhost (5/17)
2015-11-03 21:26:24,546 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 6.0 (TID 23)
2015-11-03 21:26:24,550 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00002:33554432+4326235
2015-11-03 21:26:24,779 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 6.0 (TID 23). 2269 bytes result sent to driver
2015-11-03 21:26:24,780 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 6.0 (TID 24, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:24,781 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 6.0 (TID 23) in 237 ms on localhost (6/17)
2015-11-03 21:26:24,782 INFO  org.apache.spark.executor.Executor - Running task 6.0 in stage 6.0 (TID 24)
2015-11-03 21:26:24,786 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00003:0+33554432
2015-11-03 21:26:25,945 INFO  org.apache.spark.executor.Executor - Finished task 6.0 in stage 6.0 (TID 24). 2269 bytes result sent to driver
2015-11-03 21:26:25,946 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 6.0 (TID 25, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:25,947 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 6.0 (TID 24) in 1168 ms on localhost (7/17)
2015-11-03 21:26:25,947 INFO  org.apache.spark.executor.Executor - Running task 7.0 in stage 6.0 (TID 25)
2015-11-03 21:26:25,950 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00003:33554432+7937584
2015-11-03 21:26:26,209 INFO  org.apache.spark.executor.Executor - Finished task 7.0 in stage 6.0 (TID 25). 2269 bytes result sent to driver
2015-11-03 21:26:26,211 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 8.0 in stage 6.0 (TID 26, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:26,211 INFO  org.apache.spark.executor.Executor - Running task 8.0 in stage 6.0 (TID 26)
2015-11-03 21:26:26,211 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 6.0 (TID 25) in 265 ms on localhost (8/17)
2015-11-03 21:26:26,215 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00004:0+33554432
2015-11-03 21:26:27,078 INFO  org.apache.spark.executor.Executor - Finished task 8.0 in stage 6.0 (TID 26). 2269 bytes result sent to driver
2015-11-03 21:26:27,079 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 9.0 in stage 6.0 (TID 27, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:27,080 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 8.0 in stage 6.0 (TID 26) in 870 ms on localhost (9/17)
2015-11-03 21:26:27,080 INFO  org.apache.spark.executor.Executor - Running task 9.0 in stage 6.0 (TID 27)
2015-11-03 21:26:27,083 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00004:33554432+36440007
2015-11-03 21:26:27,863 INFO  org.apache.spark.executor.Executor - Finished task 9.0 in stage 6.0 (TID 27). 2269 bytes result sent to driver
2015-11-03 21:26:27,864 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 10.0 in stage 6.0 (TID 28, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:27,865 INFO  org.apache.spark.executor.Executor - Running task 10.0 in stage 6.0 (TID 28)
2015-11-03 21:26:27,865 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 9.0 in stage 6.0 (TID 27) in 786 ms on localhost (10/17)
2015-11-03 21:26:27,868 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00005:0+33554432
2015-11-03 21:26:28,528 INFO  org.apache.spark.executor.Executor - Finished task 10.0 in stage 6.0 (TID 28). 2269 bytes result sent to driver
2015-11-03 21:26:28,530 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 11.0 in stage 6.0 (TID 29, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:28,530 INFO  org.apache.spark.executor.Executor - Running task 11.0 in stage 6.0 (TID 29)
2015-11-03 21:26:28,530 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 10.0 in stage 6.0 (TID 28) in 667 ms on localhost (11/17)
2015-11-03 21:26:28,533 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00005:33554432+33554432
2015-11-03 21:26:29,276 INFO  org.apache.spark.executor.Executor - Finished task 11.0 in stage 6.0 (TID 29). 2269 bytes result sent to driver
2015-11-03 21:26:29,277 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 12.0 in stage 6.0 (TID 30, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:29,278 INFO  org.apache.spark.executor.Executor - Running task 12.0 in stage 6.0 (TID 30)
2015-11-03 21:26:29,278 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 11.0 in stage 6.0 (TID 29) in 749 ms on localhost (12/17)
2015-11-03 21:26:29,281 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00005:67108864+33554432
2015-11-03 21:26:30,021 INFO  org.apache.spark.executor.Executor - Finished task 12.0 in stage 6.0 (TID 30). 2269 bytes result sent to driver
2015-11-03 21:26:30,022 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 13.0 in stage 6.0 (TID 31, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:30,023 INFO  org.apache.spark.executor.Executor - Running task 13.0 in stage 6.0 (TID 31)
2015-11-03 21:26:30,023 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 12.0 in stage 6.0 (TID 30) in 746 ms on localhost (13/17)
2015-11-03 21:26:30,026 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00005:100663296+33554432
2015-11-03 21:26:30,709 INFO  org.apache.spark.executor.Executor - Finished task 13.0 in stage 6.0 (TID 31). 2269 bytes result sent to driver
2015-11-03 21:26:30,712 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 14.0 in stage 6.0 (TID 32, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:30,714 INFO  org.apache.spark.executor.Executor - Running task 14.0 in stage 6.0 (TID 32)
2015-11-03 21:26:30,715 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 13.0 in stage 6.0 (TID 31) in 693 ms on localhost (14/17)
2015-11-03 21:26:30,722 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00005:134217728+15369355
2015-11-03 21:26:31,223 INFO  org.apache.spark.executor.Executor - Finished task 14.0 in stage 6.0 (TID 32). 2269 bytes result sent to driver
2015-11-03 21:26:31,224 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 15.0 in stage 6.0 (TID 33, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:31,224 INFO  org.apache.spark.executor.Executor - Running task 15.0 in stage 6.0 (TID 33)
2015-11-03 21:26:31,225 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 14.0 in stage 6.0 (TID 32) in 515 ms on localhost (15/17)
2015-11-03 21:26:31,227 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00006:0+33554432
2015-11-03 21:26:31,947 INFO  org.apache.spark.executor.Executor - Finished task 15.0 in stage 6.0 (TID 33). 2269 bytes result sent to driver
2015-11-03 21:26:31,948 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 16.0 in stage 6.0 (TID 34, localhost, PROCESS_LOCAL, 2183 bytes)
2015-11-03 21:26:31,948 INFO  org.apache.spark.executor.Executor - Running task 16.0 in stage 6.0 (TID 34)
2015-11-03 21:26:31,949 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 15.0 in stage 6.0 (TID 33) in 724 ms on localhost (16/17)
2015-11-03 21:26:31,951 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserInfo/part-00006:33554432+17559114
2015-11-03 21:26:32,462 INFO  org.apache.spark.executor.Executor - Finished task 16.0 in stage 6.0 (TID 34). 2269 bytes result sent to driver
2015-11-03 21:26:32,463 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 35, localhost, PROCESS_LOCAL, 2184 bytes)
2015-11-03 21:26:32,464 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 16.0 in stage 6.0 (TID 34) in 517 ms on localhost (17/17)
2015-11-03 21:26:32,464 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-11-03 21:26:32,464 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 6 (map at Join.scala:83) finished in 12.457 s
2015-11-03 21:26:32,464 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 21:26:32,465 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set(ShuffleMapStage 7)
2015-11-03 21:26:32,465 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 9, ShuffleMapStage 8)
2015-11-03 21:26:32,465 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 21:26:32,465 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 9: List(ShuffleMapStage 8)
2015-11-03 21:26:32,465 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 8: List(ShuffleMapStage 7)
2015-11-03 21:26:32,466 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 35)
2015-11-03 21:26:32,469 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelInfo/part-00000:0+46479
2015-11-03 21:26:32,548 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 35). 2269 bytes result sent to driver
2015-11-03 21:26:32,550 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 35) in 87 ms on localhost (1/1)
2015-11-03 21:26:32,550 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 7 (map at Join.scala:75) finished in 12.536 s
2015-11-03 21:26:32,551 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 21:26:32,551 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2015-11-03 21:26:32,551 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 21:26:32,551 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 9, ShuffleMapStage 8)
2015-11-03 21:26:32,551 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 21:26:32,551 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 9: List(ShuffleMapStage 8)
2015-11-03 21:26:32,551 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 8: List()
2015-11-03 21:26:32,552 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 8 (MapPartitionsRDD[32] at coalesce at Join.scala:94), which is now runnable
2015-11-03 21:26:32,556 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3240) called with curMem=845564, maxMem=505361203
2015-11-03 21:26:32,556 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_14 stored as values in memory (estimated size 3.2 KB, free 481.1 MB)
2015-11-03 21:26:32,557 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1726) called with curMem=848804, maxMem=505361203
2015-11-03 21:26:32,557 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 1726.0 B, free 481.1 MB)
2015-11-03 21:26:32,558 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_14_piece0 in memory on localhost:51702 (size: 1726.0 B, free: 481.8 MB)
2015-11-03 21:26:32,559 INFO  org.apache.spark.SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:861
2015-11-03 21:26:32,559 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 17 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[32] at coalesce at Join.scala:94)
2015-11-03 21:26:32,560 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 17 tasks
2015-11-03 21:26:32,561 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 36, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:32,561 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 36)
2015-11-03 21:26:32,564 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:32,564 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:32,565 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:32,565 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:33,085 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_13_piece0 on localhost:51702 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 21:26:33,087 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_12_piece0 on localhost:51702 in memory (size: 2.0 KB, free: 481.9 MB)
2015-11-03 21:26:33,089 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_9_piece0 on localhost:51702 in memory (size: 30.7 KB, free: 481.9 MB)
2015-11-03 21:26:33,090 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 6
2015-11-03 21:26:33,090 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 5
2015-11-03 21:26:33,090 INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 4
2015-11-03 21:26:33,649 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 36). 1376 bytes result sent to driver
2015-11-03 21:26:33,650 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 8.0 (TID 37, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:33,650 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 8.0 (TID 37)
2015-11-03 21:26:33,651 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 36) in 1090 ms on localhost (1/17)
2015-11-03 21:26:33,653 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:33,654 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:26:33,654 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:33,654 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:34,528 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 8.0 (TID 37). 1376 bytes result sent to driver
2015-11-03 21:26:34,529 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 8.0 (TID 38, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:34,529 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 8.0 (TID 37) in 879 ms on localhost (2/17)
2015-11-03 21:26:34,529 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 8.0 (TID 38)
2015-11-03 21:26:34,546 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:34,546 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:26:34,547 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:34,548 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:26:34,927 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 8.0 (TID 38). 1376 bytes result sent to driver
2015-11-03 21:26:34,928 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 8.0 (TID 39, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:34,928 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 8.0 (TID 39)
2015-11-03 21:26:34,929 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 8.0 (TID 38) in 400 ms on localhost (3/17)
2015-11-03 21:26:34,931 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:34,932 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:26:34,932 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:34,932 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:35,400 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 8.0 (TID 39). 1376 bytes result sent to driver
2015-11-03 21:26:35,401 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 8.0 (TID 40, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:35,401 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 8.0 (TID 40)
2015-11-03 21:26:35,401 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 8.0 (TID 39) in 473 ms on localhost (4/17)
2015-11-03 21:26:35,404 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:35,404 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:35,405 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:35,405 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:35,825 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 8.0 (TID 40). 1376 bytes result sent to driver
2015-11-03 21:26:35,826 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 8.0 (TID 41, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:35,826 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 8.0 (TID 41)
2015-11-03 21:26:35,826 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 8.0 (TID 40) in 425 ms on localhost (5/17)
2015-11-03 21:26:35,829 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:35,829 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:35,829 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:35,829 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:36,281 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 8.0 (TID 41). 1376 bytes result sent to driver
2015-11-03 21:26:36,282 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 8.0 (TID 42, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:36,282 INFO  org.apache.spark.executor.Executor - Running task 6.0 in stage 8.0 (TID 42)
2015-11-03 21:26:36,282 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 8.0 (TID 41) in 457 ms on localhost (6/17)
2015-11-03 21:26:36,285 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:36,285 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:36,286 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:36,286 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:36,645 INFO  org.apache.spark.executor.Executor - Finished task 6.0 in stage 8.0 (TID 42). 1376 bytes result sent to driver
2015-11-03 21:26:36,645 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 8.0 (TID 43, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:36,646 INFO  org.apache.spark.executor.Executor - Running task 7.0 in stage 8.0 (TID 43)
2015-11-03 21:26:36,646 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 8.0 (TID 42) in 365 ms on localhost (7/17)
2015-11-03 21:26:36,649 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:36,649 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:26:36,649 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:36,649 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:37,229 INFO  org.apache.spark.executor.Executor - Finished task 7.0 in stage 8.0 (TID 43). 1376 bytes result sent to driver
2015-11-03 21:26:37,230 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 8.0 in stage 8.0 (TID 44, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:37,230 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 8.0 (TID 43) in 585 ms on localhost (8/17)
2015-11-03 21:26:37,230 INFO  org.apache.spark.executor.Executor - Running task 8.0 in stage 8.0 (TID 44)
2015-11-03 21:26:37,233 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:37,233 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:37,234 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:37,234 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:38,011 INFO  org.apache.spark.executor.Executor - Finished task 8.0 in stage 8.0 (TID 44). 1376 bytes result sent to driver
2015-11-03 21:26:38,012 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 9.0 in stage 8.0 (TID 45, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:38,013 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 8.0 in stage 8.0 (TID 44) in 783 ms on localhost (9/17)
2015-11-03 21:26:38,013 INFO  org.apache.spark.executor.Executor - Running task 9.0 in stage 8.0 (TID 45)
2015-11-03 21:26:38,016 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:38,016 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:38,016 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:38,016 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:38,732 INFO  org.apache.spark.executor.Executor - Finished task 9.0 in stage 8.0 (TID 45). 1376 bytes result sent to driver
2015-11-03 21:26:38,733 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 10.0 in stage 8.0 (TID 46, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:38,733 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 9.0 in stage 8.0 (TID 45) in 721 ms on localhost (10/17)
2015-11-03 21:26:38,733 INFO  org.apache.spark.executor.Executor - Running task 10.0 in stage 8.0 (TID 46)
2015-11-03 21:26:38,736 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:38,737 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:26:38,737 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:38,737 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:39,136 INFO  org.apache.spark.executor.Executor - Finished task 10.0 in stage 8.0 (TID 46). 1376 bytes result sent to driver
2015-11-03 21:26:39,137 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 11.0 in stage 8.0 (TID 47, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:39,137 INFO  org.apache.spark.executor.Executor - Running task 11.0 in stage 8.0 (TID 47)
2015-11-03 21:26:39,137 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 10.0 in stage 8.0 (TID 46) in 405 ms on localhost (11/17)
2015-11-03 21:26:39,140 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:39,140 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:39,141 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:39,141 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:40,301 INFO  org.apache.spark.executor.Executor - Finished task 11.0 in stage 8.0 (TID 47). 1376 bytes result sent to driver
2015-11-03 21:26:40,302 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 12.0 in stage 8.0 (TID 48, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:40,302 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 11.0 in stage 8.0 (TID 47) in 1166 ms on localhost (12/17)
2015-11-03 21:26:40,302 INFO  org.apache.spark.executor.Executor - Running task 12.0 in stage 8.0 (TID 48)
2015-11-03 21:26:40,306 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:40,306 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:26:40,306 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:40,306 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:41,341 INFO  org.apache.spark.executor.Executor - Finished task 12.0 in stage 8.0 (TID 48). 1376 bytes result sent to driver
2015-11-03 21:26:41,342 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 13.0 in stage 8.0 (TID 49, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:41,342 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 12.0 in stage 8.0 (TID 48) in 1040 ms on localhost (13/17)
2015-11-03 21:26:41,342 INFO  org.apache.spark.executor.Executor - Running task 13.0 in stage 8.0 (TID 49)
2015-11-03 21:26:41,345 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:41,345 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:41,345 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:41,346 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:26:42,741 INFO  org.apache.spark.executor.Executor - Finished task 13.0 in stage 8.0 (TID 49). 1376 bytes result sent to driver
2015-11-03 21:26:42,741 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 14.0 in stage 8.0 (TID 50, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:42,742 INFO  org.apache.spark.executor.Executor - Running task 14.0 in stage 8.0 (TID 50)
2015-11-03 21:26:42,742 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 13.0 in stage 8.0 (TID 49) in 1401 ms on localhost (14/17)
2015-11-03 21:26:42,745 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:42,745 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:42,746 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:42,746 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:43,213 INFO  org.apache.spark.executor.Executor - Finished task 14.0 in stage 8.0 (TID 50). 1376 bytes result sent to driver
2015-11-03 21:26:43,214 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 15.0 in stage 8.0 (TID 51, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:43,214 INFO  org.apache.spark.executor.Executor - Running task 15.0 in stage 8.0 (TID 51)
2015-11-03 21:26:43,214 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 14.0 in stage 8.0 (TID 50) in 473 ms on localhost (15/17)
2015-11-03 21:26:43,217 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:43,217 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:43,218 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:43,218 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:44,168 INFO  org.apache.spark.util.collection.ExternalAppendOnlyMap - Thread 64 spilling in-memory map of 147.8 MB to disk (1 time so far)
2015-11-03 21:26:45,230 INFO  org.apache.spark.util.collection.ExternalAppendOnlyMap - Thread 64 spilling in-memory map of 147.8 MB to disk (2 times so far)
2015-11-03 21:26:47,515 INFO  org.apache.spark.executor.Executor - Finished task 15.0 in stage 8.0 (TID 51). 1376 bytes result sent to driver
2015-11-03 21:26:47,516 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 16.0 in stage 8.0 (TID 52, localhost, PROCESS_LOCAL, 1963 bytes)
2015-11-03 21:26:47,516 INFO  org.apache.spark.executor.Executor - Running task 16.0 in stage 8.0 (TID 52)
2015-11-03 21:26:47,516 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 15.0 in stage 8.0 (TID 51) in 4303 ms on localhost (16/17)
2015-11-03 21:26:47,519 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2015-11-03 21:26:47,519 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:47,520 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:47,520 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-03 21:26:47,928 INFO  org.apache.spark.executor.Executor - Finished task 16.0 in stage 8.0 (TID 52). 1376 bytes result sent to driver
2015-11-03 21:26:47,929 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 16.0 in stage 8.0 (TID 52) in 414 ms on localhost (17/17)
2015-11-03 21:26:47,930 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2015-11-03 21:26:47,930 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 8 (coalesce at Join.scala:94) finished in 15.369 s
2015-11-03 21:26:47,930 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-03 21:26:47,930 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-03 21:26:47,930 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 9)
2015-11-03 21:26:47,930 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-03 21:26:47,930 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 9: List()
2015-11-03 21:26:47,931 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 9 (MapPartitionsRDD[36] at saveAsTextFile at Join.scala:94), which is now runnable
2015-11-03 21:26:47,974 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95832) called with curMem=711816, maxMem=505361203
2015-11-03 21:26:47,974 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_15 stored as values in memory (estimated size 93.6 KB, free 481.2 MB)
2015-11-03 21:26:47,976 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31415) called with curMem=807648, maxMem=505361203
2015-11-03 21:26:47,976 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 30.7 KB, free 481.1 MB)
2015-11-03 21:26:47,979 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_15_piece0 in memory on localhost:51702 (size: 30.7 KB, free: 481.9 MB)
2015-11-03 21:26:47,980 INFO  org.apache.spark.SparkContext - Created broadcast 15 from broadcast at DAGScheduler.scala:861
2015-11-03 21:26:47,980 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 3 missing tasks from ResultStage 9 (MapPartitionsRDD[36] at saveAsTextFile at Join.scala:94)
2015-11-03 21:26:47,980 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 3 tasks
2015-11-03 21:26:48,025 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 53, localhost, PROCESS_LOCAL, 2170 bytes)
2015-11-03 21:26:48,025 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 53)
2015-11-03 21:26:48,056 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:48,056 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:49,396 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511032126_0009_m_000000_53' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511032126_0009_m_000000
2015-11-03 21:26:49,396 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511032126_0009_m_000000_53: Committed
2015-11-03 21:26:49,396 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 53). 1165 bytes result sent to driver
2015-11-03 21:26:49,397 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 9.0 (TID 54, localhost, PROCESS_LOCAL, 2170 bytes)
2015-11-03 21:26:49,397 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 9.0 (TID 54)
2015-11-03 21:26:49,398 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 53) in 1416 ms on localhost (1/3)
2015-11-03 21:26:49,418 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:49,418 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:50,795 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511032126_0009_m_000001_54' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511032126_0009_m_000001
2015-11-03 21:26:50,795 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511032126_0009_m_000001_54: Committed
2015-11-03 21:26:50,795 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 9.0 (TID 54). 1165 bytes result sent to driver
2015-11-03 21:26:50,796 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 9.0 (TID 55, localhost, PROCESS_LOCAL, 2170 bytes)
2015-11-03 21:26:50,797 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 9.0 (TID 54) in 1400 ms on localhost (2/3)
2015-11-03 21:26:50,797 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 9.0 (TID 55)
2015-11-03 21:26:50,819 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 17 non-empty blocks out of 17 blocks
2015-11-03 21:26:50,819 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-03 21:26:52,004 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511032126_0009_m_000002_55' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/_temporary/0/task_201511032126_0009_m_000002
2015-11-03 21:26:52,004 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511032126_0009_m_000002_55: Committed
2015-11-03 21:26:52,004 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 9.0 (TID 55). 1165 bytes result sent to driver
2015-11-03 21:26:52,005 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 9.0 (TID 55) in 1209 ms on localhost (3/3)
2015-11-03 21:26:52,005 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 9 (saveAsTextFile at Join.scala:94) finished in 4.024 s
2015-11-03 21:26:52,005 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2015-11-03 21:26:52,006 INFO  org.apache.spark.scheduler.DAGScheduler - Job 2 finished: saveAsTextFile at Join.scala:94, took 32.010639 s
2015-11-03 21:26:52,116 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-03 21:26:52,235 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-03 21:26:52,238 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-03 21:26:52,238 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-03 21:26:52,239 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-03 21:26:52,239 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-03 21:26:52,239 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-03 21:26:52,239 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-03 21:26:52,239 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-03 21:26:52,240 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-03 21:26:52,240 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-03 21:26:52,240 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-03 21:26:52,240 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-03 21:26:52,241 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-03 21:26:52,241 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-03 21:26:52,241 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-03 21:26:52,241 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-03 21:26:52,241 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-03 21:26:52,242 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-03 21:26:52,242 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-03 21:26:52,242 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-03 21:26:52,243 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-03 21:26:52,243 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-03 21:26:52,243 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-03 21:26:52,243 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-03 21:26:52,243 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-03 21:26:52,356 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-03 21:26:52,446 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-03 21:26:53,567 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-03 21:26:53,874 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-03 21:26:53,886 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-03 21:26:53,887 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-03 21:26:53,972 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-03 21:26:53,982 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-03 21:26:54,023 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-03 21:26:54,089 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-96c48d05-0a44-48cd-b0a0-36e1eed215af
2015-11-10 21:55:37,345 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-10 21:55:41,168 ERROR org.apache.spark.SparkContext - Error initializing SparkContext.
org.apache.spark.SparkException: A master URL must be set in your configuration
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:385)
	at Statistic$.main(Statistic.scala:13)
	at Statistic.main(Statistic.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-11-10 21:55:41,244 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-10 21:56:00,878 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-10 21:56:02,493 ERROR org.apache.spark.SparkContext - Error initializing SparkContext.
org.apache.spark.SparkException: An application name must be set in your configuration
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:388)
	at Statistic$.main(Statistic.scala:14)
	at Statistic.main(Statistic.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-11-10 21:56:02,504 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-10 21:56:27,833 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-10 21:56:29,674 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-10 21:56:29,686 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-10 21:56:29,686 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-10 21:56:32,087 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-10 21:56:32,355 INFO  Remoting - Starting remoting
2015-11-10 21:56:32,956 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:52277]
2015-11-10 21:56:32,968 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52277.
2015-11-10 21:56:33,080 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-10 21:56:33,126 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-10 21:56:33,203 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-70f29a72-8327-4400-a46c-c62228478db2
2015-11-10 21:56:33,285 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-10 21:56:33,489 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-f2ea923e-6b7f-49ed-acc6-84b653edb64f\httpd-737bb930-b0bf-4fd5-aa2d-4d8b908fa790
2015-11-10 21:56:33,526 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-10 21:56:33,678 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-10 21:56:33,714 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:52280
2015-11-10 21:56:33,714 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 52280.
2015-11-10 21:56:33,776 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-10 21:56:34,410 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-10 21:56:34,435 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-10 21:56:34,436 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-10 21:56:34,438 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-10 21:56:34,811 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-10 21:56:34,817 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-10 21:56:35,488 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52304.
2015-11-10 21:56:35,489 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 52304
2015-11-10 21:56:35,527 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-10 21:56:35,542 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:52304 with 481.9 MB RAM, BlockManagerId(driver, localhost, 52304)
2015-11-10 21:56:35,546 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-10 21:56:37,796 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-10 21:56:37,806 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-10 21:56:37,951 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-10 21:56:37,952 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-10 21:56:37,955 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:52304 (size: 9.8 KB, free: 481.9 MB)
2015-11-10 21:56:38,103 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at Statistic.scala:18
2015-11-10 21:56:39,997 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:105%30, but we couldn't find any external IP address!
2015-11-10 21:56:41,641 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 3
2015-11-10 21:56:41,815 INFO  org.apache.spark.SparkContext - Starting job: count at Statistic.scala:20
2015-11-10 21:56:41,909 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 3 (map at Statistic.scala:19)
2015-11-10 21:56:41,917 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (count at Statistic.scala:20) with 6 output partitions
2015-11-10 21:56:41,918 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 1(count at Statistic.scala:20)
2015-11-10 21:56:41,918 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 0)
2015-11-10 21:56:41,921 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 0)
2015-11-10 21:56:42,006 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at Statistic.scala:19), which has no missing parents
2015-11-10 21:56:42,194 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3928) called with curMem=116545, maxMem=505361203
2015-11-10 21:56:42,194 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 481.8 MB)
2015-11-10 21:56:42,197 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2272) called with curMem=120473, maxMem=505361203
2015-11-10 21:56:42,198 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 481.8 MB)
2015-11-10 21:56:42,199 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:52304 (size: 2.2 KB, free: 481.9 MB)
2015-11-10 21:56:42,201 INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-11-10 21:56:42,216 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at Statistic.scala:19)
2015-11-10 21:56:42,219 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 6 tasks
2015-11-10 21:56:42,304 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:56:42,352 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-10 21:56:42,468 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:0+33554432
2015-11-10 21:56:42,564 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-10 21:56:42,564 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-10 21:56:42,564 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-10 21:56:42,564 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-10 21:56:42,564 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-10 21:56:52,194 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2258 bytes result sent to driver
2015-11-10 21:56:52,197 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:56:52,198 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2015-11-10 21:56:52,206 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:33554432+20843526
2015-11-10 21:56:52,211 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 9939 ms on localhost (1/6)
2015-11-10 21:56:55,940 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 2258 bytes result sent to driver
2015-11-10 21:56:55,942 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:56:55,943 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
2015-11-10 21:56:55,945 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 3748 ms on localhost (2/6)
2015-11-10 21:56:55,951 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:0+33554432
2015-11-10 21:56:57,544 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 2258 bytes result sent to driver
2015-11-10 21:56:57,546 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:56:57,546 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
2015-11-10 21:56:57,548 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 1606 ms on localhost (3/6)
2015-11-10 21:56:57,554 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:33554432+20844232
2015-11-10 21:56:58,183 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 2258 bytes result sent to driver
2015-11-10 21:56:58,184 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:56:58,185 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
2015-11-10 21:56:58,186 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 641 ms on localhost (4/6)
2015-11-10 21:56:58,190 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:0+33554432
2015-11-10 21:56:58,940 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 2258 bytes result sent to driver
2015-11-10 21:56:58,941 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 0.0 (TID 5, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:56:58,941 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 0.0 (TID 5)
2015-11-10 21:56:58,942 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 759 ms on localhost (5/6)
2015-11-10 21:56:58,947 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:33554432+20845196
2015-11-10 21:56:59,239 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 0.0 (TID 5). 2258 bytes result sent to driver
2015-11-10 21:56:59,298 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 0.0 (TID 5) in 357 ms on localhost (6/6)
2015-11-10 21:56:59,298 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (map at Statistic.scala:19) finished in 17.049 s
2015-11-10 21:56:59,299 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-10 21:56:59,315 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-10 21:56:59,316 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-10 21:56:59,347 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 1)
2015-11-10 21:56:59,348 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-10 21:56:59,381 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 1: List()
2015-11-10 21:56:59,396 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (ShuffledRDD[4] at reduceByKey at Statistic.scala:19), which is now runnable
2015-11-10 21:56:59,402 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2104) called with curMem=122745, maxMem=505361203
2015-11-10 21:56:59,402 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.1 KB, free 481.8 MB)
2015-11-10 21:56:59,403 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1338) called with curMem=124849, maxMem=505361203
2015-11-10 21:56:59,404 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1338.0 B, free 481.8 MB)
2015-11-10 21:56:59,406 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:52304 (size: 1338.0 B, free: 481.9 MB)
2015-11-10 21:56:59,408 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-10 21:56:59,409 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 1 (ShuffledRDD[4] at reduceByKey at Statistic.scala:19)
2015-11-10 21:56:59,409 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 6 tasks
2015-11-10 21:56:59,412 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 6, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:56:59,413 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 6)
2015-11-10 21:56:59,468 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:56:59,480 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
2015-11-10 21:56:59,613 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 6). 1203 bytes result sent to driver
2015-11-10 21:56:59,614 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 7, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:56:59,615 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 6) in 205 ms on localhost (1/6)
2015-11-10 21:56:59,615 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 7)
2015-11-10 21:56:59,619 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:56:59,619 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-10 21:56:59,636 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 7). 1203 bytes result sent to driver
2015-11-10 21:56:59,641 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 1.0 (TID 8, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:56:59,642 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 1.0 (TID 8)
2015-11-10 21:56:59,642 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 7) in 29 ms on localhost (2/6)
2015-11-10 21:56:59,647 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:56:59,647 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-10 21:56:59,659 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 1.0 (TID 8). 1203 bytes result sent to driver
2015-11-10 21:56:59,660 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 1.0 (TID 9, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:56:59,661 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 1.0 (TID 8) in 21 ms on localhost (3/6)
2015-11-10 21:56:59,662 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 1.0 (TID 9)
2015-11-10 21:56:59,666 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:56:59,666 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-10 21:56:59,689 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 1.0 (TID 9). 1203 bytes result sent to driver
2015-11-10 21:56:59,690 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 1.0 (TID 10, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:56:59,692 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 1.0 (TID 9) in 32 ms on localhost (4/6)
2015-11-10 21:56:59,692 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 1.0 (TID 10)
2015-11-10 21:56:59,696 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:56:59,696 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-10 21:56:59,712 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 1.0 (TID 10). 1203 bytes result sent to driver
2015-11-10 21:56:59,731 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 1.0 (TID 11, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:56:59,732 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 1.0 (TID 11)
2015-11-10 21:56:59,732 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 1.0 (TID 10) in 43 ms on localhost (5/6)
2015-11-10 21:56:59,736 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:56:59,736 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-10 21:56:59,750 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 1.0 (TID 11). 1203 bytes result sent to driver
2015-11-10 21:56:59,752 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 1 (count at Statistic.scala:20) finished in 0.342 s
2015-11-10 21:56:59,752 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 1.0 (TID 11) in 22 ms on localhost (6/6)
2015-11-10 21:56:59,753 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-10 21:56:59,823 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: count at Statistic.scala:20, took 18.006679 s
2015-11-10 21:56:59,911 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-10 21:56:59,911 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-10 21:56:59,911 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-10 21:56:59,911 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-10 21:56:59,912 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-10 21:56:59,912 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-10 21:56:59,912 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-10 21:56:59,912 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-10 21:56:59,912 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-10 21:56:59,913 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-10 21:56:59,913 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-10 21:56:59,913 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-10 21:56:59,913 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-10 21:56:59,913 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-10 21:56:59,913 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-10 21:56:59,914 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-10 21:56:59,914 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-10 21:56:59,914 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-10 21:56:59,914 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-10 21:56:59,914 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-10 21:56:59,914 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-10 21:56:59,914 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-10 21:56:59,915 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-10 21:56:59,915 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-10 21:56:59,915 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-10 21:56:59,967 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-10 21:57:00,015 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-10 21:57:00,099 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-10 21:57:00,142 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-10 21:57:00,143 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-10 21:57:00,147 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-10 21:57:00,188 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-10 21:57:00,196 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-10 21:57:00,219 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-10 21:57:00,220 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-f2ea923e-6b7f-49ed-acc6-84b653edb64f
2015-11-10 21:59:06,544 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-10 21:59:08,170 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-10 21:59:08,171 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-10 21:59:08,172 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-10 21:59:09,181 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-10 21:59:09,241 INFO  Remoting - Starting remoting
2015-11-10 21:59:09,471 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:52682]
2015-11-10 21:59:09,478 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52682.
2015-11-10 21:59:09,503 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-10 21:59:09,520 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-10 21:59:09,573 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-0cbc3506-b22f-463a-b12d-8eecf591ca11
2015-11-10 21:59:09,588 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-10 21:59:09,713 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-0c0934bb-7c16-428d-97ed-5294d22b0870\httpd-b66f9c7a-5e14-46d2-bf65-0716e201874c
2015-11-10 21:59:09,720 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-10 21:59:09,830 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-10 21:59:09,869 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:52683
2015-11-10 21:59:09,869 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 52683.
2015-11-10 21:59:09,914 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-10 21:59:10,198 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-10 21:59:10,213 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-10 21:59:10,213 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-10 21:59:10,215 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-10 21:59:10,371 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-10 21:59:10,375 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-10 21:59:10,809 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52704.
2015-11-10 21:59:10,809 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 52704
2015-11-10 21:59:10,811 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-10 21:59:10,816 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:52704 with 481.9 MB RAM, BlockManagerId(driver, localhost, 52704)
2015-11-10 21:59:10,818 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-10 21:59:11,627 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-10 21:59:11,629 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-10 21:59:11,672 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-10 21:59:11,673 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-10 21:59:11,676 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:52704 (size: 9.8 KB, free: 481.9 MB)
2015-11-10 21:59:11,683 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at Statistic.scala:17
2015-11-10 21:59:13,083 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:105%30, but we couldn't find any external IP address!
2015-11-10 21:59:14,041 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 3
2015-11-10 21:59:14,069 INFO  org.apache.spark.SparkContext - Starting job: count at Statistic.scala:19
2015-11-10 21:59:14,106 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 3 (map at Statistic.scala:18)
2015-11-10 21:59:14,112 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (count at Statistic.scala:19) with 6 output partitions
2015-11-10 21:59:14,113 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 1(count at Statistic.scala:19)
2015-11-10 21:59:14,114 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 0)
2015-11-10 21:59:14,116 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 0)
2015-11-10 21:59:14,128 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at Statistic.scala:18), which has no missing parents
2015-11-10 21:59:14,199 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3928) called with curMem=116545, maxMem=505361203
2015-11-10 21:59:14,201 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 481.8 MB)
2015-11-10 21:59:14,234 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2267) called with curMem=120473, maxMem=505361203
2015-11-10 21:59:14,235 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 481.8 MB)
2015-11-10 21:59:14,236 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:52704 (size: 2.2 KB, free: 481.9 MB)
2015-11-10 21:59:14,238 INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-11-10 21:59:14,245 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at Statistic.scala:18)
2015-11-10 21:59:14,248 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 6 tasks
2015-11-10 21:59:14,327 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:59:14,335 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-10 21:59:14,361 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:0+33554432
2015-11-10 21:59:14,371 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-10 21:59:14,371 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-10 21:59:14,371 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-10 21:59:14,371 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-10 21:59:14,371 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-10 21:59:15,600 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2258 bytes result sent to driver
2015-11-10 21:59:15,603 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:59:15,604 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2015-11-10 21:59:15,612 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:33554432+20843526
2015-11-10 21:59:15,612 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1304 ms on localhost (1/6)
2015-11-10 21:59:16,020 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 2258 bytes result sent to driver
2015-11-10 21:59:16,022 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:59:16,022 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
2015-11-10 21:59:16,023 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 421 ms on localhost (2/6)
2015-11-10 21:59:16,028 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:0+33554432
2015-11-10 21:59:16,561 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 2258 bytes result sent to driver
2015-11-10 21:59:16,563 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:59:16,563 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
2015-11-10 21:59:16,568 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 547 ms on localhost (3/6)
2015-11-10 21:59:16,568 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:33554432+20844232
2015-11-10 21:59:16,885 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 2258 bytes result sent to driver
2015-11-10 21:59:16,887 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:59:16,887 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
2015-11-10 21:59:16,889 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 327 ms on localhost (4/6)
2015-11-10 21:59:16,893 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:0+33554432
2015-11-10 21:59:17,336 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 2258 bytes result sent to driver
2015-11-10 21:59:17,338 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 0.0 (TID 5, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:59:17,338 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 0.0 (TID 5)
2015-11-10 21:59:17,340 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 454 ms on localhost (5/6)
2015-11-10 21:59:17,343 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:33554432+20845196
2015-11-10 21:59:17,657 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 0.0 (TID 5). 2258 bytes result sent to driver
2015-11-10 21:59:17,660 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 0.0 (TID 5) in 323 ms on localhost (6/6)
2015-11-10 21:59:17,661 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (map at Statistic.scala:18) finished in 3.378 s
2015-11-10 21:59:17,661 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-10 21:59:17,661 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-10 21:59:17,662 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-10 21:59:17,662 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 1)
2015-11-10 21:59:17,663 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-10 21:59:17,665 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 1: List()
2015-11-10 21:59:17,668 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (ShuffledRDD[4] at reduceByKey at Statistic.scala:18), which is now runnable
2015-11-10 21:59:17,672 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2104) called with curMem=122740, maxMem=505361203
2015-11-10 21:59:17,673 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.1 KB, free 481.8 MB)
2015-11-10 21:59:17,673 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1338) called with curMem=124844, maxMem=505361203
2015-11-10 21:59:17,674 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1338.0 B, free 481.8 MB)
2015-11-10 21:59:17,675 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:52704 (size: 1338.0 B, free: 481.9 MB)
2015-11-10 21:59:17,676 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-10 21:59:17,677 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 1 (ShuffledRDD[4] at reduceByKey at Statistic.scala:18)
2015-11-10 21:59:17,678 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 6 tasks
2015-11-10 21:59:17,680 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 6, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:59:17,681 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 6)
2015-11-10 21:59:17,693 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:59:17,694 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 4 ms
2015-11-10 21:59:17,728 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 6). 1203 bytes result sent to driver
2015-11-10 21:59:17,730 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 7, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:59:17,730 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 7)
2015-11-10 21:59:17,732 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 6) in 53 ms on localhost (1/6)
2015-11-10 21:59:17,736 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:59:17,736 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-10 21:59:17,753 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 7). 1203 bytes result sent to driver
2015-11-10 21:59:17,754 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 1.0 (TID 8, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:59:17,755 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 1.0 (TID 8)
2015-11-10 21:59:17,756 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 7) in 26 ms on localhost (2/6)
2015-11-10 21:59:17,761 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:59:17,762 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-10 21:59:17,777 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 1.0 (TID 8). 1203 bytes result sent to driver
2015-11-10 21:59:17,779 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 1.0 (TID 9, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:59:17,779 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 1.0 (TID 8) in 26 ms on localhost (3/6)
2015-11-10 21:59:17,780 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 1.0 (TID 9)
2015-11-10 21:59:17,785 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:59:17,785 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-10 21:59:17,802 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 1.0 (TID 9). 1203 bytes result sent to driver
2015-11-10 21:59:17,803 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 1.0 (TID 10, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:59:17,803 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 1.0 (TID 10)
2015-11-10 21:59:17,803 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 1.0 (TID 9) in 26 ms on localhost (4/6)
2015-11-10 21:59:17,808 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:59:17,808 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-10 21:59:17,823 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 1.0 (TID 10). 1203 bytes result sent to driver
2015-11-10 21:59:17,824 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 1.0 (TID 11, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:59:17,824 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 1.0 (TID 11)
2015-11-10 21:59:17,825 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 1.0 (TID 10) in 23 ms on localhost (5/6)
2015-11-10 21:59:17,829 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:59:17,829 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-10 21:59:17,845 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 1.0 (TID 11). 1203 bytes result sent to driver
2015-11-10 21:59:17,847 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 1.0 (TID 11) in 24 ms on localhost (6/6)
2015-11-10 21:59:17,848 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-10 21:59:17,849 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 1 (count at Statistic.scala:19) finished in 0.170 s
2015-11-10 21:59:17,858 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: count at Statistic.scala:19, took 3.787077 s
2015-11-10 21:59:17,986 INFO  org.apache.spark.SparkContext - Starting job: count at Statistic.scala:23
2015-11-10 21:59:17,988 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 6 (map at Statistic.scala:22)
2015-11-10 21:59:17,989 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (count at Statistic.scala:23) with 6 output partitions
2015-11-10 21:59:17,989 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 3(count at Statistic.scala:23)
2015-11-10 21:59:17,989 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 2)
2015-11-10 21:59:17,989 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 2)
2015-11-10 21:59:17,990 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 2 (MapPartitionsRDD[6] at map at Statistic.scala:22), which has no missing parents
2015-11-10 21:59:17,993 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3928) called with curMem=126182, maxMem=505361203
2015-11-10 21:59:17,993 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 3.8 KB, free 481.8 MB)
2015-11-10 21:59:17,996 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2270) called with curMem=130110, maxMem=505361203
2015-11-10 21:59:17,996 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.2 KB, free 481.8 MB)
2015-11-10 21:59:17,997 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:52704 (size: 2.2 KB, free: 481.9 MB)
2015-11-10 21:59:17,998 INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-11-10 21:59:17,999 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[6] at map at Statistic.scala:22)
2015-11-10 21:59:17,999 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 6 tasks
2015-11-10 21:59:18,000 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 12, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:59:18,002 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 12)
2015-11-10 21:59:18,009 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:0+33554432
2015-11-10 21:59:18,328 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on localhost:52704 in memory (size: 1338.0 B, free: 481.9 MB)
2015-11-10 21:59:18,902 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 12). 2258 bytes result sent to driver
2015-11-10 21:59:18,908 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 13, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:59:18,908 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 12) in 909 ms on localhost (1/6)
2015-11-10 21:59:18,909 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 13)
2015-11-10 21:59:18,916 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:33554432+20843526
2015-11-10 21:59:19,292 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 13). 2258 bytes result sent to driver
2015-11-10 21:59:19,294 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 2.0 (TID 14, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:59:19,296 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 13) in 393 ms on localhost (2/6)
2015-11-10 21:59:19,296 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 2.0 (TID 14)
2015-11-10 21:59:19,302 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:0+33554432
2015-11-10 21:59:19,828 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 2.0 (TID 14). 2258 bytes result sent to driver
2015-11-10 21:59:19,829 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 2.0 (TID 15, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:59:19,829 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 2.0 (TID 15)
2015-11-10 21:59:19,830 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 2.0 (TID 14) in 537 ms on localhost (3/6)
2015-11-10 21:59:19,834 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:33554432+20844232
2015-11-10 21:59:20,201 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 2.0 (TID 15). 2258 bytes result sent to driver
2015-11-10 21:59:20,202 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 2.0 (TID 16, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:59:20,202 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 2.0 (TID 16)
2015-11-10 21:59:20,204 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 2.0 (TID 15) in 376 ms on localhost (4/6)
2015-11-10 21:59:20,208 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:0+33554432
2015-11-10 21:59:20,726 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 2.0 (TID 16). 2258 bytes result sent to driver
2015-11-10 21:59:20,732 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 2.0 (TID 17, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-10 21:59:20,732 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 2.0 (TID 17)
2015-11-10 21:59:20,733 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 2.0 (TID 16) in 532 ms on localhost (5/6)
2015-11-10 21:59:20,738 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:33554432+20845196
2015-11-10 21:59:21,153 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 2.0 (TID 17). 2258 bytes result sent to driver
2015-11-10 21:59:21,157 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 2.0 (TID 17) in 425 ms on localhost (6/6)
2015-11-10 21:59:21,157 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-10 21:59:21,158 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 2 (map at Statistic.scala:22) finished in 3.159 s
2015-11-10 21:59:21,158 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-10 21:59:21,158 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-10 21:59:21,158 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 3)
2015-11-10 21:59:21,158 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-10 21:59:21,159 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 3: List()
2015-11-10 21:59:21,159 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (ShuffledRDD[7] at reduceByKey at Statistic.scala:22), which is now runnable
2015-11-10 21:59:21,161 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2104) called with curMem=128938, maxMem=505361203
2015-11-10 21:59:21,162 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 2.1 KB, free 481.8 MB)
2015-11-10 21:59:21,163 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1335) called with curMem=131042, maxMem=505361203
2015-11-10 21:59:21,164 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1335.0 B, free 481.8 MB)
2015-11-10 21:59:21,165 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:52704 (size: 1335.0 B, free: 481.9 MB)
2015-11-10 21:59:21,166 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-10 21:59:21,166 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 3 (ShuffledRDD[7] at reduceByKey at Statistic.scala:22)
2015-11-10 21:59:21,166 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 6 tasks
2015-11-10 21:59:21,167 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 18, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:59:21,168 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 18)
2015-11-10 21:59:21,172 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:59:21,172 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-10 21:59:21,318 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 18). 1203 bytes result sent to driver
2015-11-10 21:59:21,319 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 3.0 (TID 19, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:59:21,319 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 3.0 (TID 19)
2015-11-10 21:59:21,320 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 18) in 152 ms on localhost (1/6)
2015-11-10 21:59:21,324 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:59:21,324 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-10 21:59:21,399 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 3.0 (TID 19). 1203 bytes result sent to driver
2015-11-10 21:59:21,401 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 3.0 (TID 20, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:59:21,404 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 3.0 (TID 19) in 85 ms on localhost (2/6)
2015-11-10 21:59:21,410 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 3.0 (TID 20)
2015-11-10 21:59:21,417 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:59:21,417 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-10 21:59:21,479 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 3.0 (TID 20). 1203 bytes result sent to driver
2015-11-10 21:59:21,480 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 3.0 (TID 21, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:59:21,480 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 3.0 (TID 21)
2015-11-10 21:59:21,481 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 3.0 (TID 20) in 80 ms on localhost (3/6)
2015-11-10 21:59:21,483 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:59:21,484 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-10 21:59:21,531 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 3.0 (TID 21). 1203 bytes result sent to driver
2015-11-10 21:59:21,532 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 3.0 (TID 22, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:59:21,532 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 3.0 (TID 22)
2015-11-10 21:59:21,533 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 3.0 (TID 21) in 53 ms on localhost (4/6)
2015-11-10 21:59:21,536 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:59:21,536 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-10 21:59:21,590 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 3.0 (TID 22). 1203 bytes result sent to driver
2015-11-10 21:59:21,594 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 3.0 (TID 23, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-10 21:59:21,595 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 3.0 (TID 23)
2015-11-10 21:59:21,596 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 3.0 (TID 22) in 64 ms on localhost (5/6)
2015-11-10 21:59:21,599 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-10 21:59:21,599 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-10 21:59:21,664 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 3.0 (TID 23). 1203 bytes result sent to driver
2015-11-10 21:59:21,667 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 3.0 (TID 23) in 74 ms on localhost (6/6)
2015-11-10 21:59:21,667 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-11-10 21:59:21,668 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 3 (count at Statistic.scala:23) finished in 0.501 s
2015-11-10 21:59:21,674 INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: count at Statistic.scala:23, took 3.687522 s
2015-11-10 21:59:21,692 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-10 21:59:21,693 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-10 21:59:21,693 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-10 21:59:21,693 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-10 21:59:21,693 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-10 21:59:21,693 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-10 21:59:21,693 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-10 21:59:21,694 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-10 21:59:21,694 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-10 21:59:21,694 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-10 21:59:21,694 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-10 21:59:21,694 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-10 21:59:21,694 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-10 21:59:21,695 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-10 21:59:21,695 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-10 21:59:21,695 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-10 21:59:21,695 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-10 21:59:21,695 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-10 21:59:21,695 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-10 21:59:21,695 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-10 21:59:21,695 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-10 21:59:21,696 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-10 21:59:21,696 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-10 21:59:21,696 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-10 21:59:21,696 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-10 21:59:21,748 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-10 21:59:21,751 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-10 21:59:21,830 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-10 21:59:21,907 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-10 21:59:21,908 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-10 21:59:21,911 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-10 21:59:21,914 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-10 21:59:21,915 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-10 21:59:21,919 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-10 21:59:21,919 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-0c0934bb-7c16-428d-97ed-5294d22b0870
2015-11-24 22:32:25,065 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-24 22:32:27,696 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-24 22:32:27,707 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-24 22:32:27,708 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-24 22:32:30,047 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-24 22:32:30,241 INFO  Remoting - Starting remoting
2015-11-24 22:32:30,744 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:53629]
2015-11-24 22:32:30,753 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53629.
2015-11-24 22:32:30,869 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-24 22:32:30,962 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-24 22:32:31,234 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-c26579c6-9b1a-49d1-89e3-e3dc3ddf73b7
2015-11-24 22:32:31,396 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-24 22:32:31,601 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-b4d3fd54-a230-4169-b068-90dbc546ce3f\httpd-3442110d-5c1d-4457-ba30-45e64b5addf7
2015-11-24 22:32:31,849 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-24 22:32:32,070 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:32:32,141 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:53630
2015-11-24 22:32:32,141 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 53630.
2015-11-24 22:32:32,244 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-24 22:32:32,775 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:32:32,797 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-24 22:32:32,797 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-24 22:32:32,799 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-24 22:32:33,206 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-24 22:32:33,215 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-24 22:32:33,736 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53652.
2015-11-24 22:32:33,736 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 53652
2015-11-24 22:32:33,762 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-24 22:32:33,781 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:53652 with 481.9 MB RAM, BlockManagerId(driver, localhost, 53652)
2015-11-24 22:32:33,812 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-24 22:32:36,131 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-24 22:32:36,141 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-24 22:32:36,273 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-24 22:32:36,274 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-24 22:32:36,277 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:53652 (size: 9.8 KB, free: 481.9 MB)
2015-11-24 22:32:36,319 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at InsightOfDataSet.scala:16
2015-11-24 22:32:38,111 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c701%29, but we couldn't find any external IP address!
2015-11-24 22:32:39,534 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 3
2015-11-24 22:32:40,090 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-24 22:32:40,090 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-24 22:32:40,090 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-24 22:32:40,090 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-24 22:32:40,090 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-24 22:32:40,350 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at InsightOfDataSet.scala:26
2015-11-24 22:32:40,443 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 3 (distinct at InsightOfDataSet.scala:23)
2015-11-24 22:32:40,445 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 6 (map at InsightOfDataSet.scala:24)
2015-11-24 22:32:40,448 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsTextFile at InsightOfDataSet.scala:26) with 6 output partitions
2015-11-24 22:32:40,449 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2(saveAsTextFile at InsightOfDataSet.scala:26)
2015-11-24 22:32:40,449 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2015-11-24 22:32:40,451 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2015-11-24 22:32:40,493 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at InsightOfDataSet.scala:23), which has no missing parents
2015-11-24 22:32:40,545 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(4024) called with curMem=116545, maxMem=505361203
2015-11-24 22:32:40,546 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 481.8 MB)
2015-11-24 22:32:40,586 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2297) called with curMem=120569, maxMem=505361203
2015-11-24 22:32:40,587 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 481.8 MB)
2015-11-24 22:32:40,589 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:53652 (size: 2.2 KB, free: 481.9 MB)
2015-11-24 22:32:40,590 INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-11-24 22:32:40,608 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at InsightOfDataSet.scala:23)
2015-11-24 22:32:40,625 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 6 tasks
2015-11-24 22:32:40,703 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:32:40,740 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-24 22:32:40,867 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:0+33554432
2015-11-24 22:32:43,147 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2258 bytes result sent to driver
2015-11-24 22:32:43,150 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:32:43,158 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2015-11-24 22:32:43,166 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:33554432+20843526
2015-11-24 22:32:43,225 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 2469 ms on localhost (1/6)
2015-11-24 22:32:44,661 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 2258 bytes result sent to driver
2015-11-24 22:32:44,664 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:32:44,665 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
2015-11-24 22:32:44,667 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 1517 ms on localhost (2/6)
2015-11-24 22:32:44,671 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:0+33554432
2015-11-24 22:32:45,284 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 2258 bytes result sent to driver
2015-11-24 22:32:45,285 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:32:45,286 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
2015-11-24 22:32:45,287 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 625 ms on localhost (3/6)
2015-11-24 22:32:45,291 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:33554432+20844232
2015-11-24 22:32:45,657 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 2258 bytes result sent to driver
2015-11-24 22:32:45,659 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:32:45,660 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
2015-11-24 22:32:45,666 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 381 ms on localhost (4/6)
2015-11-24 22:32:45,669 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:0+33554432
2015-11-24 22:32:46,283 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 2258 bytes result sent to driver
2015-11-24 22:32:46,284 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 0.0 (TID 5, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:32:46,285 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 0.0 (TID 5)
2015-11-24 22:32:46,286 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 628 ms on localhost (5/6)
2015-11-24 22:32:46,290 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:33554432+20845196
2015-11-24 22:32:46,612 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 0.0 (TID 5). 2258 bytes result sent to driver
2015-11-24 22:32:46,615 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 0.0 (TID 5) in 332 ms on localhost (6/6)
2015-11-24 22:32:46,616 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (distinct at InsightOfDataSet.scala:23) finished in 5.973 s
2015-11-24 22:32:46,616 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-24 22:32:46,627 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:32:46,627 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:32:46,636 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 1, ResultStage 2)
2015-11-24 22:32:46,636 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:32:46,676 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 1: List()
2015-11-24 22:32:46,677 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List(ShuffleMapStage 1)
2015-11-24 22:32:46,699 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at map at InsightOfDataSet.scala:24), which is now runnable
2015-11-24 22:32:46,708 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2704) called with curMem=122866, maxMem=505361203
2015-11-24 22:32:46,710 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 481.8 MB)
2015-11-24 22:32:46,713 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1574) called with curMem=125570, maxMem=505361203
2015-11-24 22:32:46,715 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1574.0 B, free 481.8 MB)
2015-11-24 22:32:46,723 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:53652 (size: 1574.0 B, free: 481.9 MB)
2015-11-24 22:32:46,727 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-24 22:32:46,730 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at map at InsightOfDataSet.scala:24)
2015-11-24 22:32:46,730 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 6 tasks
2015-11-24 22:32:46,739 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 6, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:32:46,739 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 6)
2015-11-24 22:32:46,766 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:46,768 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 6 ms
2015-11-24 22:32:46,891 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 6). 1379 bytes result sent to driver
2015-11-24 22:32:46,892 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 7, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:32:46,892 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 7)
2015-11-24 22:32:46,893 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 6) in 159 ms on localhost (1/6)
2015-11-24 22:32:46,898 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:46,899 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:32:46,922 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 7). 1379 bytes result sent to driver
2015-11-24 22:32:46,924 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 1.0 (TID 8, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:32:46,924 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 7) in 33 ms on localhost (2/6)
2015-11-24 22:32:46,924 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 1.0 (TID 8)
2015-11-24 22:32:46,929 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:46,929 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:32:46,961 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 1.0 (TID 8). 1379 bytes result sent to driver
2015-11-24 22:32:46,963 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 1.0 (TID 9, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:32:46,963 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 1.0 (TID 9)
2015-11-24 22:32:46,964 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 1.0 (TID 8) in 40 ms on localhost (3/6)
2015-11-24 22:32:46,968 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:46,968 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:32:46,996 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 1.0 (TID 9). 1379 bytes result sent to driver
2015-11-24 22:32:47,000 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 1.0 (TID 10, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:32:47,000 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 1.0 (TID 10)
2015-11-24 22:32:47,001 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 1.0 (TID 9) in 40 ms on localhost (4/6)
2015-11-24 22:32:47,006 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:47,006 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:32:47,027 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 1.0 (TID 10). 1379 bytes result sent to driver
2015-11-24 22:32:47,029 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 1.0 (TID 11, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:32:47,030 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 1.0 (TID 10) in 30 ms on localhost (5/6)
2015-11-24 22:32:47,030 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 1.0 (TID 11)
2015-11-24 22:32:47,035 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:47,035 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:32:47,056 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 1.0 (TID 11). 1379 bytes result sent to driver
2015-11-24 22:32:47,058 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 1.0 (TID 11) in 29 ms on localhost (6/6)
2015-11-24 22:32:47,058 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at InsightOfDataSet.scala:24) finished in 0.326 s
2015-11-24 22:32:47,058 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:32:47,058 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-24 22:32:47,058 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:32:47,058 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-24 22:32:47,058 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:32:47,058 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List()
2015-11-24 22:32:47,059 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at saveAsTextFile at InsightOfDataSet.scala:26), which is now runnable
2015-11-24 22:32:47,107 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95496) called with curMem=127144, maxMem=505361203
2015-11-24 22:32:47,107 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 93.3 KB, free 481.7 MB)
2015-11-24 22:32:47,109 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31329) called with curMem=222640, maxMem=505361203
2015-11-24 22:32:47,110 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 30.6 KB, free 481.7 MB)
2015-11-24 22:32:47,110 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:53652 (size: 30.6 KB, free: 481.9 MB)
2015-11-24 22:32:47,111 INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-11-24 22:32:47,112 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at saveAsTextFile at InsightOfDataSet.scala:26)
2015-11-24 22:32:47,113 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 6 tasks
2015-11-24 22:32:47,114 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 12, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:32:47,115 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 12)
2015-11-24 22:32:47,152 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-24 22:32:47,152 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-24 22:32:47,154 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-24 22:32:47,157 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-24 22:32:47,178 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:47,178 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:32:47,328 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242232_0002_m_000000_12' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242232_0002_m_000000
2015-11-24 22:32:47,329 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242232_0002_m_000000_12: Committed
2015-11-24 22:32:47,331 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 12). 1165 bytes result sent to driver
2015-11-24 22:32:47,332 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 13, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:32:47,336 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 12) in 223 ms on localhost (1/6)
2015-11-24 22:32:47,338 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 13)
2015-11-24 22:32:47,397 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 4 non-empty blocks out of 6 blocks
2015-11-24 22:32:47,397 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:32:47,418 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242232_0002_m_000001_13' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242232_0002_m_000001
2015-11-24 22:32:47,418 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242232_0002_m_000001_13: Committed
2015-11-24 22:32:47,419 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 13). 1165 bytes result sent to driver
2015-11-24 22:32:47,420 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 2.0 (TID 14, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:32:47,420 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 2.0 (TID 14)
2015-11-24 22:32:47,420 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 13) in 89 ms on localhost (2/6)
2015-11-24 22:32:47,457 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:47,458 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:32:47,477 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242232_0002_m_000002_14' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242232_0002_m_000002
2015-11-24 22:32:47,478 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242232_0002_m_000002_14: Committed
2015-11-24 22:32:47,478 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 2.0 (TID 14). 1165 bytes result sent to driver
2015-11-24 22:32:47,480 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 2.0 (TID 15, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:32:47,480 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 2.0 (TID 15)
2015-11-24 22:32:47,481 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 2.0 (TID 14) in 61 ms on localhost (3/6)
2015-11-24 22:32:47,524 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 4 non-empty blocks out of 6 blocks
2015-11-24 22:32:47,524 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:32:47,555 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242232_0002_m_000003_15' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242232_0002_m_000003
2015-11-24 22:32:47,555 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242232_0002_m_000003_15: Committed
2015-11-24 22:32:47,556 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 2.0 (TID 15). 1165 bytes result sent to driver
2015-11-24 22:32:47,558 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 2.0 (TID 16, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:32:47,560 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 2.0 (TID 16)
2015-11-24 22:32:47,561 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 2.0 (TID 15) in 82 ms on localhost (4/6)
2015-11-24 22:32:47,608 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:47,608 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:32:47,639 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242232_0002_m_000004_16' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242232_0002_m_000004
2015-11-24 22:32:47,640 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242232_0002_m_000004_16: Committed
2015-11-24 22:32:47,640 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 2.0 (TID 16). 1165 bytes result sent to driver
2015-11-24 22:32:47,641 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 2.0 (TID 17, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:32:47,642 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 2.0 (TID 17)
2015-11-24 22:32:47,642 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 2.0 (TID 16) in 85 ms on localhost (5/6)
2015-11-24 22:32:47,688 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:47,688 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:32:47,715 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242232_0002_m_000005_17' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242232_0002_m_000005
2015-11-24 22:32:47,715 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242232_0002_m_000005_17: Committed
2015-11-24 22:32:47,716 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 2.0 (TID 17). 1165 bytes result sent to driver
2015-11-24 22:32:47,718 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 2.0 (TID 17) in 76 ms on localhost (6/6)
2015-11-24 22:32:47,718 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-24 22:32:47,719 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (saveAsTextFile at InsightOfDataSet.scala:26) finished in 0.605 s
2015-11-24 22:32:47,746 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsTextFile at InsightOfDataSet.scala:26, took 7.395409 s
2015-11-24 22:32:47,860 INFO  org.apache.spark.SparkContext - Starting job: count at InsightOfDataSet.scala:27
2015-11-24 22:32:47,867 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 1 is 167 bytes
2015-11-24 22:32:47,908 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 186 bytes
2015-11-24 22:32:47,909 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (count at InsightOfDataSet.scala:27) with 6 output partitions
2015-11-24 22:32:47,909 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 5(count at InsightOfDataSet.scala:27)
2015-11-24 22:32:47,909 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 4)
2015-11-24 22:32:47,909 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2015-11-24 22:32:47,910 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (ShuffledRDD[7] at reduceByKey at InsightOfDataSet.scala:24), which has no missing parents
2015-11-24 22:32:47,912 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2112) called with curMem=253969, maxMem=505361203
2015-11-24 22:32:47,912 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 2.1 KB, free 481.7 MB)
2015-11-24 22:32:47,913 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1334) called with curMem=256081, maxMem=505361203
2015-11-24 22:32:47,914 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1334.0 B, free 481.7 MB)
2015-11-24 22:32:47,917 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:53652 (size: 1334.0 B, free: 481.9 MB)
2015-11-24 22:32:47,918 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-24 22:32:47,919 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 5 (ShuffledRDD[7] at reduceByKey at InsightOfDataSet.scala:24)
2015-11-24 22:32:47,919 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 6 tasks
2015-11-24 22:32:47,921 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 18, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:32:47,926 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 18)
2015-11-24 22:32:47,930 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:47,930 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:32:47,933 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 18). 1203 bytes result sent to driver
2015-11-24 22:32:47,934 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 19, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:32:47,954 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 18) in 34 ms on localhost (1/6)
2015-11-24 22:32:47,954 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 19)
2015-11-24 22:32:47,958 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 4 non-empty blocks out of 6 blocks
2015-11-24 22:32:47,958 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:32:47,966 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 19). 1203 bytes result sent to driver
2015-11-24 22:32:47,967 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 5.0 (TID 20, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:32:47,970 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 19) in 36 ms on localhost (2/6)
2015-11-24 22:32:47,970 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 5.0 (TID 20)
2015-11-24 22:32:47,974 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:47,974 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:32:47,977 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 5.0 (TID 20). 1203 bytes result sent to driver
2015-11-24 22:32:47,979 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 5.0 (TID 21, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:32:47,980 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 5.0 (TID 20) in 13 ms on localhost (3/6)
2015-11-24 22:32:47,981 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 5.0 (TID 21)
2015-11-24 22:32:47,985 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 4 non-empty blocks out of 6 blocks
2015-11-24 22:32:47,986 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:32:47,988 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 5.0 (TID 21). 1203 bytes result sent to driver
2015-11-24 22:32:47,990 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 5.0 (TID 22, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:32:47,991 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 5.0 (TID 21) in 13 ms on localhost (4/6)
2015-11-24 22:32:47,999 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 5.0 (TID 22)
2015-11-24 22:32:48,003 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:48,003 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:32:48,009 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 5.0 (TID 22). 1203 bytes result sent to driver
2015-11-24 22:32:48,011 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 5.0 (TID 23, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:32:48,011 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 5.0 (TID 23)
2015-11-24 22:32:48,016 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:32:48,016 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:32:48,021 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 5.0 (TID 23). 1203 bytes result sent to driver
2015-11-24 22:32:48,023 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 5.0 (TID 22) in 34 ms on localhost (5/6)
2015-11-24 22:32:48,025 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 5.0 (TID 23) in 15 ms on localhost (6/6)
2015-11-24 22:32:48,025 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 5 (count at InsightOfDataSet.scala:27) finished in 0.105 s
2015-11-24 22:32:48,025 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-11-24 22:32:48,026 INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: count at InsightOfDataSet.scala:27, took 0.166112 s
2015-11-24 22:32:48,031 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-24 22:32:48,071 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-24 22:32:48,071 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-24 22:32:48,072 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-24 22:32:48,072 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-24 22:32:48,072 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-24 22:32:48,072 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-24 22:32:48,073 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-24 22:32:48,073 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-24 22:32:48,073 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-24 22:32:48,073 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-24 22:32:48,074 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-24 22:32:48,074 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-24 22:32:48,074 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-24 22:32:48,074 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-24 22:32:48,075 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-24 22:32:48,075 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-24 22:32:48,075 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-24 22:32:48,075 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-24 22:32:48,075 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-24 22:32:48,076 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-24 22:32:48,076 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-24 22:32:48,076 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-24 22:32:48,076 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-24 22:32:48,076 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-24 22:32:48,077 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-24 22:32:48,128 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-24 22:32:48,133 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-24 22:32:48,234 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-24 22:32:48,319 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-24 22:32:48,320 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-24 22:32:48,330 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-24 22:32:48,355 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-24 22:32:48,367 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-24 22:32:48,396 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-24 22:32:48,397 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-b4d3fd54-a230-4169-b068-90dbc546ce3f
2015-11-24 22:36:17,691 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-24 22:36:19,095 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-24 22:36:19,096 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-24 22:36:19,098 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-24 22:36:19,929 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-24 22:36:19,995 INFO  Remoting - Starting remoting
2015-11-24 22:36:20,203 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:53718]
2015-11-24 22:36:20,209 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53718.
2015-11-24 22:36:20,230 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-24 22:36:20,246 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-24 22:36:20,278 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-5d49e8a9-124c-4732-9dd5-e9af68668cac
2015-11-24 22:36:20,292 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-24 22:36:20,391 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-5c0ab6e7-b16a-45e5-9011-4399f1a89bcf\httpd-26072eed-7afc-4399-862c-d1ec503b95b4
2015-11-24 22:36:20,396 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-24 22:36:20,469 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:36:20,492 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:53719
2015-11-24 22:36:20,492 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 53719.
2015-11-24 22:36:20,515 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-24 22:36:20,673 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:36:20,689 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-24 22:36:20,689 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-24 22:36:20,691 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-24 22:36:20,806 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-24 22:36:20,810 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-24 22:36:21,199 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53738.
2015-11-24 22:36:21,200 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 53738
2015-11-24 22:36:21,201 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-24 22:36:21,204 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:53738 with 481.9 MB RAM, BlockManagerId(driver, localhost, 53738)
2015-11-24 22:36:21,206 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-24 22:36:21,929 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-24 22:36:21,933 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-24 22:36:21,979 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-24 22:36:21,980 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-24 22:36:21,983 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:53738 (size: 9.8 KB, free: 481.9 MB)
2015-11-24 22:36:21,990 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at InsightOfDataSet.scala:16
2015-11-24 22:36:23,351 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c701%29, but we couldn't find any external IP address!
2015-11-24 22:36:24,226 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 3
2015-11-24 22:36:24,373 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-24 22:36:24,373 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-24 22:36:24,373 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-24 22:36:24,373 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-24 22:36:24,374 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-24 22:36:24,537 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at InsightOfDataSet.scala:26
2015-11-24 22:36:24,561 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 3 (distinct at InsightOfDataSet.scala:23)
2015-11-24 22:36:24,562 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 6 (map at InsightOfDataSet.scala:24)
2015-11-24 22:36:24,565 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsTextFile at InsightOfDataSet.scala:26) with 6 output partitions
2015-11-24 22:36:24,565 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2(saveAsTextFile at InsightOfDataSet.scala:26)
2015-11-24 22:36:24,566 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2015-11-24 22:36:24,567 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2015-11-24 22:36:24,576 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at InsightOfDataSet.scala:23), which has no missing parents
2015-11-24 22:36:24,604 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(4024) called with curMem=116545, maxMem=505361203
2015-11-24 22:36:24,605 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 481.8 MB)
2015-11-24 22:36:24,607 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2297) called with curMem=120569, maxMem=505361203
2015-11-24 22:36:24,608 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 481.8 MB)
2015-11-24 22:36:24,609 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:53738 (size: 2.2 KB, free: 481.9 MB)
2015-11-24 22:36:24,609 INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-11-24 22:36:24,613 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at InsightOfDataSet.scala:23)
2015-11-24 22:36:24,614 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 6 tasks
2015-11-24 22:36:24,645 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:36:24,654 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-24 22:36:24,693 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:0+33554432
2015-11-24 22:36:25,771 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2258 bytes result sent to driver
2015-11-24 22:36:25,773 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:36:25,777 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2015-11-24 22:36:25,787 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1146 ms on localhost (1/6)
2015-11-24 22:36:25,788 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:33554432+20843526
2015-11-24 22:36:26,089 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 2258 bytes result sent to driver
2015-11-24 22:36:26,091 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:36:26,093 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
2015-11-24 22:36:26,097 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 325 ms on localhost (2/6)
2015-11-24 22:36:26,100 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:0+33554432
2015-11-24 22:36:32,414 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 2258 bytes result sent to driver
2015-11-24 22:36:32,416 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:36:32,417 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
2015-11-24 22:36:32,421 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 6331 ms on localhost (3/6)
2015-11-24 22:36:32,423 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:33554432+20844232
2015-11-24 22:36:32,693 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 2258 bytes result sent to driver
2015-11-24 22:36:32,695 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:36:32,695 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
2015-11-24 22:36:32,697 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 281 ms on localhost (4/6)
2015-11-24 22:36:32,700 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:0+33554432
2015-11-24 22:36:33,296 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 2258 bytes result sent to driver
2015-11-24 22:36:33,298 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 0.0 (TID 5, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:36:33,299 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 0.0 (TID 5)
2015-11-24 22:36:33,299 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 605 ms on localhost (5/6)
2015-11-24 22:36:33,304 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:33554432+20845196
2015-11-24 22:36:33,588 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 0.0 (TID 5). 2258 bytes result sent to driver
2015-11-24 22:36:33,591 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 0.0 (TID 5) in 295 ms on localhost (6/6)
2015-11-24 22:36:33,592 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (distinct at InsightOfDataSet.scala:23) finished in 8.968 s
2015-11-24 22:36:33,592 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-24 22:36:33,592 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:36:33,593 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:36:33,593 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 1, ResultStage 2)
2015-11-24 22:36:33,594 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:36:33,596 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 1: List()
2015-11-24 22:36:33,596 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List(ShuffleMapStage 1)
2015-11-24 22:36:33,599 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at map at InsightOfDataSet.scala:24), which is now runnable
2015-11-24 22:36:33,601 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2704) called with curMem=122866, maxMem=505361203
2015-11-24 22:36:33,602 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 481.8 MB)
2015-11-24 22:36:33,603 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1574) called with curMem=125570, maxMem=505361203
2015-11-24 22:36:33,603 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1574.0 B, free 481.8 MB)
2015-11-24 22:36:33,605 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:53738 (size: 1574.0 B, free: 481.9 MB)
2015-11-24 22:36:33,606 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-24 22:36:33,606 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at map at InsightOfDataSet.scala:24)
2015-11-24 22:36:33,607 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 6 tasks
2015-11-24 22:36:33,609 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 6, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:36:33,609 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 6)
2015-11-24 22:36:33,623 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:33,624 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 5 ms
2015-11-24 22:36:33,671 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 6). 1379 bytes result sent to driver
2015-11-24 22:36:33,672 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 7, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:36:33,674 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 7)
2015-11-24 22:36:33,679 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:33,679 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:36:33,686 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 6) in 78 ms on localhost (1/6)
2015-11-24 22:36:33,701 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 7). 1379 bytes result sent to driver
2015-11-24 22:36:33,703 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 1.0 (TID 8, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:36:33,703 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 1.0 (TID 8)
2015-11-24 22:36:33,703 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 7) in 31 ms on localhost (2/6)
2015-11-24 22:36:33,708 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:33,709 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:36:33,742 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 1.0 (TID 8). 1379 bytes result sent to driver
2015-11-24 22:36:33,743 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 1.0 (TID 9, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:36:33,743 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 1.0 (TID 9)
2015-11-24 22:36:33,743 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 1.0 (TID 8) in 42 ms on localhost (3/6)
2015-11-24 22:36:33,747 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:33,747 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:36:33,767 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 1.0 (TID 9). 1379 bytes result sent to driver
2015-11-24 22:36:33,768 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 1.0 (TID 10, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:36:33,769 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 1.0 (TID 10)
2015-11-24 22:36:33,769 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 1.0 (TID 9) in 27 ms on localhost (4/6)
2015-11-24 22:36:33,774 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:33,774 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:36:33,804 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 1.0 (TID 10). 1379 bytes result sent to driver
2015-11-24 22:36:33,806 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 1.0 (TID 11, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:36:33,806 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 1.0 (TID 11)
2015-11-24 22:36:33,806 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 1.0 (TID 10) in 38 ms on localhost (5/6)
2015-11-24 22:36:33,811 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:33,811 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:36:33,832 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 1.0 (TID 11). 1379 bytes result sent to driver
2015-11-24 22:36:33,834 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 1.0 (TID 11) in 29 ms on localhost (6/6)
2015-11-24 22:36:33,834 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at InsightOfDataSet.scala:24) finished in 0.227 s
2015-11-24 22:36:33,834 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-24 22:36:33,834 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:36:33,835 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:36:33,835 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-24 22:36:33,835 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:36:33,835 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List()
2015-11-24 22:36:33,836 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at saveAsTextFile at InsightOfDataSet.scala:26), which is now runnable
2015-11-24 22:36:33,883 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95496) called with curMem=127144, maxMem=505361203
2015-11-24 22:36:33,883 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 93.3 KB, free 481.7 MB)
2015-11-24 22:36:33,885 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31329) called with curMem=222640, maxMem=505361203
2015-11-24 22:36:33,886 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 30.6 KB, free 481.7 MB)
2015-11-24 22:36:33,887 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:53738 (size: 30.6 KB, free: 481.9 MB)
2015-11-24 22:36:33,887 INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-11-24 22:36:33,889 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at saveAsTextFile at InsightOfDataSet.scala:26)
2015-11-24 22:36:33,889 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 6 tasks
2015-11-24 22:36:33,891 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 12, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:36:33,891 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 12)
2015-11-24 22:36:33,909 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-24 22:36:33,910 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-24 22:36:33,912 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-24 22:36:33,915 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-24 22:36:33,936 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:33,937 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:36:34,013 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242236_0002_m_000000_12' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242236_0002_m_000000
2015-11-24 22:36:34,014 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242236_0002_m_000000_12: Committed
2015-11-24 22:36:34,016 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 12). 1165 bytes result sent to driver
2015-11-24 22:36:34,017 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 13, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:36:34,017 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 13)
2015-11-24 22:36:34,018 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 12) in 127 ms on localhost (1/6)
2015-11-24 22:36:34,055 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:34,055 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:36:34,082 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242236_0002_m_000001_13' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242236_0002_m_000001
2015-11-24 22:36:34,082 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242236_0002_m_000001_13: Committed
2015-11-24 22:36:34,083 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 13). 1165 bytes result sent to driver
2015-11-24 22:36:34,085 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 2.0 (TID 14, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:36:34,085 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 2.0 (TID 14)
2015-11-24 22:36:34,089 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 13) in 73 ms on localhost (2/6)
2015-11-24 22:36:34,123 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:34,123 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:36:34,146 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242236_0002_m_000002_14' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242236_0002_m_000002
2015-11-24 22:36:34,146 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242236_0002_m_000002_14: Committed
2015-11-24 22:36:34,147 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 2.0 (TID 14). 1165 bytes result sent to driver
2015-11-24 22:36:34,148 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 2.0 (TID 15, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:36:34,148 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 2.0 (TID 14) in 65 ms on localhost (3/6)
2015-11-24 22:36:34,149 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 2.0 (TID 15)
2015-11-24 22:36:34,185 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:34,185 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:36:34,210 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242236_0002_m_000003_15' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242236_0002_m_000003
2015-11-24 22:36:34,210 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242236_0002_m_000003_15: Committed
2015-11-24 22:36:34,211 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 2.0 (TID 15). 1165 bytes result sent to driver
2015-11-24 22:36:34,212 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 2.0 (TID 16, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:36:34,213 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 2.0 (TID 15) in 66 ms on localhost (4/6)
2015-11-24 22:36:34,213 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 2.0 (TID 16)
2015-11-24 22:36:34,250 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:34,251 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:36:34,274 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242236_0002_m_000004_16' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242236_0002_m_000004
2015-11-24 22:36:34,274 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242236_0002_m_000004_16: Committed
2015-11-24 22:36:34,274 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 2.0 (TID 16). 1165 bytes result sent to driver
2015-11-24 22:36:34,276 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 2.0 (TID 17, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:36:34,276 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 2.0 (TID 17)
2015-11-24 22:36:34,276 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 2.0 (TID 16) in 65 ms on localhost (5/6)
2015-11-24 22:36:34,323 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:34,323 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:36:34,360 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242236_0002_m_000005_17' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242236_0002_m_000005
2015-11-24 22:36:34,360 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242236_0002_m_000005_17: Committed
2015-11-24 22:36:34,361 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 2.0 (TID 17). 1165 bytes result sent to driver
2015-11-24 22:36:34,362 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 2.0 (TID 17) in 86 ms on localhost (6/6)
2015-11-24 22:36:34,362 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (saveAsTextFile at InsightOfDataSet.scala:26) finished in 0.472 s
2015-11-24 22:36:34,362 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-24 22:36:34,369 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsTextFile at InsightOfDataSet.scala:26, took 9.831460 s
2015-11-24 22:36:34,421 INFO  org.apache.spark.SparkContext - Starting job: count at InsightOfDataSet.scala:27
2015-11-24 22:36:34,426 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 1 is 167 bytes
2015-11-24 22:36:34,430 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 188 bytes
2015-11-24 22:36:34,431 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (count at InsightOfDataSet.scala:27) with 6 output partitions
2015-11-24 22:36:34,431 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 5(count at InsightOfDataSet.scala:27)
2015-11-24 22:36:34,431 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 4)
2015-11-24 22:36:34,431 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2015-11-24 22:36:34,431 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (ShuffledRDD[7] at reduceByKey at InsightOfDataSet.scala:24), which has no missing parents
2015-11-24 22:36:34,434 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2112) called with curMem=253969, maxMem=505361203
2015-11-24 22:36:34,434 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 2.1 KB, free 481.7 MB)
2015-11-24 22:36:34,436 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1334) called with curMem=256081, maxMem=505361203
2015-11-24 22:36:34,436 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1334.0 B, free 481.7 MB)
2015-11-24 22:36:34,437 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:53738 (size: 1334.0 B, free: 481.9 MB)
2015-11-24 22:36:34,437 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-24 22:36:34,438 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 5 (ShuffledRDD[7] at reduceByKey at InsightOfDataSet.scala:24)
2015-11-24 22:36:34,438 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 6 tasks
2015-11-24 22:36:34,440 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 18, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:36:34,440 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 18)
2015-11-24 22:36:34,445 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:34,445 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:36:34,453 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 18). 1203 bytes result sent to driver
2015-11-24 22:36:34,454 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 19, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:36:34,455 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 19)
2015-11-24 22:36:34,460 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:34,460 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:36:34,468 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 18) in 28 ms on localhost (1/6)
2015-11-24 22:36:34,470 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 19). 1203 bytes result sent to driver
2015-11-24 22:36:34,472 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 5.0 (TID 20, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:36:34,473 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 5.0 (TID 20)
2015-11-24 22:36:34,474 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 19) in 20 ms on localhost (2/6)
2015-11-24 22:36:34,478 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:34,478 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:36:34,484 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 5.0 (TID 20). 1203 bytes result sent to driver
2015-11-24 22:36:34,485 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 5.0 (TID 21, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:36:34,486 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 5.0 (TID 21)
2015-11-24 22:36:34,486 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 5.0 (TID 20) in 15 ms on localhost (3/6)
2015-11-24 22:36:34,490 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:34,490 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:36:34,499 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 5.0 (TID 21). 1203 bytes result sent to driver
2015-11-24 22:36:34,500 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 5.0 (TID 22, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:36:34,501 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 5.0 (TID 22)
2015-11-24 22:36:34,501 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 5.0 (TID 21) in 16 ms on localhost (4/6)
2015-11-24 22:36:34,506 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:34,506 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:36:34,514 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 5.0 (TID 22). 1203 bytes result sent to driver
2015-11-24 22:36:34,516 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 5.0 (TID 23, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:36:34,516 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 5.0 (TID 23)
2015-11-24 22:36:34,518 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 5.0 (TID 22) in 18 ms on localhost (5/6)
2015-11-24 22:36:34,523 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:36:34,524 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:36:34,533 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 5.0 (TID 23). 1203 bytes result sent to driver
2015-11-24 22:36:34,535 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 5 (count at InsightOfDataSet.scala:27) finished in 0.097 s
2015-11-24 22:36:34,535 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 5.0 (TID 23) in 20 ms on localhost (6/6)
2015-11-24 22:36:34,536 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-11-24 22:36:34,536 INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: count at InsightOfDataSet.scala:27, took 0.114834 s
2015-11-24 22:36:34,543 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-24 22:36:34,559 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-24 22:36:34,559 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-24 22:36:34,559 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-24 22:36:34,560 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-24 22:36:34,560 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-24 22:36:34,560 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-24 22:36:34,560 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-24 22:36:34,561 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-24 22:36:34,561 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-24 22:36:34,561 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-24 22:36:34,561 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-24 22:36:34,561 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-24 22:36:34,562 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-24 22:36:34,562 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-24 22:36:34,562 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-24 22:36:34,562 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-24 22:36:34,562 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-24 22:36:34,562 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-24 22:36:34,563 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-24 22:36:34,563 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-24 22:36:34,563 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-24 22:36:34,563 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-24 22:36:34,563 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-24 22:36:34,564 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-24 22:36:34,564 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-24 22:36:34,616 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-24 22:36:34,620 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-24 22:36:34,720 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-24 22:36:34,798 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-24 22:36:34,799 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-24 22:36:34,805 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-24 22:36:34,808 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-24 22:36:34,809 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-24 22:36:34,810 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-24 22:36:34,811 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-5c0ab6e7-b16a-45e5-9011-4399f1a89bcf
2015-11-24 22:40:36,522 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-24 22:40:38,096 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-24 22:40:38,097 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-24 22:40:38,097 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-24 22:40:38,946 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-24 22:40:39,008 INFO  Remoting - Starting remoting
2015-11-24 22:40:39,201 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:53810]
2015-11-24 22:40:39,207 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53810.
2015-11-24 22:40:39,228 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-24 22:40:39,244 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-24 22:40:39,277 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-cdee3dc2-18b8-44ca-8378-78c63fd798f9
2015-11-24 22:40:39,294 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-24 22:40:39,371 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-63dc2771-53d1-40a5-a0d6-cf5b9c0674a1\httpd-2f16b7cd-1012-4482-bbe6-28f990daf79c
2015-11-24 22:40:39,376 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-24 22:40:39,444 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:40:39,464 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:53811
2015-11-24 22:40:39,465 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 53811.
2015-11-24 22:40:39,490 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-24 22:40:39,657 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:40:39,676 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-24 22:40:39,676 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-24 22:40:39,680 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-24 22:40:39,804 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-24 22:40:39,825 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-24 22:40:40,191 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53830.
2015-11-24 22:40:40,192 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 53830
2015-11-24 22:40:40,193 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-24 22:40:40,196 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:53830 with 481.9 MB RAM, BlockManagerId(driver, localhost, 53830)
2015-11-24 22:40:40,198 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-24 22:40:40,881 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-24 22:40:40,884 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-24 22:40:40,924 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-24 22:40:40,924 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-24 22:40:40,928 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:53830 (size: 9.8 KB, free: 481.9 MB)
2015-11-24 22:40:40,933 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at InsightOfDataSet.scala:16
2015-11-24 22:40:42,273 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c701%29, but we couldn't find any external IP address!
2015-11-24 22:40:43,118 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 3
2015-11-24 22:40:43,273 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-24 22:40:43,288 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-24 22:40:43,289 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-24 22:40:43,289 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-24 22:40:43,290 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-24 22:40:43,290 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-24 22:40:43,290 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-24 22:40:43,291 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-24 22:40:43,291 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-24 22:40:43,291 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-24 22:40:43,291 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-24 22:40:43,292 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-24 22:40:43,292 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-24 22:40:43,292 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-24 22:40:43,293 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-24 22:40:43,293 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-24 22:40:43,293 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-24 22:40:43,293 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-24 22:40:43,294 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-24 22:40:43,294 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-24 22:40:43,294 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-24 22:40:43,294 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-24 22:40:43,295 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-24 22:40:43,295 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-24 22:40:43,295 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-24 22:40:43,295 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-24 22:40:43,347 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-24 22:40:43,354 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-24 22:40:43,424 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-24 22:40:43,438 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-24 22:40:43,439 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-24 22:40:43,449 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-24 22:40:43,451 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-24 22:40:43,453 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-24 22:40:43,454 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-24 22:40:43,456 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-63dc2771-53d1-40a5-a0d6-cf5b9c0674a1
2015-11-24 22:40:59,552 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-24 22:41:00,986 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-24 22:41:00,987 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-24 22:41:00,988 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-24 22:41:01,793 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-24 22:41:01,860 INFO  Remoting - Starting remoting
2015-11-24 22:41:02,057 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:53854]
2015-11-24 22:41:02,064 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53854.
2015-11-24 22:41:02,085 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-24 22:41:02,101 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-24 22:41:02,138 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-d20414e2-1c99-416c-900b-314802ce412f
2015-11-24 22:41:02,152 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-24 22:41:02,242 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-c2842e80-e151-4d33-946a-31f9c01c6894\httpd-f6b1c20c-9543-4582-b5e2-19430b1cb5c2
2015-11-24 22:41:02,251 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-24 22:41:02,320 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:41:02,341 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:53855
2015-11-24 22:41:02,341 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 53855.
2015-11-24 22:41:02,366 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-24 22:41:02,562 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:41:02,579 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-24 22:41:02,579 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-24 22:41:02,582 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-24 22:41:02,708 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-24 22:41:02,712 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-24 22:41:03,087 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53874.
2015-11-24 22:41:03,088 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 53874
2015-11-24 22:41:03,089 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-24 22:41:03,092 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:53874 with 481.9 MB RAM, BlockManagerId(driver, localhost, 53874)
2015-11-24 22:41:03,093 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-24 22:41:03,729 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-24 22:41:03,732 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-24 22:41:03,775 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-24 22:41:03,776 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-24 22:41:03,779 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:53874 (size: 9.8 KB, free: 481.9 MB)
2015-11-24 22:41:03,784 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at InsightOfDataSet.scala:16
2015-11-24 22:41:05,138 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c701%29, but we couldn't find any external IP address!
2015-11-24 22:41:05,934 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 3
2015-11-24 22:41:06,074 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-24 22:41:06,074 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-24 22:41:06,074 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-24 22:41:06,074 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-24 22:41:06,074 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-24 22:41:06,207 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at InsightOfDataSet.scala:26
2015-11-24 22:41:06,230 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 3 (distinct at InsightOfDataSet.scala:23)
2015-11-24 22:41:06,232 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 6 (map at InsightOfDataSet.scala:24)
2015-11-24 22:41:06,233 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsTextFile at InsightOfDataSet.scala:26) with 6 output partitions
2015-11-24 22:41:06,234 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2(saveAsTextFile at InsightOfDataSet.scala:26)
2015-11-24 22:41:06,234 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2015-11-24 22:41:06,236 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2015-11-24 22:41:06,243 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at InsightOfDataSet.scala:23), which has no missing parents
2015-11-24 22:41:06,267 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(4024) called with curMem=116545, maxMem=505361203
2015-11-24 22:41:06,268 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 481.8 MB)
2015-11-24 22:41:06,271 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2297) called with curMem=120569, maxMem=505361203
2015-11-24 22:41:06,271 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 481.8 MB)
2015-11-24 22:41:06,272 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:53874 (size: 2.2 KB, free: 481.9 MB)
2015-11-24 22:41:06,273 INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-11-24 22:41:06,276 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at InsightOfDataSet.scala:23)
2015-11-24 22:41:06,277 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 6 tasks
2015-11-24 22:41:06,307 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:41:06,313 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-24 22:41:06,337 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:0+33554432
2015-11-24 22:41:07,419 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2258 bytes result sent to driver
2015-11-24 22:41:07,421 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:41:07,421 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2015-11-24 22:41:07,429 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:33554432+20843526
2015-11-24 22:41:07,429 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1130 ms on localhost (1/6)
2015-11-24 22:41:07,724 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 2258 bytes result sent to driver
2015-11-24 22:41:07,726 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:41:07,727 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
2015-11-24 22:41:07,729 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 309 ms on localhost (2/6)
2015-11-24 22:41:07,733 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:0+33554432
2015-11-24 22:41:08,458 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 2258 bytes result sent to driver
2015-11-24 22:41:08,460 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:41:08,462 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
2015-11-24 22:41:08,462 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 737 ms on localhost (3/6)
2015-11-24 22:41:08,467 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:33554432+20844232
2015-11-24 22:41:08,743 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 2258 bytes result sent to driver
2015-11-24 22:41:08,744 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:41:08,746 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
2015-11-24 22:41:08,746 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 287 ms on localhost (4/6)
2015-11-24 22:41:08,751 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:0+33554432
2015-11-24 22:41:09,247 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 2258 bytes result sent to driver
2015-11-24 22:41:09,249 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 0.0 (TID 5, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:41:09,250 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 505 ms on localhost (5/6)
2015-11-24 22:41:09,250 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 0.0 (TID 5)
2015-11-24 22:41:09,255 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:33554432+20845196
2015-11-24 22:41:09,529 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 0.0 (TID 5). 2258 bytes result sent to driver
2015-11-24 22:41:09,532 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 0.0 (TID 5) in 285 ms on localhost (6/6)
2015-11-24 22:41:09,533 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (distinct at InsightOfDataSet.scala:23) finished in 3.245 s
2015-11-24 22:41:09,533 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-24 22:41:09,534 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:41:09,534 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:41:09,535 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 1, ResultStage 2)
2015-11-24 22:41:09,535 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:41:09,537 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 1: List()
2015-11-24 22:41:09,537 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List(ShuffleMapStage 1)
2015-11-24 22:41:09,540 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at map at InsightOfDataSet.scala:24), which is now runnable
2015-11-24 22:41:09,543 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2704) called with curMem=122866, maxMem=505361203
2015-11-24 22:41:09,543 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 481.8 MB)
2015-11-24 22:41:09,544 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1574) called with curMem=125570, maxMem=505361203
2015-11-24 22:41:09,544 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1574.0 B, free 481.8 MB)
2015-11-24 22:41:09,546 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:53874 (size: 1574.0 B, free: 481.9 MB)
2015-11-24 22:41:09,547 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-24 22:41:09,547 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at map at InsightOfDataSet.scala:24)
2015-11-24 22:41:09,547 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 6 tasks
2015-11-24 22:41:09,549 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 6, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:41:09,549 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 6)
2015-11-24 22:41:09,563 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:09,564 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 5 ms
2015-11-24 22:41:09,617 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 6). 1379 bytes result sent to driver
2015-11-24 22:41:09,618 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 7, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:41:09,619 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 7)
2015-11-24 22:41:09,619 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 6) in 71 ms on localhost (1/6)
2015-11-24 22:41:09,623 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:09,624 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:41:09,644 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 7). 1379 bytes result sent to driver
2015-11-24 22:41:09,645 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 1.0 (TID 8, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:41:09,646 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 7) in 29 ms on localhost (2/6)
2015-11-24 22:41:09,646 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 1.0 (TID 8)
2015-11-24 22:41:09,652 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:09,652 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:41:09,679 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 1.0 (TID 8). 1379 bytes result sent to driver
2015-11-24 22:41:09,681 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 1.0 (TID 9, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:41:09,681 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 1.0 (TID 9)
2015-11-24 22:41:09,682 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 1.0 (TID 8) in 37 ms on localhost (3/6)
2015-11-24 22:41:09,686 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:09,686 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:41:09,710 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 1.0 (TID 9). 1379 bytes result sent to driver
2015-11-24 22:41:09,712 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 1.0 (TID 10, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:41:09,712 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 1.0 (TID 10)
2015-11-24 22:41:09,714 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 1.0 (TID 9) in 33 ms on localhost (4/6)
2015-11-24 22:41:09,718 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:09,719 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:41:09,746 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 1.0 (TID 10). 1379 bytes result sent to driver
2015-11-24 22:41:09,747 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 1.0 (TID 11, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:41:09,748 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 1.0 (TID 11)
2015-11-24 22:41:09,748 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 1.0 (TID 10) in 37 ms on localhost (5/6)
2015-11-24 22:41:09,753 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:09,753 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:41:09,785 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 1.0 (TID 11). 1379 bytes result sent to driver
2015-11-24 22:41:09,786 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 1.0 (TID 11) in 40 ms on localhost (6/6)
2015-11-24 22:41:09,787 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at InsightOfDataSet.scala:24) finished in 0.239 s
2015-11-24 22:41:09,787 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-24 22:41:09,787 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:41:09,787 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:41:09,787 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-24 22:41:09,787 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:41:09,788 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List()
2015-11-24 22:41:09,788 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at saveAsTextFile at InsightOfDataSet.scala:26), which is now runnable
2015-11-24 22:41:09,834 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95496) called with curMem=127144, maxMem=505361203
2015-11-24 22:41:09,835 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 93.3 KB, free 481.7 MB)
2015-11-24 22:41:09,837 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31329) called with curMem=222640, maxMem=505361203
2015-11-24 22:41:09,838 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 30.6 KB, free 481.7 MB)
2015-11-24 22:41:09,838 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:53874 (size: 30.6 KB, free: 481.9 MB)
2015-11-24 22:41:09,839 INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-11-24 22:41:09,840 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at saveAsTextFile at InsightOfDataSet.scala:26)
2015-11-24 22:41:09,841 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 6 tasks
2015-11-24 22:41:09,842 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 12, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:41:09,843 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 12)
2015-11-24 22:41:09,861 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-24 22:41:09,862 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-24 22:41:09,864 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-24 22:41:09,867 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-24 22:41:09,887 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:09,888 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:41:09,938 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242241_0002_m_000000_12' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242241_0002_m_000000
2015-11-24 22:41:09,938 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242241_0002_m_000000_12: Committed
2015-11-24 22:41:09,939 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 12). 1165 bytes result sent to driver
2015-11-24 22:41:09,940 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 13, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:41:09,941 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 13)
2015-11-24 22:41:09,941 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 12) in 100 ms on localhost (1/6)
2015-11-24 22:41:09,981 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 3 non-empty blocks out of 6 blocks
2015-11-24 22:41:09,981 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:41:10,000 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242241_0002_m_000001_13' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242241_0002_m_000001
2015-11-24 22:41:10,000 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242241_0002_m_000001_13: Committed
2015-11-24 22:41:10,001 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 13). 1165 bytes result sent to driver
2015-11-24 22:41:10,002 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 2.0 (TID 14, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:41:10,003 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 2.0 (TID 14)
2015-11-24 22:41:10,003 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 13) in 63 ms on localhost (2/6)
2015-11-24 22:41:10,043 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:10,043 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:41:10,063 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242241_0002_m_000002_14' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242241_0002_m_000002
2015-11-24 22:41:10,063 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242241_0002_m_000002_14: Committed
2015-11-24 22:41:10,064 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 2.0 (TID 14). 1165 bytes result sent to driver
2015-11-24 22:41:10,065 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 2.0 (TID 15, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:41:10,066 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 2.0 (TID 15)
2015-11-24 22:41:10,066 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 2.0 (TID 14) in 65 ms on localhost (3/6)
2015-11-24 22:41:10,103 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:10,103 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:41:10,123 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242241_0002_m_000003_15' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242241_0002_m_000003
2015-11-24 22:41:10,124 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242241_0002_m_000003_15: Committed
2015-11-24 22:41:10,124 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 2.0 (TID 15). 1165 bytes result sent to driver
2015-11-24 22:41:10,125 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 2.0 (TID 16, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:41:10,125 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 2.0 (TID 16)
2015-11-24 22:41:10,126 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 2.0 (TID 15) in 61 ms on localhost (4/6)
2015-11-24 22:41:10,156 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 4 non-empty blocks out of 6 blocks
2015-11-24 22:41:10,156 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:41:10,197 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242241_0002_m_000004_16' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242241_0002_m_000004
2015-11-24 22:41:10,197 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242241_0002_m_000004_16: Committed
2015-11-24 22:41:10,198 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 2.0 (TID 16). 1165 bytes result sent to driver
2015-11-24 22:41:10,199 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 2.0 (TID 17, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:41:10,200 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 2.0 (TID 17)
2015-11-24 22:41:10,200 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 2.0 (TID 16) in 75 ms on localhost (5/6)
2015-11-24 22:41:10,262 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:10,262 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:41:10,288 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242241_0002_m_000005_17' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242241_0002_m_000005
2015-11-24 22:41:10,288 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242241_0002_m_000005_17: Committed
2015-11-24 22:41:10,289 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 2.0 (TID 17). 1165 bytes result sent to driver
2015-11-24 22:41:10,290 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 2.0 (TID 17) in 91 ms on localhost (6/6)
2015-11-24 22:41:10,290 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (saveAsTextFile at InsightOfDataSet.scala:26) finished in 0.449 s
2015-11-24 22:41:10,290 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-24 22:41:10,295 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsTextFile at InsightOfDataSet.scala:26, took 4.088221 s
2015-11-24 22:41:10,349 INFO  org.apache.spark.SparkContext - Starting job: count at InsightOfDataSet.scala:27
2015-11-24 22:41:10,355 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 1 is 167 bytes
2015-11-24 22:41:10,360 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 189 bytes
2015-11-24 22:41:10,361 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (count at InsightOfDataSet.scala:27) with 6 output partitions
2015-11-24 22:41:10,361 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 5(count at InsightOfDataSet.scala:27)
2015-11-24 22:41:10,361 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 4)
2015-11-24 22:41:10,362 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2015-11-24 22:41:10,362 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (ShuffledRDD[7] at reduceByKey at InsightOfDataSet.scala:24), which has no missing parents
2015-11-24 22:41:10,365 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2112) called with curMem=253969, maxMem=505361203
2015-11-24 22:41:10,365 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 2.1 KB, free 481.7 MB)
2015-11-24 22:41:10,366 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1334) called with curMem=256081, maxMem=505361203
2015-11-24 22:41:10,367 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1334.0 B, free 481.7 MB)
2015-11-24 22:41:10,368 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:53874 (size: 1334.0 B, free: 481.9 MB)
2015-11-24 22:41:10,369 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-24 22:41:10,369 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 5 (ShuffledRDD[7] at reduceByKey at InsightOfDataSet.scala:24)
2015-11-24 22:41:10,369 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 6 tasks
2015-11-24 22:41:10,371 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 18, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:41:10,371 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 18)
2015-11-24 22:41:10,375 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:10,375 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:41:10,380 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 18). 1203 bytes result sent to driver
2015-11-24 22:41:10,381 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 19, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:41:10,382 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 19)
2015-11-24 22:41:10,382 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 18) in 12 ms on localhost (1/6)
2015-11-24 22:41:10,386 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 3 non-empty blocks out of 6 blocks
2015-11-24 22:41:10,386 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:41:10,390 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 19). 1203 bytes result sent to driver
2015-11-24 22:41:10,392 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 5.0 (TID 20, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:41:10,392 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 5.0 (TID 20)
2015-11-24 22:41:10,393 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 19) in 12 ms on localhost (2/6)
2015-11-24 22:41:10,397 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:10,397 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:41:10,401 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 5.0 (TID 20). 1203 bytes result sent to driver
2015-11-24 22:41:10,403 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 5.0 (TID 21, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:41:10,404 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 5.0 (TID 21)
2015-11-24 22:41:10,409 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:10,410 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:41:10,416 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 5.0 (TID 21). 1203 bytes result sent to driver
2015-11-24 22:41:10,418 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 5.0 (TID 20) in 26 ms on localhost (3/6)
2015-11-24 22:41:10,419 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 5.0 (TID 22, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:41:10,420 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 5.0 (TID 22)
2015-11-24 22:41:10,420 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 5.0 (TID 21) in 18 ms on localhost (4/6)
2015-11-24 22:41:10,425 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 4 non-empty blocks out of 6 blocks
2015-11-24 22:41:10,425 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:41:10,429 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 5.0 (TID 22). 1203 bytes result sent to driver
2015-11-24 22:41:10,430 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 5.0 (TID 23, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:41:10,431 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 5.0 (TID 23)
2015-11-24 22:41:10,431 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 5.0 (TID 22) in 13 ms on localhost (5/6)
2015-11-24 22:41:10,435 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:41:10,436 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:41:10,441 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 5.0 (TID 23). 1203 bytes result sent to driver
2015-11-24 22:41:10,442 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 5.0 (TID 23) in 13 ms on localhost (6/6)
2015-11-24 22:41:10,443 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 5 (count at InsightOfDataSet.scala:27) finished in 0.072 s
2015-11-24 22:41:10,443 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-11-24 22:41:10,443 INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: count at InsightOfDataSet.scala:27, took 0.093999 s
2015-11-24 22:41:10,449 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-24 22:41:10,464 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-24 22:41:10,464 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-24 22:41:10,465 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-24 22:41:10,465 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-24 22:41:10,465 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-24 22:41:10,465 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-24 22:41:10,465 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-24 22:41:10,466 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-24 22:41:10,466 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-24 22:41:10,466 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-24 22:41:10,466 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-24 22:41:10,466 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-24 22:41:10,466 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-24 22:41:10,467 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-24 22:41:10,467 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-24 22:41:10,467 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-24 22:41:10,467 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-24 22:41:10,467 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-24 22:41:10,467 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-24 22:41:10,468 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-24 22:41:10,468 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-24 22:41:10,468 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-24 22:41:10,468 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-24 22:41:10,468 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-24 22:41:10,468 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-24 22:41:10,521 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-24 22:41:10,525 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-24 22:41:10,593 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-24 22:41:10,664 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-24 22:41:10,665 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-24 22:41:10,679 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-24 22:41:10,684 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-24 22:41:10,685 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-24 22:41:10,686 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-24 22:41:10,687 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-c2842e80-e151-4d33-946a-31f9c01c6894
2015-11-24 22:48:11,315 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-24 22:48:12,419 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-24 22:48:12,420 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-24 22:48:12,421 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-24 22:48:13,456 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-24 22:48:13,526 INFO  Remoting - Starting remoting
2015-11-24 22:48:13,732 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:53985]
2015-11-24 22:48:13,738 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53985.
2015-11-24 22:48:13,759 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-24 22:48:13,776 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-24 22:48:13,798 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-3d8188ec-8dc7-481a-8b61-dfd6a1c57d47
2015-11-24 22:48:13,812 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-24 22:48:13,900 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-2f0e6e8c-f088-4ef3-914d-81bf435da491\httpd-a0066f2e-b9d5-49db-9550-2fe96102ccb2
2015-11-24 22:48:13,905 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-24 22:48:13,979 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:48:14,001 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:53986
2015-11-24 22:48:14,001 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 53986.
2015-11-24 22:48:14,028 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-24 22:48:14,212 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:48:14,228 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-24 22:48:14,228 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-24 22:48:14,230 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-24 22:48:14,350 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-24 22:48:14,354 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-24 22:48:14,723 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54005.
2015-11-24 22:48:14,723 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 54005
2015-11-24 22:48:14,724 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-24 22:48:14,727 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:54005 with 481.9 MB RAM, BlockManagerId(driver, localhost, 54005)
2015-11-24 22:48:14,728 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-24 22:48:15,401 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-24 22:48:15,403 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-24 22:48:15,449 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-24 22:48:15,450 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-24 22:48:15,453 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:54005 (size: 9.8 KB, free: 481.9 MB)
2015-11-24 22:48:15,459 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at InsightOfDataSet.scala:16
2015-11-24 22:48:16,967 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c701%29, but we couldn't find any external IP address!
2015-11-24 22:48:17,756 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 3
2015-11-24 22:48:17,897 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-24 22:48:17,897 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-24 22:48:17,897 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-24 22:48:17,897 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-24 22:48:17,897 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-24 22:48:18,059 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at InsightOfDataSet.scala:33
2015-11-24 22:48:18,088 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 4 (distinct at InsightOfDataSet.scala:30)
2015-11-24 22:48:18,089 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 7 (map at InsightOfDataSet.scala:31)
2015-11-24 22:48:18,092 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsTextFile at InsightOfDataSet.scala:33) with 6 output partitions
2015-11-24 22:48:18,092 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2(saveAsTextFile at InsightOfDataSet.scala:33)
2015-11-24 22:48:18,093 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2015-11-24 22:48:18,095 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2015-11-24 22:48:18,105 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at distinct at InsightOfDataSet.scala:30), which has no missing parents
2015-11-24 22:48:18,134 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(4208) called with curMem=116545, maxMem=505361203
2015-11-24 22:48:18,135 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 481.8 MB)
2015-11-24 22:48:18,137 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2348) called with curMem=120753, maxMem=505361203
2015-11-24 22:48:18,138 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 481.8 MB)
2015-11-24 22:48:18,139 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:54005 (size: 2.3 KB, free: 481.9 MB)
2015-11-24 22:48:18,140 INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-11-24 22:48:18,144 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at distinct at InsightOfDataSet.scala:30)
2015-11-24 22:48:18,145 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 6 tasks
2015-11-24 22:48:18,182 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:48:18,188 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-24 22:48:18,211 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:0+33554432
2015-11-24 22:48:19,349 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2258 bytes result sent to driver
2015-11-24 22:48:19,352 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:48:19,353 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2015-11-24 22:48:19,360 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1188 ms on localhost (1/6)
2015-11-24 22:48:19,360 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:33554432+20843526
2015-11-24 22:48:19,786 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 2258 bytes result sent to driver
2015-11-24 22:48:19,788 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:48:19,797 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
2015-11-24 22:48:19,800 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 449 ms on localhost (2/6)
2015-11-24 22:48:19,805 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:0+33554432
2015-11-24 22:48:20,301 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 2258 bytes result sent to driver
2015-11-24 22:48:20,303 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:48:20,304 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
2015-11-24 22:48:20,305 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 517 ms on localhost (3/6)
2015-11-24 22:48:20,310 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:33554432+20844232
2015-11-24 22:48:20,602 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 2258 bytes result sent to driver
2015-11-24 22:48:20,603 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:48:20,604 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
2015-11-24 22:48:20,606 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 303 ms on localhost (4/6)
2015-11-24 22:48:20,611 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:0+33554432
2015-11-24 22:48:21,060 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 2258 bytes result sent to driver
2015-11-24 22:48:21,062 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 0.0 (TID 5, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:48:21,062 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 0.0 (TID 5)
2015-11-24 22:48:21,064 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 461 ms on localhost (5/6)
2015-11-24 22:48:21,069 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:33554432+20845196
2015-11-24 22:48:21,345 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 0.0 (TID 5). 2258 bytes result sent to driver
2015-11-24 22:48:21,348 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 0.0 (TID 5) in 286 ms on localhost (6/6)
2015-11-24 22:48:21,348 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (distinct at InsightOfDataSet.scala:30) finished in 3.191 s
2015-11-24 22:48:21,349 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:48:21,350 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:48:21,350 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 1, ResultStage 2)
2015-11-24 22:48:21,351 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:48:21,352 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 1: List()
2015-11-24 22:48:21,353 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List(ShuffleMapStage 1)
2015-11-24 22:48:21,355 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at InsightOfDataSet.scala:31), which is now runnable
2015-11-24 22:48:21,359 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2704) called with curMem=123101, maxMem=505361203
2015-11-24 22:48:21,359 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 481.8 MB)
2015-11-24 22:48:21,362 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1570) called with curMem=125805, maxMem=505361203
2015-11-24 22:48:21,362 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1570.0 B, free 481.8 MB)
2015-11-24 22:48:21,365 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:54005 (size: 1570.0 B, free: 481.9 MB)
2015-11-24 22:48:21,349 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-24 22:48:21,366 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-24 22:48:21,366 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at InsightOfDataSet.scala:31)
2015-11-24 22:48:21,367 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 6 tasks
2015-11-24 22:48:21,369 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 6, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:48:21,369 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 6)
2015-11-24 22:48:21,386 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:21,387 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 4 ms
2015-11-24 22:48:21,436 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 6). 1379 bytes result sent to driver
2015-11-24 22:48:21,438 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 7, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:48:21,441 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 7)
2015-11-24 22:48:21,443 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 6) in 75 ms on localhost (1/6)
2015-11-24 22:48:21,446 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:21,446 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:48:21,467 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 7). 1379 bytes result sent to driver
2015-11-24 22:48:21,468 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 1.0 (TID 8, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:48:21,468 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 1.0 (TID 8)
2015-11-24 22:48:21,468 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 7) in 31 ms on localhost (2/6)
2015-11-24 22:48:21,472 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:21,472 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:48:21,494 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 1.0 (TID 8). 1379 bytes result sent to driver
2015-11-24 22:48:21,495 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 1.0 (TID 9, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:48:21,495 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 1.0 (TID 9)
2015-11-24 22:48:21,496 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 1.0 (TID 8) in 28 ms on localhost (3/6)
2015-11-24 22:48:21,500 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:21,500 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:48:21,521 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 1.0 (TID 9). 1379 bytes result sent to driver
2015-11-24 22:48:21,523 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 1.0 (TID 10, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:48:21,524 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 1.0 (TID 10)
2015-11-24 22:48:21,525 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 1.0 (TID 9) in 30 ms on localhost (4/6)
2015-11-24 22:48:21,529 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:21,530 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:48:21,573 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 1.0 (TID 10). 1379 bytes result sent to driver
2015-11-24 22:48:21,574 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 1.0 (TID 11, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:48:21,574 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 1.0 (TID 11)
2015-11-24 22:48:21,574 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 1.0 (TID 10) in 52 ms on localhost (5/6)
2015-11-24 22:48:21,579 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:21,579 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:48:21,677 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 1.0 (TID 11). 1379 bytes result sent to driver
2015-11-24 22:48:21,678 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 1.0 (TID 11) in 105 ms on localhost (6/6)
2015-11-24 22:48:21,678 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at InsightOfDataSet.scala:31) finished in 0.311 s
2015-11-24 22:48:21,678 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-24 22:48:21,678 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:48:21,679 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:48:21,679 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-24 22:48:21,679 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:48:21,679 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List()
2015-11-24 22:48:21,679 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[9] at saveAsTextFile at InsightOfDataSet.scala:33), which is now runnable
2015-11-24 22:48:21,723 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95496) called with curMem=127375, maxMem=505361203
2015-11-24 22:48:21,723 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 93.3 KB, free 481.7 MB)
2015-11-24 22:48:21,795 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31329) called with curMem=222871, maxMem=505361203
2015-11-24 22:48:21,798 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 30.6 KB, free 481.7 MB)
2015-11-24 22:48:21,801 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:54005 (size: 30.6 KB, free: 481.9 MB)
2015-11-24 22:48:21,803 INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-11-24 22:48:21,808 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at saveAsTextFile at InsightOfDataSet.scala:33)
2015-11-24 22:48:21,808 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 6 tasks
2015-11-24 22:48:21,813 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 12, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:48:21,813 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 12)
2015-11-24 22:48:21,839 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-24 22:48:21,840 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-24 22:48:21,842 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-24 22:48:21,846 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-24 22:48:21,869 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:21,870 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:48:21,924 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242248_0002_m_000000_12' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242248_0002_m_000000
2015-11-24 22:48:21,925 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242248_0002_m_000000_12: Committed
2015-11-24 22:48:21,926 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 12). 1165 bytes result sent to driver
2015-11-24 22:48:21,927 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 13, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:48:21,927 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 13)
2015-11-24 22:48:21,928 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 12) in 117 ms on localhost (1/6)
2015-11-24 22:48:21,961 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 6 blocks
2015-11-24 22:48:21,961 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:48:21,992 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242248_0002_m_000001_13' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242248_0002_m_000001
2015-11-24 22:48:21,992 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242248_0002_m_000001_13: Committed
2015-11-24 22:48:21,993 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 13). 1165 bytes result sent to driver
2015-11-24 22:48:21,994 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 2.0 (TID 14, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:48:21,994 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 2.0 (TID 14)
2015-11-24 22:48:21,994 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 13) in 68 ms on localhost (2/6)
2015-11-24 22:48:22,036 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:22,036 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:48:22,057 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242248_0002_m_000002_14' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242248_0002_m_000002
2015-11-24 22:48:22,057 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242248_0002_m_000002_14: Committed
2015-11-24 22:48:22,057 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 2.0 (TID 14). 1165 bytes result sent to driver
2015-11-24 22:48:22,058 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 2.0 (TID 15, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:48:22,059 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 2.0 (TID 15)
2015-11-24 22:48:22,059 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 2.0 (TID 14) in 66 ms on localhost (3/6)
2015-11-24 22:48:22,096 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:22,096 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:48:22,116 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242248_0002_m_000003_15' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242248_0002_m_000003
2015-11-24 22:48:22,116 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242248_0002_m_000003_15: Committed
2015-11-24 22:48:22,117 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 2.0 (TID 15). 1165 bytes result sent to driver
2015-11-24 22:48:22,118 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 2.0 (TID 16, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:48:22,118 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 2.0 (TID 16)
2015-11-24 22:48:22,119 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 2.0 (TID 15) in 60 ms on localhost (4/6)
2015-11-24 22:48:22,148 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 6 blocks
2015-11-24 22:48:22,148 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:48:22,165 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242248_0002_m_000004_16' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242248_0002_m_000004
2015-11-24 22:48:22,165 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242248_0002_m_000004_16: Committed
2015-11-24 22:48:22,165 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 2.0 (TID 16). 1165 bytes result sent to driver
2015-11-24 22:48:22,166 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 2.0 (TID 17, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:48:22,167 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 2.0 (TID 17)
2015-11-24 22:48:22,167 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 2.0 (TID 16) in 50 ms on localhost (5/6)
2015-11-24 22:48:22,217 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:22,217 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:48:22,244 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242248_0002_m_000005_17' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242248_0002_m_000005
2015-11-24 22:48:22,244 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242248_0002_m_000005_17: Committed
2015-11-24 22:48:22,245 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 2.0 (TID 17). 1165 bytes result sent to driver
2015-11-24 22:48:22,256 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 2.0 (TID 17) in 90 ms on localhost (6/6)
2015-11-24 22:48:22,257 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-24 22:48:22,258 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (saveAsTextFile at InsightOfDataSet.scala:33) finished in 0.449 s
2015-11-24 22:48:22,273 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsTextFile at InsightOfDataSet.scala:33, took 4.212856 s
2015-11-24 22:48:22,604 INFO  org.apache.spark.SparkContext - Starting job: count at InsightOfDataSet.scala:34
2015-11-24 22:48:22,614 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 1 is 167 bytes
2015-11-24 22:48:22,623 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 160 bytes
2015-11-24 22:48:22,624 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (count at InsightOfDataSet.scala:34) with 6 output partitions
2015-11-24 22:48:22,624 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 5(count at InsightOfDataSet.scala:34)
2015-11-24 22:48:22,624 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 4)
2015-11-24 22:48:22,625 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2015-11-24 22:48:22,625 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (ShuffledRDD[8] at reduceByKey at InsightOfDataSet.scala:31), which has no missing parents
2015-11-24 22:48:22,627 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2112) called with curMem=254200, maxMem=505361203
2015-11-24 22:48:22,627 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 2.1 KB, free 481.7 MB)
2015-11-24 22:48:22,628 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1334) called with curMem=256312, maxMem=505361203
2015-11-24 22:48:22,629 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1334.0 B, free 481.7 MB)
2015-11-24 22:48:22,630 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:54005 (size: 1334.0 B, free: 481.9 MB)
2015-11-24 22:48:22,631 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-24 22:48:22,631 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 5 (ShuffledRDD[8] at reduceByKey at InsightOfDataSet.scala:31)
2015-11-24 22:48:22,631 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 6 tasks
2015-11-24 22:48:22,633 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 18, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:48:22,633 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 18)
2015-11-24 22:48:22,637 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:22,637 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:48:22,641 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 18). 1203 bytes result sent to driver
2015-11-24 22:48:22,642 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 19, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:48:22,642 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 19)
2015-11-24 22:48:22,643 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 18) in 11 ms on localhost (1/6)
2015-11-24 22:48:22,646 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 6 blocks
2015-11-24 22:48:22,646 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:48:22,648 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 19). 1203 bytes result sent to driver
2015-11-24 22:48:22,649 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 5.0 (TID 20, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:48:22,650 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 5.0 (TID 20)
2015-11-24 22:48:22,650 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 19) in 9 ms on localhost (2/6)
2015-11-24 22:48:22,654 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:22,654 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:48:22,658 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 5.0 (TID 20). 1203 bytes result sent to driver
2015-11-24 22:48:22,659 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 5.0 (TID 21, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:48:22,660 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 5.0 (TID 21)
2015-11-24 22:48:22,660 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 5.0 (TID 20) in 12 ms on localhost (3/6)
2015-11-24 22:48:22,663 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:22,663 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:48:22,668 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 5.0 (TID 21). 1203 bytes result sent to driver
2015-11-24 22:48:22,669 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 5.0 (TID 22, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:48:22,669 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 5.0 (TID 22)
2015-11-24 22:48:22,672 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 5.0 (TID 21) in 12 ms on localhost (4/6)
2015-11-24 22:48:22,673 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 6 blocks
2015-11-24 22:48:22,673 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:48:22,674 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 5.0 (TID 22). 1203 bytes result sent to driver
2015-11-24 22:48:22,674 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 5.0 (TID 23, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:48:22,675 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 5.0 (TID 23)
2015-11-24 22:48:22,679 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:48:22,679 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:48:22,683 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 5.0 (TID 23). 1203 bytes result sent to driver
2015-11-24 22:48:22,686 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 5.0 (TID 22) in 17 ms on localhost (5/6)
2015-11-24 22:48:22,687 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 5.0 (TID 23) in 13 ms on localhost (6/6)
2015-11-24 22:48:22,688 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-11-24 22:48:22,689 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 5 (count at InsightOfDataSet.scala:34) finished in 0.056 s
2015-11-24 22:48:22,690 INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: count at InsightOfDataSet.scala:34, took 0.085360 s
2015-11-24 22:48:22,699 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-24 22:48:22,713 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-24 22:48:22,714 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-24 22:48:22,714 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-24 22:48:22,714 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-24 22:48:22,715 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-24 22:48:22,715 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-24 22:48:22,715 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-24 22:48:22,715 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-24 22:48:22,716 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-24 22:48:22,716 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-24 22:48:22,716 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-24 22:48:22,716 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-24 22:48:22,716 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-24 22:48:22,716 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-24 22:48:22,717 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-24 22:48:22,717 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-24 22:48:22,717 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-24 22:48:22,717 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-24 22:48:22,717 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-24 22:48:22,718 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-24 22:48:22,718 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-24 22:48:22,718 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-24 22:48:22,718 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-24 22:48:22,718 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-24 22:48:22,718 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-24 22:48:22,770 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-24 22:48:22,774 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-24 22:48:22,838 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-24 22:48:23,082 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-24 22:48:23,083 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-24 22:48:23,094 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-24 22:48:23,098 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-24 22:48:23,099 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-24 22:48:23,100 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-2f0e6e8c-f088-4ef3-914d-81bf435da491
2015-11-24 22:48:23,116 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - Shutting down remote daemon.
2015-11-24 22:48:23,118 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - Remote daemon shut down; proceeding with flushing remote transports.
2015-11-24 22:51:04,820 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-24 22:51:06,092 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-24 22:51:06,093 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-24 22:51:06,094 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-24 22:51:07,062 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-24 22:51:07,117 INFO  Remoting - Starting remoting
2015-11-24 22:51:07,327 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:54067]
2015-11-24 22:51:07,334 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54067.
2015-11-24 22:51:07,355 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-24 22:51:07,372 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-24 22:51:07,396 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-c93bdfe4-0ba5-491f-9d59-f6b0102ef578
2015-11-24 22:51:07,410 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-24 22:51:07,497 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-9e0c21f4-c8d8-456a-bc9f-adc8d91d6ab0\httpd-932013e2-6cfb-4c98-9350-3e079b822d95
2015-11-24 22:51:07,503 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-24 22:51:07,572 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:51:07,600 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:54068
2015-11-24 22:51:07,600 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 54068.
2015-11-24 22:51:07,630 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-24 22:51:07,808 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:51:07,825 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-24 22:51:07,825 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-24 22:51:07,828 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-24 22:51:07,949 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-24 22:51:07,970 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-24 22:51:08,346 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54087.
2015-11-24 22:51:08,347 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 54087
2015-11-24 22:51:08,348 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-24 22:51:08,351 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:54087 with 481.9 MB RAM, BlockManagerId(driver, localhost, 54087)
2015-11-24 22:51:08,352 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-24 22:51:09,046 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-24 22:51:09,048 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-24 22:51:09,093 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-24 22:51:09,094 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-24 22:51:09,097 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:54087 (size: 9.8 KB, free: 481.9 MB)
2015-11-24 22:51:09,103 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at InsightOfDataSet.scala:16
2015-11-24 22:51:10,430 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c701%29, but we couldn't find any external IP address!
2015-11-24 22:51:11,380 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 3
2015-11-24 22:51:11,933 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-24 22:51:11,933 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-24 22:51:11,933 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-24 22:51:11,933 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-24 22:51:11,933 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-24 22:51:12,483 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at InsightOfDataSet.scala:33
2015-11-24 22:51:12,510 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 4 (distinct at InsightOfDataSet.scala:30)
2015-11-24 22:51:12,511 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 7 (map at InsightOfDataSet.scala:31)
2015-11-24 22:51:12,511 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 9 (coalesce at InsightOfDataSet.scala:33)
2015-11-24 22:51:12,514 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsTextFile at InsightOfDataSet.scala:33) with 1 output partitions
2015-11-24 22:51:12,514 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 3(saveAsTextFile at InsightOfDataSet.scala:33)
2015-11-24 22:51:12,515 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 2)
2015-11-24 22:51:12,516 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 2)
2015-11-24 22:51:12,522 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at distinct at InsightOfDataSet.scala:30), which has no missing parents
2015-11-24 22:51:12,555 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(4208) called with curMem=116545, maxMem=505361203
2015-11-24 22:51:12,555 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 481.8 MB)
2015-11-24 22:51:12,559 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2348) called with curMem=120753, maxMem=505361203
2015-11-24 22:51:12,559 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 481.8 MB)
2015-11-24 22:51:12,560 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:54087 (size: 2.3 KB, free: 481.9 MB)
2015-11-24 22:51:12,562 INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-11-24 22:51:12,567 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at distinct at InsightOfDataSet.scala:30)
2015-11-24 22:51:12,569 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 6 tasks
2015-11-24 22:51:12,612 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:51:12,623 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-24 22:51:12,665 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:0+33554432
2015-11-24 22:51:14,023 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2258 bytes result sent to driver
2015-11-24 22:51:14,025 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:51:14,025 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2015-11-24 22:51:14,032 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:33554432+20843526
2015-11-24 22:51:14,033 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1434 ms on localhost (1/6)
2015-11-24 22:51:14,355 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 2258 bytes result sent to driver
2015-11-24 22:51:14,357 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:51:14,357 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
2015-11-24 22:51:14,359 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 335 ms on localhost (2/6)
2015-11-24 22:51:14,365 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:0+33554432
2015-11-24 22:51:14,860 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 2258 bytes result sent to driver
2015-11-24 22:51:14,861 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:51:14,862 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
2015-11-24 22:51:14,862 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 506 ms on localhost (3/6)
2015-11-24 22:51:14,869 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:33554432+20844232
2015-11-24 22:51:15,146 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 2258 bytes result sent to driver
2015-11-24 22:51:15,148 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:51:15,148 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
2015-11-24 22:51:15,149 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 289 ms on localhost (4/6)
2015-11-24 22:51:15,154 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:0+33554432
2015-11-24 22:51:15,600 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 2258 bytes result sent to driver
2015-11-24 22:51:15,601 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 0.0 (TID 5, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:51:15,602 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 0.0 (TID 5)
2015-11-24 22:51:15,603 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 456 ms on localhost (5/6)
2015-11-24 22:51:15,607 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:33554432+20845196
2015-11-24 22:51:15,977 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 0.0 (TID 5). 2258 bytes result sent to driver
2015-11-24 22:51:15,980 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 0.0 (TID 5) in 380 ms on localhost (6/6)
2015-11-24 22:51:15,981 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (distinct at InsightOfDataSet.scala:30) finished in 3.398 s
2015-11-24 22:51:15,982 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:51:15,982 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-24 22:51:15,982 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:51:15,983 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 1, ShuffleMapStage 2, ResultStage 3)
2015-11-24 22:51:15,983 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:51:15,985 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 1: List()
2015-11-24 22:51:15,986 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 2: List(ShuffleMapStage 1)
2015-11-24 22:51:15,986 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 3: List(ShuffleMapStage 2)
2015-11-24 22:51:15,988 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at InsightOfDataSet.scala:31), which is now runnable
2015-11-24 22:51:15,992 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2704) called with curMem=123101, maxMem=505361203
2015-11-24 22:51:15,992 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 481.8 MB)
2015-11-24 22:51:15,993 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1570) called with curMem=125805, maxMem=505361203
2015-11-24 22:51:15,994 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1570.0 B, free 481.8 MB)
2015-11-24 22:51:15,995 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:54087 (size: 1570.0 B, free: 481.9 MB)
2015-11-24 22:51:15,996 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-24 22:51:15,996 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at InsightOfDataSet.scala:31)
2015-11-24 22:51:15,996 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 6 tasks
2015-11-24 22:51:15,998 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 6, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:51:15,999 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 6)
2015-11-24 22:51:16,012 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:16,013 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 4 ms
2015-11-24 22:51:16,061 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 6). 1379 bytes result sent to driver
2015-11-24 22:51:16,062 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 7, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:51:16,062 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 7)
2015-11-24 22:51:16,063 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 6) in 65 ms on localhost (1/6)
2015-11-24 22:51:16,067 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:16,067 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:16,124 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 7). 1379 bytes result sent to driver
2015-11-24 22:51:16,125 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 1.0 (TID 8, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:51:16,126 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 1.0 (TID 8)
2015-11-24 22:51:16,126 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 7) in 65 ms on localhost (2/6)
2015-11-24 22:51:16,130 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:16,130 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:16,151 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 1.0 (TID 8). 1379 bytes result sent to driver
2015-11-24 22:51:16,153 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 1.0 (TID 9, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:51:16,153 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 1.0 (TID 9)
2015-11-24 22:51:16,153 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 1.0 (TID 8) in 29 ms on localhost (3/6)
2015-11-24 22:51:16,158 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:16,158 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:51:16,288 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 1.0 (TID 9). 1379 bytes result sent to driver
2015-11-24 22:51:16,297 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 1.0 (TID 10, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:51:16,299 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 1.0 (TID 9) in 147 ms on localhost (4/6)
2015-11-24 22:51:16,308 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 1.0 (TID 10)
2015-11-24 22:51:16,319 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:16,319 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:16,355 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 1.0 (TID 10). 1379 bytes result sent to driver
2015-11-24 22:51:16,356 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 1.0 (TID 11, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:51:16,357 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 1.0 (TID 10) in 59 ms on localhost (5/6)
2015-11-24 22:51:16,357 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 1.0 (TID 11)
2015-11-24 22:51:16,361 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:16,361 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:16,381 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 1.0 (TID 11). 1379 bytes result sent to driver
2015-11-24 22:51:16,382 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 1.0 (TID 11) in 27 ms on localhost (6/6)
2015-11-24 22:51:16,382 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at InsightOfDataSet.scala:31) finished in 0.385 s
2015-11-24 22:51:16,382 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-24 22:51:16,382 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:51:16,382 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:51:16,383 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 2, ResultStage 3)
2015-11-24 22:51:16,383 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:51:16,383 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 2: List()
2015-11-24 22:51:16,383 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 3: List(ShuffleMapStage 2)
2015-11-24 22:51:16,384 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 2 (MapPartitionsRDD[9] at coalesce at InsightOfDataSet.scala:33), which is now runnable
2015-11-24 22:51:16,386 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2688) called with curMem=127375, maxMem=505361203
2015-11-24 22:51:16,387 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 481.8 MB)
2015-11-24 22:51:16,388 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1587) called with curMem=130063, maxMem=505361203
2015-11-24 22:51:16,389 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1587.0 B, free 481.8 MB)
2015-11-24 22:51:16,389 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:54087 (size: 1587.0 B, free: 481.9 MB)
2015-11-24 22:51:16,390 INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-11-24 22:51:16,391 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[9] at coalesce at InsightOfDataSet.scala:33)
2015-11-24 22:51:16,391 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 6 tasks
2015-11-24 22:51:16,392 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 12, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:51:16,392 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 12)
2015-11-24 22:51:16,395 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:16,396 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:51:16,674 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 12). 1374 bytes result sent to driver
2015-11-24 22:51:16,675 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 13, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:51:16,675 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 13)
2015-11-24 22:51:16,676 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 12) in 284 ms on localhost (1/6)
2015-11-24 22:51:16,679 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 6 blocks
2015-11-24 22:51:16,679 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:16,686 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 13). 1374 bytes result sent to driver
2015-11-24 22:51:16,688 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 2.0 (TID 14, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:51:16,688 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 2.0 (TID 14)
2015-11-24 22:51:16,688 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 13) in 14 ms on localhost (2/6)
2015-11-24 22:51:16,691 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:16,691 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:16,712 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 2.0 (TID 14). 1374 bytes result sent to driver
2015-11-24 22:51:16,713 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 2.0 (TID 15, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:51:16,714 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 2.0 (TID 15)
2015-11-24 22:51:16,715 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 2.0 (TID 14) in 28 ms on localhost (3/6)
2015-11-24 22:51:16,719 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:16,719 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:51:16,729 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 2.0 (TID 15). 1374 bytes result sent to driver
2015-11-24 22:51:16,730 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 2.0 (TID 16, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:51:16,731 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 2.0 (TID 16)
2015-11-24 22:51:16,731 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 2.0 (TID 15) in 19 ms on localhost (4/6)
2015-11-24 22:51:16,737 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 6 blocks
2015-11-24 22:51:16,737 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:16,797 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 2.0 (TID 16). 1374 bytes result sent to driver
2015-11-24 22:51:16,798 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 2.0 (TID 17, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:51:16,799 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 2.0 (TID 17)
2015-11-24 22:51:16,799 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 2.0 (TID 16) in 69 ms on localhost (5/6)
2015-11-24 22:51:16,802 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:16,803 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:51:16,868 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 2.0 (TID 17). 1374 bytes result sent to driver
2015-11-24 22:51:16,870 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 2.0 (TID 17) in 72 ms on localhost (6/6)
2015-11-24 22:51:16,870 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 2 (coalesce at InsightOfDataSet.scala:33) finished in 0.479 s
2015-11-24 22:51:16,870 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-24 22:51:16,870 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:51:16,870 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:51:16,870 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 3)
2015-11-24 22:51:16,870 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:51:16,871 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 3: List()
2015-11-24 22:51:16,871 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at saveAsTextFile at InsightOfDataSet.scala:33), which is now runnable
2015-11-24 22:51:16,936 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95776) called with curMem=131650, maxMem=505361203
2015-11-24 22:51:16,937 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 93.5 KB, free 481.7 MB)
2015-11-24 22:51:16,939 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31396) called with curMem=227426, maxMem=505361203
2015-11-24 22:51:16,939 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 30.7 KB, free 481.7 MB)
2015-11-24 22:51:16,940 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:54087 (size: 30.7 KB, free: 481.9 MB)
2015-11-24 22:51:16,941 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-24 22:51:16,943 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at saveAsTextFile at InsightOfDataSet.scala:33)
2015-11-24 22:51:16,943 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks
2015-11-24 22:51:17,110 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 18, localhost, PROCESS_LOCAL, 2170 bytes)
2015-11-24 22:51:17,111 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 18)
2015-11-24 22:51:17,156 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-24 22:51:17,157 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-24 22:51:17,159 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-24 22:51:17,162 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-24 22:51:17,226 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 5 non-empty blocks out of 6 blocks
2015-11-24 22:51:17,226 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:17,304 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242251_0003_m_000000_18' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegion/_temporary/0/task_201511242251_0003_m_000000
2015-11-24 22:51:17,306 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242251_0003_m_000000_18: Committed
2015-11-24 22:51:17,309 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 18). 1165 bytes result sent to driver
2015-11-24 22:51:17,311 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 18) in 366 ms on localhost (1/1)
2015-11-24 22:51:17,311 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 3 (saveAsTextFile at InsightOfDataSet.scala:33) finished in 0.367 s
2015-11-24 22:51:17,311 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-11-24 22:51:17,318 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsTextFile at InsightOfDataSet.scala:33, took 4.834459 s
2015-11-24 22:51:17,356 INFO  org.apache.spark.SparkContext - Starting job: count at InsightOfDataSet.scala:34
2015-11-24 22:51:17,367 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 2 is 167 bytes
2015-11-24 22:51:17,371 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 1 is 160 bytes
2015-11-24 22:51:17,372 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (count at InsightOfDataSet.scala:34) with 6 output partitions
2015-11-24 22:51:17,372 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 6(count at InsightOfDataSet.scala:34)
2015-11-24 22:51:17,372 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 5)
2015-11-24 22:51:17,372 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2015-11-24 22:51:17,373 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (ShuffledRDD[8] at reduceByKey at InsightOfDataSet.scala:31), which has no missing parents
2015-11-24 22:51:17,375 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2112) called with curMem=258822, maxMem=505361203
2015-11-24 22:51:17,375 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 2.1 KB, free 481.7 MB)
2015-11-24 22:51:17,397 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1331) called with curMem=260934, maxMem=505361203
2015-11-24 22:51:17,397 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 1331.0 B, free 481.7 MB)
2015-11-24 22:51:17,398 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:54087 (size: 1331.0 B, free: 481.9 MB)
2015-11-24 22:51:17,399 INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-11-24 22:51:17,399 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 6 (ShuffledRDD[8] at reduceByKey at InsightOfDataSet.scala:31)
2015-11-24 22:51:17,399 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 6 tasks
2015-11-24 22:51:17,400 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 19, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:51:17,400 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 19)
2015-11-24 22:51:17,404 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:17,404 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:17,408 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 19). 1203 bytes result sent to driver
2015-11-24 22:51:17,409 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 6.0 (TID 20, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:51:17,410 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 19) in 10 ms on localhost (1/6)
2015-11-24 22:51:17,410 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 6.0 (TID 20)
2015-11-24 22:51:17,414 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 6 blocks
2015-11-24 22:51:17,414 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:17,415 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 6.0 (TID 20). 1203 bytes result sent to driver
2015-11-24 22:51:17,416 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 6.0 (TID 21, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:51:17,416 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 6.0 (TID 21)
2015-11-24 22:51:17,420 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:17,420 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:17,424 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 6.0 (TID 21). 1203 bytes result sent to driver
2015-11-24 22:51:17,425 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 6.0 (TID 22, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:51:17,426 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 6.0 (TID 22)
2015-11-24 22:51:17,427 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 6.0 (TID 21) in 10 ms on localhost (2/6)
2015-11-24 22:51:17,428 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 6.0 (TID 20) in 20 ms on localhost (3/6)
2015-11-24 22:51:17,429 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:17,429 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:17,432 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 6.0 (TID 22). 1203 bytes result sent to driver
2015-11-24 22:51:17,433 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 6.0 (TID 23, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:51:17,434 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 6.0 (TID 23)
2015-11-24 22:51:17,434 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 6.0 (TID 22) in 9 ms on localhost (4/6)
2015-11-24 22:51:17,439 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 6 blocks
2015-11-24 22:51:17,439 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:17,440 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 6.0 (TID 23). 1203 bytes result sent to driver
2015-11-24 22:51:17,442 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 6.0 (TID 24, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:51:17,443 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 6.0 (TID 24)
2015-11-24 22:51:17,443 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 6.0 (TID 23) in 10 ms on localhost (5/6)
2015-11-24 22:51:17,446 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:51:17,446 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:51:17,449 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 6.0 (TID 24). 1203 bytes result sent to driver
2015-11-24 22:51:17,451 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 6.0 (TID 24) in 9 ms on localhost (6/6)
2015-11-24 22:51:17,451 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 6 (count at InsightOfDataSet.scala:34) finished in 0.052 s
2015-11-24 22:51:17,452 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-11-24 22:51:17,452 INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: count at InsightOfDataSet.scala:34, took 0.095979 s
2015-11-24 22:51:17,457 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-24 22:51:17,471 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-24 22:51:17,471 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-24 22:51:17,471 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-24 22:51:17,472 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-24 22:51:17,472 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-24 22:51:17,472 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-24 22:51:17,472 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-24 22:51:17,472 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-24 22:51:17,472 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-24 22:51:17,472 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-24 22:51:17,473 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-24 22:51:17,473 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-24 22:51:17,473 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-24 22:51:17,473 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-24 22:51:17,473 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-24 22:51:17,474 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-24 22:51:17,474 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-24 22:51:17,474 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-24 22:51:17,474 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-24 22:51:17,474 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-24 22:51:17,474 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-24 22:51:17,474 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-24 22:51:17,475 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-24 22:51:17,475 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-24 22:51:17,475 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-24 22:51:17,526 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-24 22:51:17,530 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-24 22:51:17,594 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-24 22:51:17,682 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-24 22:51:17,683 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-24 22:51:17,693 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-24 22:51:17,696 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-24 22:51:17,698 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-24 22:51:17,699 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-24 22:51:17,701 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-9e0c21f4-c8d8-456a-bc9f-adc8d91d6ab0
2015-11-24 22:53:12,355 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-24 22:53:13,688 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-24 22:53:13,689 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-24 22:53:13,690 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-24 22:53:14,757 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-24 22:53:14,805 INFO  Remoting - Starting remoting
2015-11-24 22:53:15,004 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:54143]
2015-11-24 22:53:15,010 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54143.
2015-11-24 22:53:15,032 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-24 22:53:15,048 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-24 22:53:15,072 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-794adbf3-2f29-4f39-acd2-cd9f5c897e7c
2015-11-24 22:53:15,087 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-24 22:53:15,176 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-5c21eaab-0f78-4531-b004-98ec92edbc91\httpd-d89a6d20-45a8-41a4-8e33-19370becbc83
2015-11-24 22:53:15,181 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-24 22:53:15,248 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:53:15,269 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:54144
2015-11-24 22:53:15,269 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 54144.
2015-11-24 22:53:15,293 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-24 22:53:15,472 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 22:53:15,488 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-24 22:53:15,488 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-24 22:53:15,490 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-24 22:53:15,606 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-24 22:53:15,610 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-24 22:53:16,039 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54163.
2015-11-24 22:53:16,040 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 54163
2015-11-24 22:53:16,042 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-24 22:53:16,045 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:54163 with 481.9 MB RAM, BlockManagerId(driver, localhost, 54163)
2015-11-24 22:53:16,047 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-24 22:53:16,778 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-24 22:53:16,780 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-24 22:53:16,822 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-24 22:53:16,822 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-24 22:53:16,826 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:54163 (size: 9.8 KB, free: 481.9 MB)
2015-11-24 22:53:16,832 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at InsightOfDataSet.scala:16
2015-11-24 22:53:18,180 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c701%29, but we couldn't find any external IP address!
2015-11-24 22:53:19,172 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 3
2015-11-24 22:53:19,335 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-24 22:53:19,335 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-24 22:53:19,335 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-24 22:53:19,335 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-24 22:53:19,335 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-24 22:53:19,514 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at InsightOfDataSet.scala:33
2015-11-24 22:53:19,547 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 4 (distinct at InsightOfDataSet.scala:30)
2015-11-24 22:53:19,549 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 7 (map at InsightOfDataSet.scala:31)
2015-11-24 22:53:19,550 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 9 (coalesce at InsightOfDataSet.scala:33)
2015-11-24 22:53:19,554 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsTextFile at InsightOfDataSet.scala:33) with 1 output partitions
2015-11-24 22:53:19,555 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 3(saveAsTextFile at InsightOfDataSet.scala:33)
2015-11-24 22:53:19,556 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 2)
2015-11-24 22:53:19,558 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 2)
2015-11-24 22:53:19,568 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at distinct at InsightOfDataSet.scala:30), which has no missing parents
2015-11-24 22:53:19,608 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(4208) called with curMem=116545, maxMem=505361203
2015-11-24 22:53:19,609 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 481.8 MB)
2015-11-24 22:53:19,612 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2348) called with curMem=120753, maxMem=505361203
2015-11-24 22:53:19,613 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 481.8 MB)
2015-11-24 22:53:19,615 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:54163 (size: 2.3 KB, free: 481.9 MB)
2015-11-24 22:53:19,617 INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-11-24 22:53:19,622 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at distinct at InsightOfDataSet.scala:30)
2015-11-24 22:53:19,625 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 6 tasks
2015-11-24 22:53:19,673 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:53:19,682 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-24 22:53:19,718 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:0+33554432
2015-11-24 22:53:21,101 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2258 bytes result sent to driver
2015-11-24 22:53:21,103 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:53:21,104 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2015-11-24 22:53:21,111 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:33554432+20843526
2015-11-24 22:53:21,114 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1457 ms on localhost (1/6)
2015-11-24 22:53:21,433 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 2258 bytes result sent to driver
2015-11-24 22:53:21,435 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:53:21,436 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
2015-11-24 22:53:21,437 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 335 ms on localhost (2/6)
2015-11-24 22:53:21,443 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:0+33554432
2015-11-24 22:53:21,925 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 2258 bytes result sent to driver
2015-11-24 22:53:21,927 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:53:21,927 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
2015-11-24 22:53:21,933 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:33554432+20844232
2015-11-24 22:53:21,933 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 499 ms on localhost (3/6)
2015-11-24 22:53:22,224 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 2258 bytes result sent to driver
2015-11-24 22:53:22,226 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:53:22,226 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
2015-11-24 22:53:22,227 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 301 ms on localhost (4/6)
2015-11-24 22:53:22,232 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:0+33554432
2015-11-24 22:53:23,303 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 2258 bytes result sent to driver
2015-11-24 22:53:23,304 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 0.0 (TID 5, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 22:53:23,304 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 0.0 (TID 5)
2015-11-24 22:53:23,306 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 1080 ms on localhost (5/6)
2015-11-24 22:53:23,309 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:33554432+20845196
2015-11-24 22:53:23,570 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 0.0 (TID 5). 2258 bytes result sent to driver
2015-11-24 22:53:23,573 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 0.0 (TID 5) in 270 ms on localhost (6/6)
2015-11-24 22:53:23,574 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (distinct at InsightOfDataSet.scala:30) finished in 3.934 s
2015-11-24 22:53:23,574 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:53:23,575 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:53:23,575 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 1, ShuffleMapStage 2, ResultStage 3)
2015-11-24 22:53:23,576 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:53:23,578 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 1: List()
2015-11-24 22:53:23,578 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 2: List(ShuffleMapStage 1)
2015-11-24 22:53:23,578 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 3: List(ShuffleMapStage 2)
2015-11-24 22:53:23,574 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-24 22:53:23,582 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at InsightOfDataSet.scala:31), which is now runnable
2015-11-24 22:53:23,586 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2704) called with curMem=123101, maxMem=505361203
2015-11-24 22:53:23,586 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 481.8 MB)
2015-11-24 22:53:23,587 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1570) called with curMem=125805, maxMem=505361203
2015-11-24 22:53:23,588 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1570.0 B, free 481.8 MB)
2015-11-24 22:53:23,589 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:54163 (size: 1570.0 B, free: 481.9 MB)
2015-11-24 22:53:23,590 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-24 22:53:23,590 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at InsightOfDataSet.scala:31)
2015-11-24 22:53:23,590 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 6 tasks
2015-11-24 22:53:23,592 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 6, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:53:23,592 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 6)
2015-11-24 22:53:23,606 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:23,608 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 4 ms
2015-11-24 22:53:23,667 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 6). 1379 bytes result sent to driver
2015-11-24 22:53:23,668 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 7, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:53:23,668 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 7)
2015-11-24 22:53:23,669 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 6) in 78 ms on localhost (1/6)
2015-11-24 22:53:23,673 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:23,673 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:23,690 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 7). 1379 bytes result sent to driver
2015-11-24 22:53:23,691 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 1.0 (TID 8, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:53:23,692 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 1.0 (TID 8)
2015-11-24 22:53:23,692 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 7) in 25 ms on localhost (2/6)
2015-11-24 22:53:23,696 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:23,696 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:23,715 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 1.0 (TID 8). 1379 bytes result sent to driver
2015-11-24 22:53:23,716 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 1.0 (TID 9, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:53:23,716 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 1.0 (TID 9)
2015-11-24 22:53:23,717 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 1.0 (TID 8) in 26 ms on localhost (3/6)
2015-11-24 22:53:23,721 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:23,721 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:23,739 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 1.0 (TID 9). 1379 bytes result sent to driver
2015-11-24 22:53:23,741 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 1.0 (TID 10, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:53:23,741 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 1.0 (TID 10)
2015-11-24 22:53:23,743 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 1.0 (TID 9) in 28 ms on localhost (4/6)
2015-11-24 22:53:23,747 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:23,747 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:53:23,772 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 1.0 (TID 10). 1379 bytes result sent to driver
2015-11-24 22:53:23,773 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 1.0 (TID 11, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:53:23,774 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 1.0 (TID 11)
2015-11-24 22:53:23,774 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 1.0 (TID 10) in 34 ms on localhost (5/6)
2015-11-24 22:53:23,778 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:23,778 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:23,799 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 1.0 (TID 11). 1379 bytes result sent to driver
2015-11-24 22:53:23,800 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 1.0 (TID 11) in 28 ms on localhost (6/6)
2015-11-24 22:53:23,801 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at InsightOfDataSet.scala:31) finished in 0.209 s
2015-11-24 22:53:23,801 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-24 22:53:23,801 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:53:23,801 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:53:23,801 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 2, ResultStage 3)
2015-11-24 22:53:23,801 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:53:23,801 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 2: List()
2015-11-24 22:53:23,802 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 3: List(ShuffleMapStage 2)
2015-11-24 22:53:23,802 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 2 (MapPartitionsRDD[9] at coalesce at InsightOfDataSet.scala:33), which is now runnable
2015-11-24 22:53:23,805 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2688) called with curMem=127375, maxMem=505361203
2015-11-24 22:53:23,805 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 481.8 MB)
2015-11-24 22:53:23,807 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1587) called with curMem=130063, maxMem=505361203
2015-11-24 22:53:23,807 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1587.0 B, free 481.8 MB)
2015-11-24 22:53:23,808 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:54163 (size: 1587.0 B, free: 481.9 MB)
2015-11-24 22:53:23,809 INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-11-24 22:53:23,810 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[9] at coalesce at InsightOfDataSet.scala:33)
2015-11-24 22:53:23,810 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 6 tasks
2015-11-24 22:53:23,811 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 12, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:53:23,812 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 12)
2015-11-24 22:53:23,816 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:23,816 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:23,830 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 12). 1374 bytes result sent to driver
2015-11-24 22:53:23,832 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 13, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:53:23,832 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 13)
2015-11-24 22:53:23,833 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 12) in 21 ms on localhost (1/6)
2015-11-24 22:53:23,837 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 6 blocks
2015-11-24 22:53:23,837 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:23,839 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 13). 1374 bytes result sent to driver
2015-11-24 22:53:23,841 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 2.0 (TID 14, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:53:23,841 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 2.0 (TID 14)
2015-11-24 22:53:23,841 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 13) in 10 ms on localhost (2/6)
2015-11-24 22:53:23,845 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:23,845 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:23,853 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 2.0 (TID 14). 1374 bytes result sent to driver
2015-11-24 22:53:23,854 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 2.0 (TID 15, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:53:23,855 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 2.0 (TID 15)
2015-11-24 22:53:23,855 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 2.0 (TID 14) in 15 ms on localhost (3/6)
2015-11-24 22:53:23,861 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 6 blocks
2015-11-24 22:53:23,861 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:23,870 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 2.0 (TID 15). 1374 bytes result sent to driver
2015-11-24 22:53:23,871 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 2.0 (TID 16, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:53:23,871 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 2.0 (TID 16)
2015-11-24 22:53:23,873 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 2.0 (TID 15) in 19 ms on localhost (4/6)
2015-11-24 22:53:23,877 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:23,877 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:53:23,886 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 2.0 (TID 16). 1374 bytes result sent to driver
2015-11-24 22:53:23,887 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 2.0 (TID 17, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 22:53:23,887 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 2.0 (TID 17)
2015-11-24 22:53:23,888 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 2.0 (TID 16) in 17 ms on localhost (5/6)
2015-11-24 22:53:23,892 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:23,892 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:23,900 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 2.0 (TID 17). 1374 bytes result sent to driver
2015-11-24 22:53:23,901 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 2.0 (TID 17) in 15 ms on localhost (6/6)
2015-11-24 22:53:23,901 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 2 (coalesce at InsightOfDataSet.scala:33) finished in 0.090 s
2015-11-24 22:53:23,902 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-24 22:53:23,902 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 22:53:23,902 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 22:53:23,902 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 3)
2015-11-24 22:53:23,902 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 22:53:23,902 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 3: List()
2015-11-24 22:53:23,902 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at saveAsTextFile at InsightOfDataSet.scala:33), which is now runnable
2015-11-24 22:53:23,948 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95792) called with curMem=131650, maxMem=505361203
2015-11-24 22:53:23,949 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 93.5 KB, free 481.7 MB)
2015-11-24 22:53:23,950 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31357) called with curMem=227442, maxMem=505361203
2015-11-24 22:53:23,951 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 30.6 KB, free 481.7 MB)
2015-11-24 22:53:23,952 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:54163 (size: 30.6 KB, free: 481.9 MB)
2015-11-24 22:53:23,952 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-24 22:53:23,953 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at saveAsTextFile at InsightOfDataSet.scala:33)
2015-11-24 22:53:23,954 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks
2015-11-24 22:53:23,962 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 18, localhost, PROCESS_LOCAL, 2170 bytes)
2015-11-24 22:53:23,962 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 18)
2015-11-24 22:53:23,978 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-24 22:53:23,979 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-24 22:53:23,980 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-24 22:53:23,984 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-24 22:53:24,055 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 5 non-empty blocks out of 6 blocks
2015-11-24 22:53:24,055 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:24,063 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242253_0003_m_000000_18' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelRegionCode/_temporary/0/task_201511242253_0003_m_000000
2015-11-24 22:53:24,064 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242253_0003_m_000000_18: Committed
2015-11-24 22:53:24,065 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 18). 1165 bytes result sent to driver
2015-11-24 22:53:24,067 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 18) in 112 ms on localhost (1/1)
2015-11-24 22:53:24,067 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 3 (saveAsTextFile at InsightOfDataSet.scala:33) finished in 0.113 s
2015-11-24 22:53:24,067 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-11-24 22:53:24,073 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsTextFile at InsightOfDataSet.scala:33, took 4.558034 s
2015-11-24 22:53:24,104 INFO  org.apache.spark.SparkContext - Starting job: count at InsightOfDataSet.scala:34
2015-11-24 22:53:24,109 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 2 is 167 bytes
2015-11-24 22:53:24,113 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 1 is 171 bytes
2015-11-24 22:53:24,115 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (count at InsightOfDataSet.scala:34) with 6 output partitions
2015-11-24 22:53:24,115 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 6(count at InsightOfDataSet.scala:34)
2015-11-24 22:53:24,115 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 5)
2015-11-24 22:53:24,115 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2015-11-24 22:53:24,116 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (ShuffledRDD[8] at reduceByKey at InsightOfDataSet.scala:31), which has no missing parents
2015-11-24 22:53:24,118 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2112) called with curMem=258799, maxMem=505361203
2015-11-24 22:53:24,118 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 2.1 KB, free 481.7 MB)
2015-11-24 22:53:24,120 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1331) called with curMem=260911, maxMem=505361203
2015-11-24 22:53:24,121 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 1331.0 B, free 481.7 MB)
2015-11-24 22:53:24,122 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:54163 (size: 1331.0 B, free: 481.9 MB)
2015-11-24 22:53:24,122 INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-11-24 22:53:24,123 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 6 (ShuffledRDD[8] at reduceByKey at InsightOfDataSet.scala:31)
2015-11-24 22:53:24,123 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 6 tasks
2015-11-24 22:53:24,124 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 19, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:53:24,124 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 19)
2015-11-24 22:53:24,127 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:24,128 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 22:53:24,132 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 19). 1203 bytes result sent to driver
2015-11-24 22:53:24,133 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 6.0 (TID 20, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:53:24,134 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 6.0 (TID 20)
2015-11-24 22:53:24,134 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 19) in 11 ms on localhost (1/6)
2015-11-24 22:53:24,137 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 6 blocks
2015-11-24 22:53:24,137 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:24,138 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 6.0 (TID 20). 1203 bytes result sent to driver
2015-11-24 22:53:24,139 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 6.0 (TID 21, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:53:24,139 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 6.0 (TID 21)
2015-11-24 22:53:24,140 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 6.0 (TID 20) in 8 ms on localhost (2/6)
2015-11-24 22:53:24,143 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:24,143 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:24,146 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 6.0 (TID 21). 1203 bytes result sent to driver
2015-11-24 22:53:24,147 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 6.0 (TID 22, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:53:24,147 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 6.0 (TID 22)
2015-11-24 22:53:24,148 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 6.0 (TID 21) in 10 ms on localhost (3/6)
2015-11-24 22:53:24,151 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 6 blocks
2015-11-24 22:53:24,151 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:24,152 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 6.0 (TID 22). 1203 bytes result sent to driver
2015-11-24 22:53:24,153 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 6.0 (TID 23, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:53:24,154 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 6.0 (TID 23)
2015-11-24 22:53:24,154 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 6.0 (TID 22) in 8 ms on localhost (4/6)
2015-11-24 22:53:24,157 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:24,157 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:24,162 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 6.0 (TID 23). 1203 bytes result sent to driver
2015-11-24 22:53:24,164 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 6.0 (TID 24, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 22:53:24,164 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 6.0 (TID 24)
2015-11-24 22:53:24,165 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 6.0 (TID 23) in 12 ms on localhost (5/6)
2015-11-24 22:53:24,169 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 22:53:24,169 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 22:53:24,173 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 6.0 (TID 24). 1203 bytes result sent to driver
2015-11-24 22:53:24,175 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 6.0 (TID 24) in 11 ms on localhost (6/6)
2015-11-24 22:53:24,175 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 6 (count at InsightOfDataSet.scala:34) finished in 0.052 s
2015-11-24 22:53:24,175 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-11-24 22:53:24,175 INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: count at InsightOfDataSet.scala:34, took 0.070743 s
2015-11-24 22:53:24,180 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-24 22:53:24,194 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-24 22:53:24,194 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-24 22:53:24,194 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-24 22:53:24,194 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-24 22:53:24,194 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-24 22:53:24,194 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-24 22:53:24,195 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-24 22:53:24,195 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-24 22:53:24,195 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-24 22:53:24,195 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-24 22:53:24,195 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-24 22:53:24,195 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-24 22:53:24,195 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-24 22:53:24,195 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-24 22:53:24,196 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-24 22:53:24,196 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-24 22:53:24,196 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-24 22:53:24,196 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-24 22:53:24,196 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-24 22:53:24,196 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-24 22:53:24,196 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-24 22:53:24,197 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-24 22:53:24,197 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-24 22:53:24,197 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-24 22:53:24,197 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-24 22:53:24,248 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-24 22:53:24,251 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-24 22:53:24,330 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-24 22:53:24,417 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-24 22:53:24,418 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-24 22:53:24,423 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-24 22:53:24,426 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-24 22:53:24,427 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-24 22:53:24,427 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-24 22:53:24,428 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-5c21eaab-0f78-4531-b004-98ec92edbc91
2015-11-24 23:06:13,068 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-24 23:06:14,858 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-24 23:06:14,870 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-24 23:06:14,871 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-24 23:06:16,486 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-24 23:06:16,613 INFO  Remoting - Starting remoting
2015-11-24 23:06:16,906 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:55330]
2015-11-24 23:06:16,914 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55330.
2015-11-24 23:06:17,045 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-24 23:06:17,127 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-24 23:06:17,192 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-0bbe884f-e03e-49b4-857c-5dd65d2e8998
2015-11-24 23:06:17,272 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-24 23:06:18,681 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-9acd7219-83bd-41fa-b256-9a74e7d28eef\httpd-552335bb-7dfe-4c60-a4c3-7f2d874f4ab8
2015-11-24 23:06:18,757 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-24 23:06:18,974 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 23:06:19,015 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:55331
2015-11-24 23:06:19,015 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 55331.
2015-11-24 23:06:19,051 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-24 23:06:19,425 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 23:06:19,456 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-24 23:06:19,457 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-24 23:06:19,459 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-24 23:06:19,880 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-24 23:06:19,888 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-24 23:06:20,374 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55350.
2015-11-24 23:06:20,374 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 55350
2015-11-24 23:06:20,402 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-24 23:06:20,420 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:55350 with 481.9 MB RAM, BlockManagerId(driver, localhost, 55350)
2015-11-24 23:06:20,425 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-24 23:06:22,905 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-24 23:06:22,927 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-24 23:06:23,210 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-24 23:06:23,210 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-24 23:06:23,214 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:55350 (size: 9.8 KB, free: 481.9 MB)
2015-11-24 23:06:23,362 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at InsightOfDataSet.scala:16
2015-11-24 23:06:25,159 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c701%29, but we couldn't find any external IP address!
2015-11-24 23:06:26,677 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 3
2015-11-24 23:06:26,998 INFO  org.apache.spark.SparkContext - Starting job: sortBy at InsightOfDataSet.scala:59
2015-11-24 23:06:27,050 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 4 (distinct at InsightOfDataSet.scala:56)
2015-11-24 23:06:27,051 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 7 (map at InsightOfDataSet.scala:57)
2015-11-24 23:06:27,054 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (sortBy at InsightOfDataSet.scala:59) with 6 output partitions
2015-11-24 23:06:27,055 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2(sortBy at InsightOfDataSet.scala:59)
2015-11-24 23:06:27,056 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2015-11-24 23:06:27,058 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2015-11-24 23:06:27,080 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at distinct at InsightOfDataSet.scala:56), which has no missing parents
2015-11-24 23:06:27,142 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(4208) called with curMem=116545, maxMem=505361203
2015-11-24 23:06:27,143 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 481.8 MB)
2015-11-24 23:06:27,145 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2348) called with curMem=120753, maxMem=505361203
2015-11-24 23:06:27,146 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 481.8 MB)
2015-11-24 23:06:27,148 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:55350 (size: 2.3 KB, free: 481.9 MB)
2015-11-24 23:06:27,149 INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-11-24 23:06:27,154 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at distinct at InsightOfDataSet.scala:56)
2015-11-24 23:06:27,157 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 6 tasks
2015-11-24 23:06:27,217 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:06:27,249 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-24 23:06:27,392 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:0+33554432
2015-11-24 23:06:27,440 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-24 23:06:27,440 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-24 23:06:27,440 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-24 23:06:27,440 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-24 23:06:27,440 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-24 23:06:29,618 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2258 bytes result sent to driver
2015-11-24 23:06:29,784 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:06:29,786 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2015-11-24 23:06:29,879 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:33554432+20843526
2015-11-24 23:06:29,930 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 2696 ms on localhost (1/6)
2015-11-24 23:06:35,005 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 2258 bytes result sent to driver
2015-11-24 23:06:35,007 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:06:35,007 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
2015-11-24 23:06:35,016 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 5234 ms on localhost (2/6)
2015-11-24 23:06:35,016 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:0+33554432
2015-11-24 23:06:37,693 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 2258 bytes result sent to driver
2015-11-24 23:06:37,701 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:06:37,702 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
2015-11-24 23:06:37,703 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 2697 ms on localhost (3/6)
2015-11-24 23:06:37,707 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:33554432+20844232
2015-11-24 23:06:38,338 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 2258 bytes result sent to driver
2015-11-24 23:06:38,339 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:06:38,339 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
2015-11-24 23:06:38,341 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 639 ms on localhost (4/6)
2015-11-24 23:06:38,345 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:0+33554432
2015-11-24 23:06:39,085 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 2258 bytes result sent to driver
2015-11-24 23:06:39,086 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 0.0 (TID 5, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:06:39,087 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 0.0 (TID 5)
2015-11-24 23:06:39,088 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 749 ms on localhost (5/6)
2015-11-24 23:06:39,093 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:33554432+20845196
2015-11-24 23:06:39,512 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 0.0 (TID 5). 2258 bytes result sent to driver
2015-11-24 23:06:39,528 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 0.0 (TID 5) in 442 ms on localhost (6/6)
2015-11-24 23:06:39,529 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (distinct at InsightOfDataSet.scala:56) finished in 12.358 s
2015-11-24 23:06:39,530 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-24 23:06:39,530 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 23:06:39,531 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 23:06:39,544 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 1, ResultStage 2)
2015-11-24 23:06:39,545 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 23:06:39,572 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 1: List()
2015-11-24 23:06:39,572 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List(ShuffleMapStage 1)
2015-11-24 23:06:39,610 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at InsightOfDataSet.scala:57), which is now runnable
2015-11-24 23:06:39,612 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2704) called with curMem=123101, maxMem=505361203
2015-11-24 23:06:39,613 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 481.8 MB)
2015-11-24 23:06:39,613 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1570) called with curMem=125805, maxMem=505361203
2015-11-24 23:06:39,614 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1570.0 B, free 481.8 MB)
2015-11-24 23:06:39,616 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:55350 (size: 1570.0 B, free: 481.9 MB)
2015-11-24 23:06:39,617 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-24 23:06:39,617 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at InsightOfDataSet.scala:57)
2015-11-24 23:06:39,617 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 6 tasks
2015-11-24 23:06:39,620 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 6, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:39,620 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 6)
2015-11-24 23:06:39,713 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:39,734 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 37 ms
2015-11-24 23:06:40,278 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 6). 1379 bytes result sent to driver
2015-11-24 23:06:40,279 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 7, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:40,279 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 7)
2015-11-24 23:06:40,279 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 6) in 661 ms on localhost (1/6)
2015-11-24 23:06:40,283 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:40,283 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:40,509 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 7). 1379 bytes result sent to driver
2015-11-24 23:06:40,510 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 1.0 (TID 8, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:40,511 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 1.0 (TID 8)
2015-11-24 23:06:40,511 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 7) in 233 ms on localhost (2/6)
2015-11-24 23:06:40,513 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:40,513 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:40,626 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 1.0 (TID 8). 1379 bytes result sent to driver
2015-11-24 23:06:40,627 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 1.0 (TID 9, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:40,627 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 1.0 (TID 9)
2015-11-24 23:06:40,628 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 1.0 (TID 8) in 117 ms on localhost (3/6)
2015-11-24 23:06:40,630 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:40,630 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:40,735 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 1.0 (TID 9). 1379 bytes result sent to driver
2015-11-24 23:06:40,736 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 1.0 (TID 10, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:40,737 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 1.0 (TID 9) in 109 ms on localhost (4/6)
2015-11-24 23:06:40,738 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 1.0 (TID 10)
2015-11-24 23:06:40,742 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:40,742 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:40,858 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 1.0 (TID 10). 1379 bytes result sent to driver
2015-11-24 23:06:40,859 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 1.0 (TID 11, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:40,859 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 1.0 (TID 11)
2015-11-24 23:06:40,860 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 1.0 (TID 10) in 124 ms on localhost (5/6)
2015-11-24 23:06:40,862 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:40,862 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:40,978 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 1.0 (TID 11). 1379 bytes result sent to driver
2015-11-24 23:06:40,979 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 1.0 (TID 11) in 120 ms on localhost (6/6)
2015-11-24 23:06:40,979 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at InsightOfDataSet.scala:57) finished in 1.361 s
2015-11-24 23:06:40,979 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 23:06:40,979 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-24 23:06:40,980 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 23:06:40,980 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-24 23:06:40,980 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 23:06:40,980 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List()
2015-11-24 23:06:40,981 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[11] at sortBy at InsightOfDataSet.scala:59), which is now runnable
2015-11-24 23:06:41,005 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3424) called with curMem=127375, maxMem=505361203
2015-11-24 23:06:41,005 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 3.3 KB, free 481.8 MB)
2015-11-24 23:06:41,007 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1961) called with curMem=130799, maxMem=505361203
2015-11-24 23:06:41,008 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1961.0 B, free 481.8 MB)
2015-11-24 23:06:41,008 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:55350 (size: 1961.0 B, free: 481.9 MB)
2015-11-24 23:06:41,009 INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-11-24 23:06:41,012 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at sortBy at InsightOfDataSet.scala:59)
2015-11-24 23:06:41,013 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 6 tasks
2015-11-24 23:06:41,016 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 12, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:06:41,017 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 12)
2015-11-24 23:06:41,023 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:41,023 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:06:41,122 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 12). 1589 bytes result sent to driver
2015-11-24 23:06:41,123 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 13, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:06:41,123 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 13)
2015-11-24 23:06:41,124 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 12) in 109 ms on localhost (1/6)
2015-11-24 23:06:41,126 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:41,126 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:41,191 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 13). 1589 bytes result sent to driver
2015-11-24 23:06:41,220 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 2.0 (TID 14, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:06:41,221 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 2.0 (TID 14)
2015-11-24 23:06:41,222 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 13) in 98 ms on localhost (2/6)
2015-11-24 23:06:41,231 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:41,231 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:41,288 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 2.0 (TID 14). 1589 bytes result sent to driver
2015-11-24 23:06:41,290 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 2.0 (TID 15, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:06:41,290 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 2.0 (TID 15)
2015-11-24 23:06:41,290 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 2.0 (TID 14) in 71 ms on localhost (3/6)
2015-11-24 23:06:41,295 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:41,296 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:06:41,339 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 2.0 (TID 15). 1589 bytes result sent to driver
2015-11-24 23:06:41,340 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 2.0 (TID 16, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:06:41,340 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 2.0 (TID 16)
2015-11-24 23:06:41,341 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 2.0 (TID 15) in 51 ms on localhost (4/6)
2015-11-24 23:06:41,344 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:41,344 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:41,374 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 2.0 (TID 16). 1589 bytes result sent to driver
2015-11-24 23:06:41,375 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 2.0 (TID 17, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:06:41,375 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 2.0 (TID 17)
2015-11-24 23:06:41,375 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 2.0 (TID 16) in 36 ms on localhost (5/6)
2015-11-24 23:06:41,378 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:41,379 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:06:41,410 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 2.0 (TID 17). 1589 bytes result sent to driver
2015-11-24 23:06:41,412 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 2.0 (TID 17) in 37 ms on localhost (6/6)
2015-11-24 23:06:41,412 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (sortBy at InsightOfDataSet.scala:59) finished in 0.397 s
2015-11-24 23:06:41,412 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-24 23:06:41,476 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: sortBy at InsightOfDataSet.scala:59, took 14.477062 s
2015-11-24 23:06:42,140 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at InsightOfDataSet.scala:59
2015-11-24 23:06:42,174 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 1 is 180 bytes
2015-11-24 23:06:42,235 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 162 bytes
2015-11-24 23:06:42,236 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 9 (sortBy at InsightOfDataSet.scala:59)
2015-11-24 23:06:42,236 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 14 (coalesce at InsightOfDataSet.scala:59)
2015-11-24 23:06:42,237 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (saveAsTextFile at InsightOfDataSet.scala:59) with 1 output partitions
2015-11-24 23:06:42,237 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 7(saveAsTextFile at InsightOfDataSet.scala:59)
2015-11-24 23:06:42,237 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 6)
2015-11-24 23:06:42,237 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 6)
2015-11-24 23:06:42,238 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 5 (MapPartitionsRDD[9] at sortBy at InsightOfDataSet.scala:59), which has no missing parents
2015-11-24 23:06:42,243 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3208) called with curMem=132760, maxMem=505361203
2015-11-24 23:06:42,243 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.1 KB, free 481.8 MB)
2015-11-24 23:06:42,245 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1883) called with curMem=135968, maxMem=505361203
2015-11-24 23:06:42,245 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1883.0 B, free 481.8 MB)
2015-11-24 23:06:42,246 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:55350 (size: 1883.0 B, free: 481.9 MB)
2015-11-24 23:06:42,247 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-24 23:06:42,248 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[9] at sortBy at InsightOfDataSet.scala:59)
2015-11-24 23:06:42,248 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 6 tasks
2015-11-24 23:06:42,249 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 18, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:42,250 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 18)
2015-11-24 23:06:42,265 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:42,265 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:42,526 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 18). 1378 bytes result sent to driver
2015-11-24 23:06:42,528 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 19, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:42,529 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 19)
2015-11-24 23:06:42,534 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:42,534 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:42,536 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 18) in 286 ms on localhost (1/6)
2015-11-24 23:06:42,725 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 19). 1378 bytes result sent to driver
2015-11-24 23:06:42,727 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 5.0 (TID 20, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:42,728 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 5.0 (TID 20)
2015-11-24 23:06:42,733 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:42,733 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:42,737 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 19) in 209 ms on localhost (2/6)
2015-11-24 23:06:42,869 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 5.0 (TID 20). 1378 bytes result sent to driver
2015-11-24 23:06:42,870 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 5.0 (TID 21, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:42,871 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 5.0 (TID 20) in 145 ms on localhost (3/6)
2015-11-24 23:06:42,871 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 5.0 (TID 21)
2015-11-24 23:06:42,875 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:42,875 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:06:42,996 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 5.0 (TID 21). 1378 bytes result sent to driver
2015-11-24 23:06:42,997 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 5.0 (TID 22, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:42,998 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 5.0 (TID 22)
2015-11-24 23:06:42,998 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 5.0 (TID 21) in 128 ms on localhost (4/6)
2015-11-24 23:06:43,002 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:43,002 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:43,029 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on localhost:55350 in memory (size: 1961.0 B, free: 481.9 MB)
2015-11-24 23:06:43,058 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on localhost:55350 in memory (size: 1570.0 B, free: 481.9 MB)
2015-11-24 23:06:43,087 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 5.0 (TID 22). 1378 bytes result sent to driver
2015-11-24 23:06:43,089 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 5.0 (TID 23, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:43,089 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 5.0 (TID 23)
2015-11-24 23:06:43,089 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 5.0 (TID 22) in 92 ms on localhost (5/6)
2015-11-24 23:06:43,094 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:43,094 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:43,183 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 5.0 (TID 23). 1378 bytes result sent to driver
2015-11-24 23:06:43,184 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 5.0 (TID 23) in 95 ms on localhost (6/6)
2015-11-24 23:06:43,184 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 5 (sortBy at InsightOfDataSet.scala:59) finished in 0.935 s
2015-11-24 23:06:43,184 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-11-24 23:06:43,184 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 23:06:43,185 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 23:06:43,185 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 6, ResultStage 7)
2015-11-24 23:06:43,185 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 23:06:43,186 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 6: List()
2015-11-24 23:06:43,187 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 7: List(ShuffleMapStage 6)
2015-11-24 23:06:43,188 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 6 (MapPartitionsRDD[14] at coalesce at InsightOfDataSet.scala:59), which is now runnable
2015-11-24 23:06:43,190 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3280) called with curMem=128192, maxMem=505361203
2015-11-24 23:06:43,190 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 3.2 KB, free 481.8 MB)
2015-11-24 23:06:43,192 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1881) called with curMem=131472, maxMem=505361203
2015-11-24 23:06:43,193 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 1881.0 B, free 481.8 MB)
2015-11-24 23:06:43,194 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:55350 (size: 1881.0 B, free: 481.9 MB)
2015-11-24 23:06:43,195 INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-11-24 23:06:43,195 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 5 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[14] at coalesce at InsightOfDataSet.scala:59)
2015-11-24 23:06:43,195 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 5 tasks
2015-11-24 23:06:43,197 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 24, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:43,197 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 24)
2015-11-24 23:06:43,201 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:43,201 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:06:44,841 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 24). 1374 bytes result sent to driver
2015-11-24 23:06:44,842 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 6.0 (TID 25, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:44,842 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 6.0 (TID 25)
2015-11-24 23:06:44,842 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 24) in 1646 ms on localhost (1/5)
2015-11-24 23:06:44,844 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:44,844 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:44,916 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 6.0 (TID 25). 1374 bytes result sent to driver
2015-11-24 23:06:44,917 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 6.0 (TID 26, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:44,917 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 6.0 (TID 26)
2015-11-24 23:06:44,917 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 6.0 (TID 25) in 76 ms on localhost (2/5)
2015-11-24 23:06:44,919 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:44,919 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:06:44,939 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 6.0 (TID 26). 1374 bytes result sent to driver
2015-11-24 23:06:44,940 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 6.0 (TID 27, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:44,940 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 6.0 (TID 27)
2015-11-24 23:06:44,941 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 6.0 (TID 26) in 25 ms on localhost (3/5)
2015-11-24 23:06:44,942 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:44,942 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:44,954 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 6.0 (TID 27). 1374 bytes result sent to driver
2015-11-24 23:06:44,955 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 6.0 (TID 28, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:06:44,955 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 6.0 (TID 28)
2015-11-24 23:06:44,958 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:44,959 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:06:44,958 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 6.0 (TID 27) in 19 ms on localhost (4/5)
2015-11-24 23:06:44,971 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 6.0 (TID 28). 1374 bytes result sent to driver
2015-11-24 23:06:44,972 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 6.0 (TID 28) in 16 ms on localhost (5/5)
2015-11-24 23:06:44,972 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 6 (coalesce at InsightOfDataSet.scala:59) finished in 1.776 s
2015-11-24 23:06:44,972 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-11-24 23:06:44,972 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 23:06:44,972 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 23:06:44,972 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 7)
2015-11-24 23:06:44,972 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 23:06:44,972 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 7: List()
2015-11-24 23:06:44,973 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[18] at saveAsTextFile at InsightOfDataSet.scala:59), which is now runnable
2015-11-24 23:06:45,022 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95776) called with curMem=133353, maxMem=505361203
2015-11-24 23:06:45,023 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 93.5 KB, free 481.7 MB)
2015-11-24 23:06:45,025 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31393) called with curMem=229129, maxMem=505361203
2015-11-24 23:06:45,025 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 30.7 KB, free 481.7 MB)
2015-11-24 23:06:45,026 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on localhost:55350 (size: 30.7 KB, free: 481.9 MB)
2015-11-24 23:06:45,027 INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:861
2015-11-24 23:06:45,027 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[18] at saveAsTextFile at InsightOfDataSet.scala:59)
2015-11-24 23:06:45,027 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks
2015-11-24 23:06:45,072 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 29, localhost, PROCESS_LOCAL, 2170 bytes)
2015-11-24 23:06:45,072 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 29)
2015-11-24 23:06:45,120 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-24 23:06:45,120 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-24 23:06:45,122 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-24 23:06:45,127 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-24 23:06:45,378 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 5 non-empty blocks out of 5 blocks
2015-11-24 23:06:45,378 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:45,725 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242306_0007_m_000000_29' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserToHotels/_temporary/0/task_201511242306_0007_m_000000
2015-11-24 23:06:45,726 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242306_0007_m_000000_29: Committed
2015-11-24 23:06:45,727 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 29). 1165 bytes result sent to driver
2015-11-24 23:06:45,728 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 29) in 700 ms on localhost (1/1)
2015-11-24 23:06:45,728 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 7 (saveAsTextFile at InsightOfDataSet.scala:59) finished in 0.701 s
2015-11-24 23:06:45,728 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2015-11-24 23:06:45,729 INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: saveAsTextFile at InsightOfDataSet.scala:59, took 3.588923 s
2015-11-24 23:06:45,809 INFO  org.apache.spark.SparkContext - Starting job: count at InsightOfDataSet.scala:60
2015-11-24 23:06:45,810 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 1 is 180 bytes
2015-11-24 23:06:45,811 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 162 bytes
2015-11-24 23:06:45,812 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 2 (count at InsightOfDataSet.scala:60) with 6 output partitions
2015-11-24 23:06:45,812 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 10(count at InsightOfDataSet.scala:60)
2015-11-24 23:06:45,812 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 9)
2015-11-24 23:06:45,812 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2015-11-24 23:06:45,813 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 10 (ShuffledRDD[8] at reduceByKey at InsightOfDataSet.scala:57), which has no missing parents
2015-11-24 23:06:45,814 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2112) called with curMem=260522, maxMem=505361203
2015-11-24 23:06:45,815 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 2.1 KB, free 481.7 MB)
2015-11-24 23:06:45,816 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1334) called with curMem=262634, maxMem=505361203
2015-11-24 23:06:45,816 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 1334.0 B, free 481.7 MB)
2015-11-24 23:06:45,817 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on localhost:55350 (size: 1334.0 B, free: 481.9 MB)
2015-11-24 23:06:45,818 INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:861
2015-11-24 23:06:45,818 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 10 (ShuffledRDD[8] at reduceByKey at InsightOfDataSet.scala:57)
2015-11-24 23:06:45,818 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 10.0 with 6 tasks
2015-11-24 23:06:45,819 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 10.0 (TID 30, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:06:45,820 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 10.0 (TID 30)
2015-11-24 23:06:45,821 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:45,821 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:45,847 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 10.0 (TID 30). 1203 bytes result sent to driver
2015-11-24 23:06:45,848 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 10.0 (TID 31, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:06:45,848 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 10.0 (TID 31)
2015-11-24 23:06:45,849 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 10.0 (TID 30) in 30 ms on localhost (1/6)
2015-11-24 23:06:45,850 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:45,850 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:45,882 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 10.0 (TID 31). 1203 bytes result sent to driver
2015-11-24 23:06:45,883 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 10.0 (TID 32, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:06:45,883 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 10.0 (TID 32)
2015-11-24 23:06:45,883 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 10.0 (TID 31) in 35 ms on localhost (2/6)
2015-11-24 23:06:45,885 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:45,885 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:45,913 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 10.0 (TID 32). 1203 bytes result sent to driver
2015-11-24 23:06:45,914 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 10.0 (TID 33, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:06:45,914 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 10.0 (TID 33)
2015-11-24 23:06:45,915 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 10.0 (TID 32) in 32 ms on localhost (3/6)
2015-11-24 23:06:45,917 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:45,917 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:06:45,969 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 10.0 (TID 33). 1203 bytes result sent to driver
2015-11-24 23:06:45,970 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 10.0 (TID 34, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:06:45,971 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 10.0 (TID 33) in 58 ms on localhost (4/6)
2015-11-24 23:06:45,972 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 10.0 (TID 34)
2015-11-24 23:06:45,975 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:45,975 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:06:46,001 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 10.0 (TID 34). 1203 bytes result sent to driver
2015-11-24 23:06:46,002 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 10.0 (TID 35, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:06:46,002 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 10.0 (TID 35)
2015-11-24 23:06:46,003 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 10.0 (TID 34) in 33 ms on localhost (5/6)
2015-11-24 23:06:46,005 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:06:46,005 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:06:46,027 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 10.0 (TID 35). 1203 bytes result sent to driver
2015-11-24 23:06:46,028 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 10.0 (TID 35) in 26 ms on localhost (6/6)
2015-11-24 23:06:46,028 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 10 (count at InsightOfDataSet.scala:60) finished in 0.209 s
2015-11-24 23:06:46,028 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2015-11-24 23:06:46,029 INFO  org.apache.spark.scheduler.DAGScheduler - Job 2 finished: count at InsightOfDataSet.scala:60, took 0.219379 s
2015-11-24 23:06:46,134 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-24 23:06:46,208 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-24 23:06:46,209 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-24 23:06:46,209 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-24 23:06:46,210 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-24 23:06:46,210 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-24 23:06:46,210 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-24 23:06:46,210 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-24 23:06:46,210 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-24 23:06:46,210 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-24 23:06:46,211 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-24 23:06:46,211 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-24 23:06:46,211 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-24 23:06:46,211 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-24 23:06:46,211 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-24 23:06:46,211 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-24 23:06:46,212 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-24 23:06:46,212 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-24 23:06:46,212 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-24 23:06:46,212 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-24 23:06:46,213 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-24 23:06:46,213 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-24 23:06:46,213 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-24 23:06:46,214 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-24 23:06:46,214 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-24 23:06:46,214 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-24 23:06:46,292 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-24 23:06:46,335 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-24 23:06:46,534 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-24 23:06:46,727 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-24 23:06:46,730 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-24 23:06:46,731 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-24 23:06:46,801 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-24 23:06:46,802 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-24 23:06:46,803 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-24 23:06:46,806 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-9acd7219-83bd-41fa-b256-9a74e7d28eef
2015-11-24 23:08:47,053 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-24 23:08:52,576 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-24 23:08:52,620 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-24 23:08:52,621 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-24 23:09:00,931 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-24 23:09:01,065 INFO  Remoting - Starting remoting
2015-11-24 23:09:01,372 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:55418]
2015-11-24 23:09:01,383 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55418.
2015-11-24 23:09:01,517 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-24 23:09:01,564 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-24 23:09:01,674 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-215b19df-3499-48ef-b04c-9a62aa67fa0d
2015-11-24 23:09:01,810 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-24 23:09:02,004 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-c2282331-951d-4976-8b9a-e2d7dcbbba04\httpd-8026fbe7-6eff-466c-81e7-71d175b1335d
2015-11-24 23:09:02,042 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-24 23:09:02,203 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 23:09:02,226 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:55419
2015-11-24 23:09:02,227 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 55419.
2015-11-24 23:09:02,264 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-24 23:09:02,643 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 23:09:02,664 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-24 23:09:02,664 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-24 23:09:02,668 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-24 23:09:03,012 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-24 23:09:03,018 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-24 23:09:03,633 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55441.
2015-11-24 23:09:03,634 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 55441
2015-11-24 23:09:03,645 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-24 23:09:03,666 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:55441 with 481.9 MB RAM, BlockManagerId(driver, localhost, 55441)
2015-11-24 23:09:03,679 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-24 23:09:06,110 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-24 23:09:06,177 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-24 23:09:06,587 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-24 23:09:06,588 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-24 23:09:06,591 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:55441 (size: 9.8 KB, free: 481.9 MB)
2015-11-24 23:09:06,658 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at InsightOfDataSet.scala:16
2015-11-24 23:09:08,207 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c701%29, but we couldn't find any external IP address!
2015-11-24 23:09:09,811 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 3
2015-11-24 23:09:10,112 INFO  org.apache.spark.SparkContext - Starting job: sortBy at InsightOfDataSet.scala:59
2015-11-24 23:09:10,182 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 4 (distinct at InsightOfDataSet.scala:56)
2015-11-24 23:09:10,183 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 7 (map at InsightOfDataSet.scala:57)
2015-11-24 23:09:10,188 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (sortBy at InsightOfDataSet.scala:59) with 6 output partitions
2015-11-24 23:09:10,189 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2(sortBy at InsightOfDataSet.scala:59)
2015-11-24 23:09:10,190 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2015-11-24 23:09:10,193 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2015-11-24 23:09:10,224 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at distinct at InsightOfDataSet.scala:56), which has no missing parents
2015-11-24 23:09:10,291 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(4208) called with curMem=116545, maxMem=505361203
2015-11-24 23:09:10,292 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 481.8 MB)
2015-11-24 23:09:10,294 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2348) called with curMem=120753, maxMem=505361203
2015-11-24 23:09:10,295 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 481.8 MB)
2015-11-24 23:09:10,296 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:55441 (size: 2.3 KB, free: 481.9 MB)
2015-11-24 23:09:10,297 INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-11-24 23:09:10,303 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at distinct at InsightOfDataSet.scala:56)
2015-11-24 23:09:10,304 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 6 tasks
2015-11-24 23:09:10,413 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:09:10,469 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-24 23:09:10,549 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:0+33554432
2015-11-24 23:09:10,589 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-24 23:09:10,589 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-24 23:09:10,589 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-24 23:09:10,589 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-24 23:09:10,590 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-24 23:09:13,528 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2258 bytes result sent to driver
2015-11-24 23:09:13,620 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:09:13,621 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2015-11-24 23:09:13,668 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:33554432+20843526
2015-11-24 23:09:13,744 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 3314 ms on localhost (1/6)
2015-11-24 23:09:16,387 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 2258 bytes result sent to driver
2015-11-24 23:09:16,392 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:09:16,396 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
2015-11-24 23:09:16,403 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 2783 ms on localhost (2/6)
2015-11-24 23:09:16,406 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:0+33554432
2015-11-24 23:09:17,320 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 2258 bytes result sent to driver
2015-11-24 23:09:17,321 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:09:17,321 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
2015-11-24 23:09:17,328 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:33554432+20844232
2015-11-24 23:09:17,332 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 942 ms on localhost (3/6)
2015-11-24 23:09:19,496 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 2258 bytes result sent to driver
2015-11-24 23:09:19,497 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:09:19,497 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
2015-11-24 23:09:19,499 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 2178 ms on localhost (4/6)
2015-11-24 23:09:19,503 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:0+33554432
2015-11-24 23:09:20,411 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 2258 bytes result sent to driver
2015-11-24 23:09:20,412 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 0.0 (TID 5, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:09:20,413 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 0.0 (TID 5)
2015-11-24 23:09:20,414 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 918 ms on localhost (5/6)
2015-11-24 23:09:20,418 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:33554432+20845196
2015-11-24 23:09:20,945 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 0.0 (TID 5). 2258 bytes result sent to driver
2015-11-24 23:09:20,980 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 0.0 (TID 5) in 569 ms on localhost (6/6)
2015-11-24 23:09:20,982 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-24 23:09:20,984 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (distinct at InsightOfDataSet.scala:56) finished in 10.650 s
2015-11-24 23:09:20,998 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 23:09:21,000 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 23:09:21,001 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 1, ResultStage 2)
2015-11-24 23:09:21,005 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 23:09:21,054 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 1: List()
2015-11-24 23:09:21,054 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List(ShuffleMapStage 1)
2015-11-24 23:09:21,073 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at InsightOfDataSet.scala:57), which is now runnable
2015-11-24 23:09:21,075 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2704) called with curMem=123101, maxMem=505361203
2015-11-24 23:09:21,075 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 481.8 MB)
2015-11-24 23:09:21,078 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1570) called with curMem=125805, maxMem=505361203
2015-11-24 23:09:21,078 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1570.0 B, free 481.8 MB)
2015-11-24 23:09:21,080 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:55441 (size: 1570.0 B, free: 481.9 MB)
2015-11-24 23:09:21,081 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-24 23:09:21,082 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at InsightOfDataSet.scala:57)
2015-11-24 23:09:21,082 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 6 tasks
2015-11-24 23:09:21,085 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 6, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:21,085 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 6)
2015-11-24 23:09:21,143 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:21,145 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 6 ms
2015-11-24 23:09:21,654 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 6). 1379 bytes result sent to driver
2015-11-24 23:09:21,655 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 7, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:21,655 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 7)
2015-11-24 23:09:21,655 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 6) in 571 ms on localhost (1/6)
2015-11-24 23:09:21,659 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:21,659 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:21,944 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 7). 1379 bytes result sent to driver
2015-11-24 23:09:21,946 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 1.0 (TID 8, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:21,947 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 1.0 (TID 8)
2015-11-24 23:09:21,947 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 7) in 293 ms on localhost (2/6)
2015-11-24 23:09:21,951 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:21,951 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:22,082 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 1.0 (TID 8). 1379 bytes result sent to driver
2015-11-24 23:09:22,083 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 1.0 (TID 9, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:22,083 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 1.0 (TID 9)
2015-11-24 23:09:22,083 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 1.0 (TID 8) in 137 ms on localhost (3/6)
2015-11-24 23:09:22,086 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:22,086 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:22,199 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 1.0 (TID 9). 1379 bytes result sent to driver
2015-11-24 23:09:22,201 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 1.0 (TID 10, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:22,201 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 1.0 (TID 10)
2015-11-24 23:09:22,202 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 1.0 (TID 9) in 120 ms on localhost (4/6)
2015-11-24 23:09:22,204 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:22,204 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:22,339 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 1.0 (TID 10). 1379 bytes result sent to driver
2015-11-24 23:09:22,340 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 1.0 (TID 11, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:22,341 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 1.0 (TID 11)
2015-11-24 23:09:22,341 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 1.0 (TID 10) in 141 ms on localhost (5/6)
2015-11-24 23:09:22,343 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:22,343 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:22,491 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 1.0 (TID 11). 1379 bytes result sent to driver
2015-11-24 23:09:22,495 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 1.0 (TID 11) in 154 ms on localhost (6/6)
2015-11-24 23:09:22,496 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-24 23:09:22,496 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at InsightOfDataSet.scala:57) finished in 1.413 s
2015-11-24 23:09:22,497 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 23:09:22,497 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 23:09:22,497 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2015-11-24 23:09:22,497 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 23:09:22,499 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 2: List()
2015-11-24 23:09:22,499 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[11] at sortBy at InsightOfDataSet.scala:59), which is now runnable
2015-11-24 23:09:22,504 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3424) called with curMem=127375, maxMem=505361203
2015-11-24 23:09:22,505 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 3.3 KB, free 481.8 MB)
2015-11-24 23:09:22,508 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1953) called with curMem=130799, maxMem=505361203
2015-11-24 23:09:22,508 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1953.0 B, free 481.8 MB)
2015-11-24 23:09:22,510 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:55441 (size: 1953.0 B, free: 481.9 MB)
2015-11-24 23:09:22,511 INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-11-24 23:09:22,513 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at sortBy at InsightOfDataSet.scala:59)
2015-11-24 23:09:22,514 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 6 tasks
2015-11-24 23:09:22,518 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 12, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:09:22,520 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 12)
2015-11-24 23:09:22,527 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:22,528 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:22,649 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 12). 1589 bytes result sent to driver
2015-11-24 23:09:22,650 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 13, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:09:22,650 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 13)
2015-11-24 23:09:22,651 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 12) in 136 ms on localhost (1/6)
2015-11-24 23:09:22,654 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:22,654 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:22,705 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 13). 1589 bytes result sent to driver
2015-11-24 23:09:22,712 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 2.0 (TID 14, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:09:22,712 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 2.0 (TID 14)
2015-11-24 23:09:22,713 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 13) in 63 ms on localhost (2/6)
2015-11-24 23:09:22,716 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:22,716 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:22,769 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 2.0 (TID 14). 1589 bytes result sent to driver
2015-11-24 23:09:22,770 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 2.0 (TID 15, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:09:22,773 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 2.0 (TID 14) in 63 ms on localhost (3/6)
2015-11-24 23:09:22,774 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 2.0 (TID 15)
2015-11-24 23:09:22,784 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:22,785 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:22,838 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 2.0 (TID 15). 1589 bytes result sent to driver
2015-11-24 23:09:22,839 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 2.0 (TID 16, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:09:22,840 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 2.0 (TID 16)
2015-11-24 23:09:22,840 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 2.0 (TID 15) in 71 ms on localhost (4/6)
2015-11-24 23:09:22,843 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:22,843 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:22,880 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 2.0 (TID 16). 1589 bytes result sent to driver
2015-11-24 23:09:22,881 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 2.0 (TID 17, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:09:22,882 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 2.0 (TID 16) in 43 ms on localhost (5/6)
2015-11-24 23:09:22,883 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 2.0 (TID 17)
2015-11-24 23:09:22,888 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:22,888 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:22,946 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 2.0 (TID 17). 1589 bytes result sent to driver
2015-11-24 23:09:22,949 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 2.0 (TID 17) in 69 ms on localhost (6/6)
2015-11-24 23:09:22,950 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-24 23:09:22,950 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (sortBy at InsightOfDataSet.scala:59) finished in 0.435 s
2015-11-24 23:09:22,953 INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on localhost:55441 in memory (size: 1570.0 B, free: 481.9 MB)
2015-11-24 23:09:22,981 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: sortBy at InsightOfDataSet.scala:59, took 12.868587 s
2015-11-24 23:09:23,414 INFO  org.apache.spark.SparkContext - Starting job: saveAsTextFile at InsightOfDataSet.scala:59
2015-11-24 23:09:23,427 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 1 is 180 bytes
2015-11-24 23:09:23,452 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 162 bytes
2015-11-24 23:09:23,454 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 9 (sortBy at InsightOfDataSet.scala:59)
2015-11-24 23:09:23,455 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 14 (coalesce at InsightOfDataSet.scala:59)
2015-11-24 23:09:23,456 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (saveAsTextFile at InsightOfDataSet.scala:59) with 1 output partitions
2015-11-24 23:09:23,456 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 7(saveAsTextFile at InsightOfDataSet.scala:59)
2015-11-24 23:09:23,456 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 6)
2015-11-24 23:09:23,457 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 6)
2015-11-24 23:09:23,459 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 5 (MapPartitionsRDD[9] at sortBy at InsightOfDataSet.scala:59), which has no missing parents
2015-11-24 23:09:23,475 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3264) called with curMem=128478, maxMem=505361203
2015-11-24 23:09:23,476 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.2 KB, free 481.8 MB)
2015-11-24 23:09:23,478 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1909) called with curMem=131742, maxMem=505361203
2015-11-24 23:09:23,479 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1909.0 B, free 481.8 MB)
2015-11-24 23:09:23,481 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:55441 (size: 1909.0 B, free: 481.9 MB)
2015-11-24 23:09:23,483 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-24 23:09:23,484 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[9] at sortBy at InsightOfDataSet.scala:59)
2015-11-24 23:09:23,485 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 6 tasks
2015-11-24 23:09:23,493 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 18, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:23,494 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 18)
2015-11-24 23:09:23,503 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:23,504 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:23,873 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 18). 1378 bytes result sent to driver
2015-11-24 23:09:23,875 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 19, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:23,875 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 19)
2015-11-24 23:09:23,876 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 18) in 385 ms on localhost (1/6)
2015-11-24 23:09:23,880 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:23,881 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:24,080 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 19). 1378 bytes result sent to driver
2015-11-24 23:09:24,088 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 5.0 (TID 20, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:24,089 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 5.0 (TID 20)
2015-11-24 23:09:24,089 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 19) in 215 ms on localhost (2/6)
2015-11-24 23:09:24,094 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:24,095 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:24,275 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 5.0 (TID 20). 1378 bytes result sent to driver
2015-11-24 23:09:24,283 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 5.0 (TID 21, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:24,284 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 5.0 (TID 21)
2015-11-24 23:09:24,295 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:24,296 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:24,317 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 5.0 (TID 20) in 223 ms on localhost (3/6)
2015-11-24 23:09:24,486 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 5.0 (TID 21). 1378 bytes result sent to driver
2015-11-24 23:09:24,487 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 5.0 (TID 22, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:24,488 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 5.0 (TID 21) in 206 ms on localhost (4/6)
2015-11-24 23:09:24,490 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 5.0 (TID 22)
2015-11-24 23:09:24,494 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:24,494 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:24,649 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 5.0 (TID 22). 1378 bytes result sent to driver
2015-11-24 23:09:24,653 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 5.0 (TID 23, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:24,655 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 5.0 (TID 22) in 168 ms on localhost (5/6)
2015-11-24 23:09:24,657 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 5.0 (TID 23)
2015-11-24 23:09:24,661 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:24,661 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:24,762 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 5.0 (TID 23). 1378 bytes result sent to driver
2015-11-24 23:09:24,770 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 5 (sortBy at InsightOfDataSet.scala:59) finished in 1.281 s
2015-11-24 23:09:24,771 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 23:09:24,771 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 5.0 (TID 23) in 117 ms on localhost (6/6)
2015-11-24 23:09:24,771 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 23:09:24,771 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 6, ResultStage 7)
2015-11-24 23:09:24,771 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-11-24 23:09:24,771 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 23:09:24,772 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 6: List()
2015-11-24 23:09:24,772 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 7: List(ShuffleMapStage 6)
2015-11-24 23:09:24,772 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 6 (MapPartitionsRDD[14] at coalesce at InsightOfDataSet.scala:59), which is now runnable
2015-11-24 23:09:24,774 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3336) called with curMem=133651, maxMem=505361203
2015-11-24 23:09:24,775 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 3.3 KB, free 481.8 MB)
2015-11-24 23:09:24,777 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1902) called with curMem=136987, maxMem=505361203
2015-11-24 23:09:24,777 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 1902.0 B, free 481.8 MB)
2015-11-24 23:09:24,778 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:55441 (size: 1902.0 B, free: 481.9 MB)
2015-11-24 23:09:24,779 INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-11-24 23:09:24,783 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 5 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[14] at coalesce at InsightOfDataSet.scala:59)
2015-11-24 23:09:24,783 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 5 tasks
2015-11-24 23:09:24,785 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 24, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:24,788 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 24)
2015-11-24 23:09:24,792 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:24,792 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:24,898 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 24). 1374 bytes result sent to driver
2015-11-24 23:09:24,900 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 6.0 (TID 25, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:24,901 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 6.0 (TID 25)
2015-11-24 23:09:24,901 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 24) in 116 ms on localhost (1/5)
2015-11-24 23:09:24,905 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:24,905 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:24,925 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 6.0 (TID 25). 1374 bytes result sent to driver
2015-11-24 23:09:24,927 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 6.0 (TID 26, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:24,928 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 6.0 (TID 26)
2015-11-24 23:09:24,932 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 6.0 (TID 25) in 32 ms on localhost (2/5)
2015-11-24 23:09:24,936 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:24,936 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:24,998 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 6.0 (TID 26). 1374 bytes result sent to driver
2015-11-24 23:09:25,001 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 6.0 (TID 27, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:25,003 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 6.0 (TID 27)
2015-11-24 23:09:25,007 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 6.0 (TID 26) in 79 ms on localhost (3/5)
2015-11-24 23:09:25,007 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:25,007 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:25,136 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 6.0 (TID 27). 1374 bytes result sent to driver
2015-11-24 23:09:25,139 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 6.0 (TID 28, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:09:25,141 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 6.0 (TID 27) in 140 ms on localhost (4/5)
2015-11-24 23:09:25,142 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 6.0 (TID 28)
2015-11-24 23:09:25,145 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:25,146 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:25,552 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 6.0 (TID 28). 1374 bytes result sent to driver
2015-11-24 23:09:25,553 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 6.0 (TID 28) in 414 ms on localhost (5/5)
2015-11-24 23:09:25,553 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 6 (coalesce at InsightOfDataSet.scala:59) finished in 0.770 s
2015-11-24 23:09:25,553 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-11-24 23:09:25,553 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 23:09:25,553 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 23:09:25,553 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 7)
2015-11-24 23:09:25,553 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 23:09:25,554 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 7: List()
2015-11-24 23:09:25,554 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[18] at saveAsTextFile at InsightOfDataSet.scala:59), which is now runnable
2015-11-24 23:09:25,609 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(95776) called with curMem=138889, maxMem=505361203
2015-11-24 23:09:25,610 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 93.5 KB, free 481.7 MB)
2015-11-24 23:09:25,611 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(31393) called with curMem=234665, maxMem=505361203
2015-11-24 23:09:25,612 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 30.7 KB, free 481.7 MB)
2015-11-24 23:09:25,612 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on localhost:55441 (size: 30.7 KB, free: 481.9 MB)
2015-11-24 23:09:25,613 INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:861
2015-11-24 23:09:25,613 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[18] at saveAsTextFile at InsightOfDataSet.scala:59)
2015-11-24 23:09:25,613 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks
2015-11-24 23:09:25,666 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 29, localhost, PROCESS_LOCAL, 2170 bytes)
2015-11-24 23:09:25,670 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 29)
2015-11-24 23:09:25,719 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-11-24 23:09:25,720 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-11-24 23:09:25,722 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-11-24 23:09:25,725 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-11-24 23:09:25,950 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 5 non-empty blocks out of 5 blocks
2015-11-24 23:09:25,950 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:26,309 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201511242309_0007_m_000000_29' to file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/UserToHotels/_temporary/0/task_201511242309_0007_m_000000
2015-11-24 23:09:26,309 INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_201511242309_0007_m_000000_29: Committed
2015-11-24 23:09:26,310 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 29). 1165 bytes result sent to driver
2015-11-24 23:09:26,311 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 29) in 696 ms on localhost (1/1)
2015-11-24 23:09:26,311 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 7 (saveAsTextFile at InsightOfDataSet.scala:59) finished in 0.697 s
2015-11-24 23:09:26,311 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2015-11-24 23:09:26,312 INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: saveAsTextFile at InsightOfDataSet.scala:59, took 2.896982 s
2015-11-24 23:09:26,381 INFO  org.apache.spark.SparkContext - Starting job: count at InsightOfDataSet.scala:60
2015-11-24 23:09:26,383 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 1 is 180 bytes
2015-11-24 23:09:26,384 INFO  org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 162 bytes
2015-11-24 23:09:26,385 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 2 (count at InsightOfDataSet.scala:60) with 6 output partitions
2015-11-24 23:09:26,386 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 10(count at InsightOfDataSet.scala:60)
2015-11-24 23:09:26,386 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 9)
2015-11-24 23:09:26,386 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2015-11-24 23:09:26,387 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 10 (ShuffledRDD[8] at reduceByKey at InsightOfDataSet.scala:57), which has no missing parents
2015-11-24 23:09:26,388 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2112) called with curMem=266058, maxMem=505361203
2015-11-24 23:09:26,389 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 2.1 KB, free 481.7 MB)
2015-11-24 23:09:26,392 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1334) called with curMem=268170, maxMem=505361203
2015-11-24 23:09:26,392 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 1334.0 B, free 481.7 MB)
2015-11-24 23:09:26,393 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on localhost:55441 (size: 1334.0 B, free: 481.9 MB)
2015-11-24 23:09:26,394 INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:861
2015-11-24 23:09:26,394 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 10 (ShuffledRDD[8] at reduceByKey at InsightOfDataSet.scala:57)
2015-11-24 23:09:26,394 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 10.0 with 6 tasks
2015-11-24 23:09:26,396 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 10.0 (TID 30, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:09:26,396 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 10.0 (TID 30)
2015-11-24 23:09:26,398 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:26,398 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:26,421 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 10.0 (TID 30). 1203 bytes result sent to driver
2015-11-24 23:09:26,422 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 10.0 (TID 31, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:09:26,422 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 10.0 (TID 30) in 27 ms on localhost (1/6)
2015-11-24 23:09:26,422 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 10.0 (TID 31)
2015-11-24 23:09:26,423 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:26,424 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:26,447 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 10.0 (TID 31). 1203 bytes result sent to driver
2015-11-24 23:09:26,448 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 10.0 (TID 32, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:09:26,448 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 10.0 (TID 32)
2015-11-24 23:09:26,449 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 10.0 (TID 31) in 27 ms on localhost (2/6)
2015-11-24 23:09:26,450 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:26,450 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:26,473 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 10.0 (TID 32). 1203 bytes result sent to driver
2015-11-24 23:09:26,474 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 10.0 (TID 33, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:09:26,474 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 10.0 (TID 33)
2015-11-24 23:09:26,474 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 10.0 (TID 32) in 26 ms on localhost (3/6)
2015-11-24 23:09:26,476 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:26,476 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:26,503 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 10.0 (TID 33). 1203 bytes result sent to driver
2015-11-24 23:09:26,504 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 10.0 (TID 34, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:09:26,504 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 10.0 (TID 33) in 31 ms on localhost (4/6)
2015-11-24 23:09:26,504 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 10.0 (TID 34)
2015-11-24 23:09:26,506 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:26,506 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:09:26,532 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 10.0 (TID 34). 1203 bytes result sent to driver
2015-11-24 23:09:26,533 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 10.0 (TID 35, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:09:26,533 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 10.0 (TID 35)
2015-11-24 23:09:26,534 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 10.0 (TID 34) in 31 ms on localhost (5/6)
2015-11-24 23:09:26,535 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:09:26,535 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:09:26,559 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 10.0 (TID 35). 1203 bytes result sent to driver
2015-11-24 23:09:26,560 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 10.0 (TID 35) in 28 ms on localhost (6/6)
2015-11-24 23:09:26,560 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 10 (count at InsightOfDataSet.scala:60) finished in 0.165 s
2015-11-24 23:09:26,560 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2015-11-24 23:09:26,561 INFO  org.apache.spark.scheduler.DAGScheduler - Job 2 finished: count at InsightOfDataSet.scala:60, took 0.179277 s
2015-11-24 23:09:26,629 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-24 23:09:26,702 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-24 23:09:26,703 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-24 23:09:26,703 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-24 23:09:26,703 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-24 23:09:26,704 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-24 23:09:26,704 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-24 23:09:26,704 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-24 23:09:26,704 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-24 23:09:26,704 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-24 23:09:26,705 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-24 23:09:26,705 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-24 23:09:26,705 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-24 23:09:26,705 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-24 23:09:26,705 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-24 23:09:26,706 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-24 23:09:26,706 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-24 23:09:26,706 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-24 23:09:26,706 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-24 23:09:26,706 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-24 23:09:26,707 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-24 23:09:26,707 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-24 23:09:26,707 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-24 23:09:26,707 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-24 23:09:26,707 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-24 23:09:26,707 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-24 23:09:26,786 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-24 23:09:26,829 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-24 23:09:27,051 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-24 23:09:27,194 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-24 23:09:27,195 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-24 23:09:27,196 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-24 23:09:27,227 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-24 23:09:27,227 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-24 23:09:27,309 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-24 23:09:27,354 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-c2282331-951d-4976-8b9a-e2d7dcbbba04
2015-11-24 23:20:57,975 INFO  org.apache.spark.SparkContext - Running Spark version 1.5.0
2015-11-24 23:21:03,316 INFO  org.apache.spark.SecurityManager - Changing view acls to: Claire
2015-11-24 23:21:03,362 INFO  org.apache.spark.SecurityManager - Changing modify acls to: Claire
2015-11-24 23:21:03,363 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Claire); users with modify permissions: Set(Claire)
2015-11-24 23:21:08,207 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-11-24 23:21:08,304 INFO  Remoting - Starting remoting
2015-11-24 23:21:08,653 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.18.1:56155]
2015-11-24 23:21:08,659 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 56155.
2015-11-24 23:21:08,802 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-11-24 23:21:08,847 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-11-24 23:21:08,911 INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Claire\AppData\Local\Temp\blockmgr-46058d26-c4c4-47d1-9c2e-1a7a7209e690
2015-11-24 23:21:08,985 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 481.9 MB
2015-11-24 23:21:09,155 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\Claire\AppData\Local\Temp\spark-b13827e4-b27b-4840-8c50-b97d0e7cd991\httpd-a1d8d1de-3a12-467a-818c-fa7871071c82
2015-11-24 23:21:09,194 INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-11-24 23:21:09,333 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 23:21:09,386 INFO  org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:56157
2015-11-24 23:21:09,387 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 56157.
2015-11-24 23:21:09,488 INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2015-11-24 23:21:09,908 INFO  org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2015-11-24 23:21:09,925 INFO  org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2015-11-24 23:21:09,925 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-11-24 23:21:09,927 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.18.1:4040
2015-11-24 23:21:10,220 WARN  org.apache.spark.metrics.MetricsSystem - Using default name DAGScheduler for source because spark.app.id is not set.
2015-11-24 23:21:10,226 INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2015-11-24 23:21:10,679 INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56177.
2015-11-24 23:21:10,680 INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 56177
2015-11-24 23:21:10,727 INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-11-24 23:21:10,740 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager localhost:56177 with 481.9 MB RAM, BlockManagerId(driver, localhost, 56177)
2015-11-24 23:21:10,753 INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-11-24 23:21:12,196 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(106480) called with curMem=0, maxMem=505361203
2015-11-24 23:21:12,220 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 104.0 KB, free 481.8 MB)
2015-11-24 23:21:12,359 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(10065) called with curMem=106480, maxMem=505361203
2015-11-24 23:21:12,360 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 481.8 MB)
2015-11-24 23:21:12,364 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:56177 (size: 9.8 KB, free: 481.9 MB)
2015-11-24 23:21:12,392 INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at InsightOfDataSet.scala:16
2015-11-24 23:21:13,873 WARN   - Your hostname, Claire-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c701%29, but we couldn't find any external IP address!
2015-11-24 23:21:15,163 INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 3
2015-11-24 23:21:15,374 INFO  org.apache.spark.SparkContext - Starting job: collect at InsightOfDataSet.scala:65
2015-11-24 23:21:15,436 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 4 (distinct at InsightOfDataSet.scala:56)
2015-11-24 23:21:15,438 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 7 (map at InsightOfDataSet.scala:57)
2015-11-24 23:21:15,439 INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 9 (map at InsightOfDataSet.scala:63)
2015-11-24 23:21:15,442 INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (collect at InsightOfDataSet.scala:65) with 6 output partitions
2015-11-24 23:21:15,443 INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 3(collect at InsightOfDataSet.scala:65)
2015-11-24 23:21:15,444 INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 2)
2015-11-24 23:21:15,446 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 2)
2015-11-24 23:21:15,477 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at distinct at InsightOfDataSet.scala:56), which has no missing parents
2015-11-24 23:21:15,594 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(4208) called with curMem=116545, maxMem=505361203
2015-11-24 23:21:15,595 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 481.8 MB)
2015-11-24 23:21:15,597 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2348) called with curMem=120753, maxMem=505361203
2015-11-24 23:21:15,597 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 481.8 MB)
2015-11-24 23:21:15,598 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:56177 (size: 2.3 KB, free: 481.9 MB)
2015-11-24 23:21:15,599 INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-11-24 23:21:15,605 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at distinct at InsightOfDataSet.scala:56)
2015-11-24 23:21:15,606 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 6 tasks
2015-11-24 23:21:15,661 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:21:15,681 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-11-24 23:21:15,723 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:0+33554432
2015-11-24 23:21:15,752 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-11-24 23:21:15,752 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-11-24 23:21:15,752 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-11-24 23:21:15,752 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-11-24 23:21:15,752 INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-11-24 23:21:18,043 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2258 bytes result sent to driver
2015-11-24 23:21:18,151 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:21:18,151 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2015-11-24 23:21:18,255 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00000:33554432+20843526
2015-11-24 23:21:18,373 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 2639 ms on localhost (1/6)
2015-11-24 23:21:20,088 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 2258 bytes result sent to driver
2015-11-24 23:21:20,091 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:21:20,093 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 1943 ms on localhost (2/6)
2015-11-24 23:21:20,094 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
2015-11-24 23:21:20,103 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:0+33554432
2015-11-24 23:21:24,829 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 2258 bytes result sent to driver
2015-11-24 23:21:24,834 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:21:24,835 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
2015-11-24 23:21:24,836 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 4745 ms on localhost (3/6)
2015-11-24 23:21:24,841 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00001:33554432+20844232
2015-11-24 23:21:25,407 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 2258 bytes result sent to driver
2015-11-24 23:21:25,408 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:21:25,409 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
2015-11-24 23:21:25,412 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 579 ms on localhost (4/6)
2015-11-24 23:21:25,420 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:0+33554432
2015-11-24 23:21:26,295 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 2258 bytes result sent to driver
2015-11-24 23:21:26,297 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 0.0 (TID 5, localhost, PROCESS_LOCAL, 2188 bytes)
2015-11-24 23:21:26,297 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 0.0 (TID 5)
2015-11-24 23:21:26,299 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 890 ms on localhost (5/6)
2015-11-24 23:21:26,304 INFO  org.apache.spark.rdd.HadoopRDD - Input split: file:/E:/Project/FoodTracing/DataProcessing/GroupRec/DataResource/HotelUserInfo/part-00002:33554432+20845196
2015-11-24 23:21:26,739 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 0.0 (TID 5). 2258 bytes result sent to driver
2015-11-24 23:21:26,765 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 0.0 (TID 5) in 468 ms on localhost (6/6)
2015-11-24 23:21:26,766 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (distinct at InsightOfDataSet.scala:56) finished in 11.147 s
2015-11-24 23:21:26,768 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-11-24 23:21:26,768 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 23:21:26,789 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 23:21:26,790 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 1, ShuffleMapStage 2, ResultStage 3)
2015-11-24 23:21:26,791 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 23:21:26,852 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 1: List()
2015-11-24 23:21:26,852 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 2: List(ShuffleMapStage 1)
2015-11-24 23:21:26,853 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 3: List(ShuffleMapStage 2)
2015-11-24 23:21:26,866 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at InsightOfDataSet.scala:57), which is now runnable
2015-11-24 23:21:26,867 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2704) called with curMem=123101, maxMem=505361203
2015-11-24 23:21:26,868 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 481.8 MB)
2015-11-24 23:21:26,869 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1570) called with curMem=125805, maxMem=505361203
2015-11-24 23:21:26,869 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1570.0 B, free 481.8 MB)
2015-11-24 23:21:26,871 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:56177 (size: 1570.0 B, free: 481.9 MB)
2015-11-24 23:21:26,872 INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-11-24 23:21:26,872 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at InsightOfDataSet.scala:57)
2015-11-24 23:21:26,873 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 6 tasks
2015-11-24 23:21:26,875 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 6, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:21:26,875 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 6)
2015-11-24 23:21:26,969 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:21:26,986 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 24 ms
2015-11-24 23:21:27,484 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 6). 1379 bytes result sent to driver
2015-11-24 23:21:27,485 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 7, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:21:27,485 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 7)
2015-11-24 23:21:27,485 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 6) in 612 ms on localhost (1/6)
2015-11-24 23:21:27,541 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:21:27,541 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:21:27,752 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 7). 1379 bytes result sent to driver
2015-11-24 23:21:27,753 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 1.0 (TID 8, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:21:27,754 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 1.0 (TID 8)
2015-11-24 23:21:27,754 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 7) in 269 ms on localhost (2/6)
2015-11-24 23:21:27,756 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:21:27,756 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:21:27,860 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 1.0 (TID 8). 1379 bytes result sent to driver
2015-11-24 23:21:27,861 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 1.0 (TID 9, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:21:27,862 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 1.0 (TID 9)
2015-11-24 23:21:27,862 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 1.0 (TID 8) in 109 ms on localhost (3/6)
2015-11-24 23:21:27,865 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:21:27,865 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:21:27,967 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 1.0 (TID 9). 1379 bytes result sent to driver
2015-11-24 23:21:27,968 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 1.0 (TID 10, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:21:27,968 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 1.0 (TID 10)
2015-11-24 23:21:27,968 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 1.0 (TID 9) in 107 ms on localhost (4/6)
2015-11-24 23:21:27,971 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:21:27,971 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:21:28,067 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 1.0 (TID 10). 1379 bytes result sent to driver
2015-11-24 23:21:28,068 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 1.0 (TID 11, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:21:28,068 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 1.0 (TID 11)
2015-11-24 23:21:28,069 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 1.0 (TID 10) in 101 ms on localhost (5/6)
2015-11-24 23:21:28,071 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:21:28,071 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:21:28,187 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 1.0 (TID 11). 1379 bytes result sent to driver
2015-11-24 23:21:28,188 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 1.0 (TID 11) in 120 ms on localhost (6/6)
2015-11-24 23:21:28,188 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (map at InsightOfDataSet.scala:57) finished in 1.315 s
2015-11-24 23:21:28,188 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-11-24 23:21:28,188 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 23:21:28,188 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 23:21:28,188 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 2, ResultStage 3)
2015-11-24 23:21:28,189 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 23:21:28,189 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ShuffleMapStage 2: List()
2015-11-24 23:21:28,189 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 3: List(ShuffleMapStage 2)
2015-11-24 23:21:28,189 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 2 (MapPartitionsRDD[9] at map at InsightOfDataSet.scala:63), which is now runnable
2015-11-24 23:21:28,191 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2536) called with curMem=127375, maxMem=505361203
2015-11-24 23:21:28,191 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 2.5 KB, free 481.8 MB)
2015-11-24 23:21:28,200 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1518) called with curMem=129911, maxMem=505361203
2015-11-24 23:21:28,200 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1518.0 B, free 481.8 MB)
2015-11-24 23:21:28,201 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:56177 (size: 1518.0 B, free: 481.9 MB)
2015-11-24 23:21:28,202 INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-11-24 23:21:28,203 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[9] at map at InsightOfDataSet.scala:63)
2015-11-24 23:21:28,203 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 6 tasks
2015-11-24 23:21:28,204 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 12, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:21:28,204 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 12)
2015-11-24 23:21:28,206 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:21:28,206 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:21:28,327 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 12). 1379 bytes result sent to driver
2015-11-24 23:21:28,328 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 13, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:21:28,328 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 13)
2015-11-24 23:21:28,329 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 12) in 125 ms on localhost (1/6)
2015-11-24 23:21:28,331 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:21:28,331 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:21:28,374 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 13). 1379 bytes result sent to driver
2015-11-24 23:21:28,376 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 2.0 (TID 14, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:21:28,376 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 2.0 (TID 14)
2015-11-24 23:21:28,377 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 13) in 49 ms on localhost (2/6)
2015-11-24 23:21:28,379 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:21:28,380 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:21:28,480 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 2.0 (TID 14). 1379 bytes result sent to driver
2015-11-24 23:21:28,481 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 2.0 (TID 15, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:21:28,481 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 2.0 (TID 15)
2015-11-24 23:21:28,481 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 2.0 (TID 14) in 106 ms on localhost (3/6)
2015-11-24 23:21:28,485 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:21:28,485 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:21:28,534 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 2.0 (TID 15). 1379 bytes result sent to driver
2015-11-24 23:21:28,534 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 2.0 (TID 16, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:21:28,535 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 2.0 (TID 16)
2015-11-24 23:21:28,536 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 2.0 (TID 15) in 55 ms on localhost (4/6)
2015-11-24 23:21:28,537 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:21:28,538 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:21:28,577 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 2.0 (TID 16). 1379 bytes result sent to driver
2015-11-24 23:21:28,578 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 2.0 (TID 17, localhost, PROCESS_LOCAL, 1890 bytes)
2015-11-24 23:21:28,578 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 2.0 (TID 17)
2015-11-24 23:21:28,579 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 2.0 (TID 16) in 44 ms on localhost (5/6)
2015-11-24 23:21:28,581 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:21:28,581 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:21:28,627 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 2.0 (TID 17). 1379 bytes result sent to driver
2015-11-24 23:21:28,629 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 2.0 (TID 17) in 50 ms on localhost (6/6)
2015-11-24 23:21:28,629 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-11-24 23:21:28,630 INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 2 (map at InsightOfDataSet.scala:63) finished in 0.427 s
2015-11-24 23:21:28,630 INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2015-11-24 23:21:28,630 INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2015-11-24 23:21:28,630 INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 3)
2015-11-24 23:21:28,630 INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2015-11-24 23:21:28,634 INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents for ResultStage 3: List()
2015-11-24 23:21:28,634 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (ShuffledRDD[10] at reduceByKey at InsightOfDataSet.scala:65), which is now runnable
2015-11-24 23:21:28,673 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2296) called with curMem=131429, maxMem=505361203
2015-11-24 23:21:28,673 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 2.2 KB, free 481.8 MB)
2015-11-24 23:21:28,674 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(1383) called with curMem=133725, maxMem=505361203
2015-11-24 23:21:28,674 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1383.0 B, free 481.8 MB)
2015-11-24 23:21:28,675 INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:56177 (size: 1383.0 B, free: 481.9 MB)
2015-11-24 23:21:28,676 INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-11-24 23:21:28,683 INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ResultStage 3 (ShuffledRDD[10] at reduceByKey at InsightOfDataSet.scala:65)
2015-11-24 23:21:28,683 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 6 tasks
2015-11-24 23:21:28,686 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 18, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:21:28,686 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 18)
2015-11-24 23:21:28,689 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 6 blocks
2015-11-24 23:21:28,690 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:21:28,691 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 18). 1161 bytes result sent to driver
2015-11-24 23:21:28,692 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 3.0 (TID 19, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:21:28,693 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 18) in 8 ms on localhost (1/6)
2015-11-24 23:21:28,693 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 3.0 (TID 19)
2015-11-24 23:21:28,695 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 6 blocks
2015-11-24 23:21:28,695 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:21:28,696 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 3.0 (TID 19). 1161 bytes result sent to driver
2015-11-24 23:21:28,697 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 3.0 (TID 20, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:21:28,698 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 3.0 (TID 19) in 5 ms on localhost (2/6)
2015-11-24 23:21:28,698 INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 3.0 (TID 20)
2015-11-24 23:21:28,701 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 6 blocks
2015-11-24 23:21:28,701 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:21:28,702 INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 3.0 (TID 20). 1161 bytes result sent to driver
2015-11-24 23:21:28,703 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 3.0 (TID 21, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:21:28,703 INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 3.0 (TID 21)
2015-11-24 23:21:28,703 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 3.0 (TID 20) in 7 ms on localhost (3/6)
2015-11-24 23:21:28,705 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 6 blocks
2015-11-24 23:21:28,705 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2015-11-24 23:21:28,706 INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 3.0 (TID 21). 1161 bytes result sent to driver
2015-11-24 23:21:28,708 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 3.0 (TID 22, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:21:28,709 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 3.0 (TID 21) in 7 ms on localhost (4/6)
2015-11-24 23:21:28,709 INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 3.0 (TID 22)
2015-11-24 23:21:28,712 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 6 blocks
2015-11-24 23:21:28,712 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:21:28,712 INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 3.0 (TID 22). 1161 bytes result sent to driver
2015-11-24 23:21:28,713 INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 3.0 (TID 23, localhost, PROCESS_LOCAL, 1901 bytes)
2015-11-24 23:21:28,714 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 3.0 (TID 22) in 8 ms on localhost (5/6)
2015-11-24 23:21:28,715 INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 3.0 (TID 23)
2015-11-24 23:21:28,717 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 non-empty blocks out of 6 blocks
2015-11-24 23:21:28,718 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2015-11-24 23:21:28,721 INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 3.0 (TID 23). 1309 bytes result sent to driver
2015-11-24 23:21:28,722 INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 3.0 (TID 23) in 9 ms on localhost (6/6)
2015-11-24 23:21:28,722 INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 3 (collect at InsightOfDataSet.scala:65) finished in 0.038 s
2015-11-24 23:21:28,723 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-11-24 23:21:28,767 INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: collect at InsightOfDataSet.scala:65, took 13.393065 s
2015-11-24 23:21:28,892 INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2015-11-24 23:21:28,956 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-11-24 23:21:28,957 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-11-24 23:21:28,958 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-11-24 23:21:28,958 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2015-11-24 23:21:28,959 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-11-24 23:21:28,960 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-11-24 23:21:28,961 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-11-24 23:21:28,962 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-11-24 23:21:28,962 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-11-24 23:21:28,963 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-11-24 23:21:28,964 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-11-24 23:21:28,965 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-11-24 23:21:28,966 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-11-24 23:21:28,967 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-11-24 23:21:28,968 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-11-24 23:21:28,970 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-11-24 23:21:28,971 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-11-24 23:21:28,972 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-11-24 23:21:28,973 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-11-24 23:21:28,974 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-11-24 23:21:28,975 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-11-24 23:21:28,976 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-11-24 23:21:28,977 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-11-24 23:21:28,977 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-11-24 23:21:28,978 INFO  org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-11-24 23:21:29,049 INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.18.1:4040
2015-11-24 23:21:29,093 INFO  org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
2015-11-24 23:21:29,308 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2015-11-24 23:21:29,399 INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2015-11-24 23:21:29,401 INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2015-11-24 23:21:29,437 INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2015-11-24 23:21:29,478 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2015-11-24 23:21:29,478 INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2015-11-24 23:21:29,490 INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2015-11-24 23:21:29,491 INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Claire\AppData\Local\Temp\spark-b13827e4-b27b-4840-8c50-b97d0e7cd991
